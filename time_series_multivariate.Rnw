% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, eval=FALSE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size='scriptsize', fig.width=4, fig.height=4)
options(digits=3)
options(width=60, dev='pdf')
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[10pt]{beamer}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
% \usepackage{mathtools}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape,bg=red,fg=red}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}



% Title page setup
\title[Time Series Multivariate]{Time Series Multivariate}
\subtitle{FRE6871 \& FRE7241, Spring 2017}
\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@nyu.edu}
\date{\today}



%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle



%%%%%%%%%%%%%%%
\section{Asset Pricing Models}


%%%%%%%%%%%%%%%
\subsection{Linear Regression of Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The returns of \emph{XLP} and \emph{VTI} are highly correlated because they are driven by common market factors of returns, 
      \vskip1ex
      The \emph{t}-statistic (\emph{t}-value) is the ratio of the estimated value divided by its standard error,
      \vskip1ex
      The \emph{p}-value is the probability of obtaining the observed value of the \emph{t}-statistic, or more extreme values,
      <<echo=(-(1:1)),eval=TRUE>>=
library(HighFreq)
# specify formula and perform regression
reg_formula <- XLP ~ VTI
reg_model <- lm(reg_formula, 
                data=rutils::env_etf$re_turns)
# get regression coefficients
coef(summary(reg_model))
# Durbin-Watson test of autocorrelation of residuals
lmtest::dwtest(reg_model)
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/reg_rets.png}\\
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# plot scatterplot of returns with aspect ratio 1
plot(reg_formula, data=rutils::env_etf$re_turns,
     xlim=c(-0.1, 0.1), ylim=c(-0.1, 0.1), 
     asp=1, main="Regression XLP ~ VTI")
# add regression line and perpendicular line
abline(reg_model, lwd=2, col="red")
abline(a=0, b=-1/coef(summary(reg_model))[2, 1], 
       lwd=2, col="blue")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Linear Regression Summary Statistics}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.55\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(HighFreq)  # load HighFreq
re_turns <- na.omit(rutils::env_etf$re_turns)
# perform regressions and collect statistics
etf_reg_stats <- sapply(colnames(re_turns)[-1], 
                        function(etf_name) {
# specify regression formula
  reg_formula <- as.formula(
    paste(etf_name, "~ VTI"))
# perform regression
  reg_model <- lm(reg_formula, data=re_turns)
# get regression summary
  reg_model_sum <- summary(reg_model)
# collect regression statistics
  etf_reg_stats <- with(reg_model_sum, 
    c(alpha=coefficients[1, 1], 
      p_alpha=coefficients[1, 4], 
      beta=coefficients[2, 1], 
      p_beta=coefficients[2, 4]))
  etf_reg_stats <- c(etf_reg_stats, 
               p_dw=lmtest::dwtest(reg_model)$p.value)
  etf_reg_stats
})  # end sapply
etf_reg_stats <- t(etf_reg_stats)
# sort by p_alpha
etf_reg_stats <- etf_reg_stats[
  order(etf_reg_stats[, "p_alpha"]), ]
      @
    \column{0.45\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
etf_reg_stats[, 1:3]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Rolling Beta Regressions Over Time}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{rollapply()} allows performing regressions over a rolling window, 
      \vskip1ex
      The function \texttt{roll\_lm()} from package \emph{roll} performs rolling regressions in \texttt{C++}, in parallel, and is therefore much faster than function \texttt{rollapply()}, 
      <<echo=TRUE,eval=FALSE>>=
library(HighFreq)
# specify regression formula
reg_formula <- XLP ~ VTI
# perform rolling beta regressions every month
beta_s <- rollapply(rutils::env_etf$re_turns, width=252, 
  FUN=function(de_sign) 
  coef(lm(reg_formula, data=de_sign))[2],
  by=22, by.column=FALSE, align="right")
beta_s <- na.omit(beta_s)
# plot beta_s in x11() window
x11(width=(wid_th <- 6), height=(hei_ght <- 4))
chart_Series(x=beta_s, 
  name=paste("rolling betas", format(reg_formula)))
# perform daily rolling beta regressions in parallel
library(roll)
beta_s <- roll_lm(x=rutils::env_etf$re_turns[, "VTI"], 
                  y=rutils::env_etf$re_turns[, "XLP"],
                  width=252)$coefficients
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/rolling_betas.png}\\
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# compare speed of rollapply() versus roll_lm()
library(microbenchmark)
da_ta <- rutils::env_etf$re_turns["2012", c("VTI", "XLP")]
summary(microbenchmark(
  rollapply=rollapply(da_ta, width=22, 
      FUN=function(de_sign) 
      coef(lm(reg_formula, data=de_sign))[2],
        by.column=FALSE, align="right"), 
  roll_lm=roll_lm(x=da_ta[, "VTI"], 
                  y=da_ta[, "XLP"],
                  width=22)$coefficients, 
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Capital Asset Pricing Model (\protect \emph{CAPM})}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Capital Asset Pricing Model} decomposes asset returns into \emph{systematic} returns (proportional to the market returns) and \emph{idiosyncratic} returns (uncorrelated to market returns):
      \begin{displaymath}
        R - R_f = {\alpha} + \beta (R_m - R_f) + {\varepsilon}
      \end{displaymath}
      The \emph{systematic} risk and returns are proportional to $\beta$, 
      \vskip1ex
      $\beta$ can be obtained from linear regression, and is proportional to the correlation of returns between the asset and the market:
      \begin{displaymath}
        \beta = \frac{\sum_{i=1}^k (R_i-\bar{R}) (R_{i,m}-\bar{R_m})} {\sum_{i=1}^k (R_{i,m}-\bar{R_m})^2}
      \end{displaymath}
      The \emph{CAPM} model states that if an asset has higher $\beta$ risk, then it should earn higher \emph{systematic} returns,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(PerformanceAnalytics)
CAPM.beta(Ra=re_turns[, "XLP"], 
          Rb=re_turns[, "VTI"])
CAPM.beta.bull(Ra=re_turns[, "XLP"], 
  Rb=re_turns[, "VTI"])
CAPM.beta.bear(Ra=re_turns[, "XLP"], 
  Rb=re_turns[, "VTI"])
CAPM.alpha(Ra=re_turns[, "XLP"], 
           Rb=re_turns[, "VTI"])
      @
      The \emph{idiosyncratic} returns are equal to the sum of $\alpha$ plus $\varepsilon$,
      \vskip1ex
      \emph{Alpha} ($\alpha$) are the returns in excess of \emph{systematic} returns, that can be attributed to portfolio selection or active manager performance,
      \vskip1ex
      The \emph{idiosyncratic} risk (equal to $\varepsilon$) is uncorrelated to the \emph{systematic} risk, and can be reduced through portfolio diversification,
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Security Market Line}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      According to the \emph{CAPM} model, assets should earn a \emph{systematic} return proportional to their \emph{systematic} risk ($\beta$),
      \vskip1ex
      The \emph{Security Market Line} (SML) represents the linear relationship between \emph{systematic} risk ($\beta$) and return, for different stocks, 
      <<capm_scatter,echo=(-1),eval=FALSE,fig.width=5,fig.height=5,fig.show='hide'>>=
library(PerformanceAnalytics)
etf_betas <- sapply(
  re_turns[, colnames(re_turns)!="VXX"], 
  CAPM.beta, Rb=re_turns[, "VTI"])
etf_annrets <- sapply(
  re_turns[, colnames(re_turns)!="VXX"], 
  Return.annualized)
# plot scatterplot
plot(etf_annrets ~ etf_betas, xlab="betas", 
            ylab="ann. rets", xlim=c(-0.25, 1.6))
points(x=1, y=etf_annrets["VTI"], col="red", 
       lwd=3, pch=21)
abline(a=0, b=etf_annrets["VTI"])
label_names <- rownames(etf_reg_stats)[1:13]
# add labels
text(x=1, y=etf_annrets["VTI"], labels="VTI", 
     pos=2)
text(x=etf_betas[label_names], 
     y=etf_annrets[label_names], 
     labels=label_names, pos=2, cex=0.8)
      @
    \column{0.5\textwidth}
    \vspace{-3em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/capm_scatter-1}\\
    \vspace{-2em}
      A scatterplot of asset returns versus their $\beta$ shows which assets earn a positive $\alpha$, and which don't,
      \vskip1ex
      If an asset lies on the \emph{SML}, then its returns are mostly \emph{systematic}, and its $\alpha$ is equal to zero,
      \vskip1ex
      Assets above the \emph{SML} have a positive $\alpha$), and those below have a negative $\alpha$),
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Risk-adjusted Performance Measurement}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Treynor} ratio measures the excess returns per unit of \emph{systematic} risk ($\beta$), and is equal to the excess returns (over a risk-free return) divided by the $\beta$:
      \begin{displaymath}
        T_r=\frac{E[R-R_f]}{\beta}
      \end{displaymath}
      The \emph{Treynor} ratio is similar to the \emph{Sharpe} ratio, with the difference that its denominator represents only \emph{systematic} risk, not total risk,
      \vskip1ex
      The \emph{Information} ratio is equal to the excess returns (over a benchmark) divided by the \emph{tracking error} (standard deviation of excess returns):
      \begin{displaymath}
        I_r = \frac{E[R-R_b]} {\sqrt{\sum_{i=1}^k (R_i-R_{i,b})^2}}
      \end{displaymath}
      The \emph{Information} ratio measures the amount of outperformance versus the benchmark, and the consistency of outperformance,
      \vskip1ex
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(PerformanceAnalytics)
TreynorRatio(Ra=re_turns[, "XLP"], 
           Rb=re_turns[, "VTI"])

InformationRatio(Ra=re_turns[, "XLP"], 
           Rb=re_turns[, "VTI"])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{CAPM} Summary Statistics}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.55\textwidth}
      \vspace{-1em}
      <<echo=(-1),eval=FALSE>>=
library(PerformanceAnalytics)
table.CAPM(Ra=re_turns[, c("XLP", "XLF")], 
           Rb=re_turns[, "VTI"], scale=252)
      @
      \vspace{-2em}
      <<eval=FALSE,echo=(-1)>>=
library(PerformanceAnalytics)
capm_stats <- table.CAPM(Ra=re_turns[, colnames(re_turns)!="VTI"], 
              Rb=re_turns[, "VTI"], scale=252)
colnames(capm_stats) <- 
  sapply(colnames(capm_stats), 
  function (str) {strsplit(str, split=" ")[[1]][1]})
capm_stats <- as.matrix(capm_stats)
capm_stats <- t(capm_stats)
capm_stats <- capm_stats[
  order(capm_stats[, "Annualized Alpha"], 
        decreasing=TRUE), ]
# copy capm_stats into env_etf and save to .RData file
assign("capm_stats", capm_stats, envir=env_etf)
save(env_etf, file='etf_data.RData')
      @
    \column{0.45\textwidth}
      \vspace{-1em}
      <<eval=FALSE,echo=TRUE>>=
capm_stats[, c("Information Ratio", "Annualized Alpha")]
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Principal Component Analysis}


%%%%%%%%%%%%%%%
\subsection{draft - Principal Components for two assets}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The scaled returns of \emph{XLP} and \emph{VTI} can be expressed as linear combinations of two orthogonal principal components: \\
      The first principal component can be 
      returns of \emph{XLP} and \emph{VTI} are highly correlated because they both share a common factor of market returns, 
      <<echo=TRUE,eval=FALSE>>=
re_turns <- 
  scale(na.omit(rutils::env_etf$re_turns
                [, as.character(reg_formula)[-1]]))
(t(re_turns) %*% re_turns) / NROW(re_turns)
w_1 <- sqrt(0.5); w_2 <- w_1
foo <- matrix(c(w_1, w_2, -w_2, w_1), nc=2)
t(foo) %*% foo
# bar <- re_turns %*% t(solve(foo))
(t(bar) %*% bar) / NROW(bar)

cov_mat <- function(re_turns, an_gle=0) {
  w_1 <- cos(an_gle)
  w_2 <- sin(an_gle)
  mat_rix <- matrix(c(w_1, -w_2, w_2, w_1), nc=2)
  compo_nents <- re_turns %*% t(mat_rix)
  (t(compo_nents) %*% compo_nents) / NROW(compo_nents)
}  # end cov_mat

bar <- cov_mat(re_turns, an_gle=pi/4)
(t(re_turns) %*% re_turns) / NROW(re_turns)
(t(bar) %*% bar) / NROW(bar)

angle_s <- seq(0, pi/2, by=pi/24)
co_var <- sapply(angle_s, function(an_gle) 
  cov_mat(re_turns, an_gle=an_gle)[1, 1])
plot(x=angle_s, y=co_var, t="l")

op_tim <- optimize(
  f=function(an_gle) 
    -cov_mat(re_turns, an_gle=an_gle)[1, 1], 
  interval=range(angle_s))
an_gle <- op_tim$minimum
bar <- cov_mat(re_turns, an_gle=an_gle)
tan(an_gle)

w_1 <- cos(an_gle)
w_2 <- sin(an_gle)
mat_rix <- matrix(c(w_1, -w_2, w_2, w_1), nc=2)
compo_nents <- re_turns %*% t(mat_rix)
(t(compo_nents) %*% compo_nents) / NROW(compo_nents)

plot(x=compo_nents[, 1], y=compo_nents[, 2],
     xlim=c(-10, 10), ylim=c(-10, 10))

reg_model <- lm(reg_formula, data=re_turns)
# get regression coefficients
coef(summary(reg_model))

foo <- cbind(rnorm(1000, sd=0.2), rnorm(1000)) %*% t(mat_rix)
(t(foo) %*% foo) / NROW(foo)
plot(x=foo[, 1], y=foo[, 2])
summary(lm(foo[, 1] ~ foo[, 2]))

op_tim <- optimize(
  f=function(an_gle) 
    -cov_mat(foo, an_gle=an_gle)[1, 1], 
  interval=range(angle_s))
an_gle <- op_tim$minimum
tan(an_gle)

###

w_1 <- cos(0.5)
s_1 <- 1
s_2 <- 2
foo <- matrix(c(s_1^2, s_1*s_2*w_1, s_1*s_2*w_1, s_2^2), nc=2)
eigen(foo)

# Durbin-Watson test of autocorrelation of residuals
lmtest::dwtest(reg_model)
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/returns_regress-1}\\
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# plot scatterplot of returns
plot(reg_formula, data=rutils::env_etf$re_turns,
     main="Regression XLP ~ VTI")
# add regression line
abline(reg_model, lwd=2, col="red")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Covariance Matrix of the Data}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The covariance matrix $\mathbf{V}$, of the data matrix $\mathbf{r}$, is given by:
      \begin{displaymath}
        \mathbf{V} = \frac{\mathbf{r}^T \, \mathbf{r}} {n-1}
      \end{displaymath}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# select ETF symbols
sym_bols <- c("IEF", "DBC", "XLF", "XLP", "XLI", "VXX")
# select and de-mean the returns
re_turns <- na.omit(rutils::env_etf$re_turns[, sym_bols])
in_dex <- index(re_turns)
re_turns <- t(t(re_turns) - sapply(re_turns, sum)/NROW(re_turns))
# re_turns <- lapply(re_turns, function(x) {x - sum(x)/NROW(re_turns)})
# re_turns <- do.call(cbind, re_turns)
# re_turns <- scale(re_turns, scale=FALSE)
# covariance matrix and variance vector of the data
cov_mat <- (t(re_turns) %*% re_turns) / (NROW(re_turns)-1)
vari_ance <- diag(cov_mat)
cor_mat <- cov_mat / sqrt(vari_ance)
cor_mat <- t(t(cor_mat) / sqrt(vari_ance))
# cor_mat <- cor(re_turns)
# reorder correlation matrix based on clusters
library(corrplot)
or_der <- corrMatOrder(cor_mat, 
              order="hclust", 
              hclust.method="complete")
cor_mat <- cor_mat[or_der, or_der]
# plot the correlation matrix
col_ors <- colorRampPalette(c("red", "white", "blue"))
corrplot(cor_mat, title="Correlation Matrix", 
    tl.col="black", tl.cex=0.8, mar=c(0,0,1,0), 
    method="square", col=col_ors(8), 
    cl.offset=0.75, cl.cex=0.7, 
    cl.align.text="l", cl.ratio=0.25)
# draw rectangles on the correlation matrix plot
corrRect.hclust(cor_mat, k=NROW(cor_mat) %/% 2, 
                method="complete", col="red")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/cor_mat.png}\\
      \vspace{-1em}
            <<echo=TRUE,eval=FALSE>>=
# plot the correlation matrix
col_ors <- colorRampPalette(c("red", "white", "blue"))
corrplot(cor_mat, title="Correlation Matrix", 
    tl.col="black", tl.cex=0.8, mar = c(0,0,1,0),
    method="square", col=col_ors(NCOL(cor_mat)), 
    cl.offset=0.75, cl.cex=0.7, 
    cl.align.text="l", cl.ratio=0.25)
# draw rectangles on the correlation matrix plot
corrRect.hclust(cor_mat, k=NCOL(cor_mat) %/% 2, 
                method="complete", col="red")
      @

  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Principal Components of the Data}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Principal components} are linear combinations of the vectors of the data $\mathbf{r}_i$, 
      \vskip1ex
      The first principal component $\mathbf{pc}$, is given by:
      \begin{displaymath}
        \mathbf{pc} = \sum_{i=1}^k {w_i \, \mathbf{r}_i} = \mathbf{r} \, \mathbf{w}
      \end{displaymath}
      Where $w_i$ is a vector of weights (loadings), such that its sum of squares is equal to \texttt{1}: $\mathbf{w}^T \, \mathbf{w} = 1$,
      \vskip1ex
      The weights $\mathbf{w}$ are chosen to maximize the variance of the principal component:
      \begin{displaymath}
        \mathbf{w} = {\operatorname{\arg \, \max}} \, \left\{ \mathbf{pc}^T \, \mathbf{pc} \right\} = {\operatorname{\arg \, \max}} \, \left\{ \mathbf{w}^T \, \mathbf{r}^T \, \mathbf{r} \, \mathbf{w} \right\}
      \end{displaymath}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# create initial vector of portfolio weights
n_weights <- NROW(sym_bols)
weight_s <- rep(1/sqrt(n_weights), n_weights)
names(weight_s) <- sym_bols
# objective function equal to minus portfolio variance
object_ive <- function(weight_s, re_turns) {
  portf_rets <- re_turns %*% weight_s
  -sum(portf_rets*portf_rets) + 
    1000*(1 - sum(weight_s*weight_s))^2
}  # end object_ive
# objective for equal weight portfolio
object_ive(weight_s, re_turns)
# compare speed of two methods
summary(microbenchmark(
  trans_pose=t(portf_rets) %*% portf_rets,
  s_um=sum(portf_rets*portf_rets),
  times=10))[, c(1, 4, 5)]
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth,valign=t]{figure/pca_load.png}\\
      \vspace{-3em}
      <<echo=TRUE,eval=FALSE>>=
# find weights with maximum variance
optim_run <- optim(par=weight_s,
                   fn=object_ive,
                   re_turns=re_turns,
                   method="L-BFGS-B",
                   upper=rep(1.0, n_weights),
                   lower=rep(-1.0, n_weights))
# optimal weights and maximum variance
weight_s <- optim_run$par
-object_ive(weight_s, re_turns)
# plot first principal component loadings
barplot(weight_s, names.arg=names(weight_s), 
        xlab="", ylab="", 
        main="first principal component loadings")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Higher Order Principal Components}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{second principal component} can be calculated by maximizing its variance, under the constraint that it must be orthogonal to the \emph{first principal component}, 
      \vskip1ex
      Similarly, higher order \emph{principal components} can be calculated by maximizing their variances, under the constraint that they must be orthogonal to all the previous \emph{principal components}, 
      <<echo=TRUE,eval=FALSE>>=
# pc1 weights and returns
weights_1 <- weight_s
pc_1 <- re_turns %*% weights_1
# redefine objective function
object_ive <- function(weight_s, re_turns) {
  portf_rets <- re_turns %*% weight_s
  -sum(portf_rets*portf_rets) + 
    1000*(1 - sum(weight_s*weight_s))^2 + 
    1000*sum(pc_1*portf_rets)^2
}  # end object_ive
# find second principal component weights
optim_run <- optim(par=weight_s,
                   fn=object_ive,
                   re_turns=re_turns,
                   method="L-BFGS-B",
                   upper=rep(1.0, n_weights),
                   lower=rep(-1.0, n_weights))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth,valign=t]{figure/pca_load2.png}\\
      \vspace{-3em}
      <<echo=TRUE,eval=FALSE>>=
# pc2 weights and returns
weights_2 <- optim_run$par
pc_2 <- re_turns %*% weights_2
sum(pc_1*pc_2)
# plot second principal component loadings
barplot(weights_2, names.arg=names(weights_2), 
        xlab="", ylab="", 
        main="second principal component loadings")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Eigenvalues of the Covariance Matrix}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The maximization of the portfolio variance: $\mathbf{w}^T \, \mathbf{V} \, \mathbf{w}$, under the constraint $\mathbf{w}^T \, \mathbf{w} = 1$, can be redefined using the method of \emph{Lagrange multipliers} as the maximization of:
      \begin{displaymath}
        \mathbf{w}^T \, \mathbf{V} \, \mathbf{w} \, - \, \lambda \, \mathbf{w}^T \, \mathbf{w}
      \end{displaymath}
      Where $\lambda$ is a \emph{Lagrange multiplier}, 
      \vskip1ex
      The solution can be found by differentiating the above with respect to $\mathbf{w}$ and setting it to zero:
      \begin{displaymath}
        \mathbf{V} \, \mathbf{w} = \lambda \, \mathbf{w}
      \end{displaymath}
      The above is the \emph{eigenvalue} equation of the covariance matrix $\mathbf{V}$, and the optimal weights $\mathbf{w}$ form an \emph{eigenvector}, and $\lambda$ is the \emph{eigenvalue} corresponding to the \emph{eigenvector} $\mathbf{w}$, 
      \vskip1ex
      The \emph{eigenvalues} are the variances of the \emph{eigenvectors}, and their sum is equal to the sum of the data variances:
      \begin{displaymath}
        \sum_{i=1}^k \lambda_i = \sum_{i=1}^k \mathbf{r}_i^T \, \mathbf{r}_i
      \end{displaymath}
      The number of \emph{eigenvalues} is equal to the dimension of the covariance matrix,
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.45\paperwidth,valign=t]{figure/pca_eigen_values.png}\\
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# calculate eigenvectors and eigenvalues
ei_gen <- eigen(cov_mat)
ei_gen$values[1]
var(pc_1)
(cov_mat %*% weights_1) / weights_1
ei_gen$values[2]
var(pc_2)
(cov_mat %*% weights_2) / weights_2
sum(vari_ance)
sum(ei_gen$values)
barplot(ei_gen$values, # plot eigenvalues
        names.arg=paste0("PC", 1:n_weights), 
        las=3, xlab="", ylab="", main="PC eigenvalues (variances)")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Principal Component Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{prcomp()} performs \emph{Principal Component Analysis} on a matrix of data, and returns the results as an object of class \texttt{prcomp}, 
      \vskip1ex
      The first few \emph{principal components} explain most of the volatility in the data, so \emph{PCA} is a form of \emph{dimensionality reduction}, 
      <<echo=TRUE,eval=FALSE>>=
# perform principal component analysis PCA
p_ca <- prcomp(re_turns, 
               center=TRUE, scale=FALSE)
# plot standard deviations
barplot(p_ca$sdev, 
        names.arg=colnames(p_ca$rotation), 
        las=3, xlab="", ylab="", 
        main="PC volatilities")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.45\paperwidth,valign=t]{figure/pca_std_dev.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Principal Component Loadings (Weights)}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Principal component} loadings are the weights of portfolios which have mutually orthogonal returns,
      \vskip1ex
      The \emph{principal component} portfolios represent the different orthogonal modes of the data variance, 
      <<echo=TRUE,eval=FALSE>>=
# principal component loadings (weights)
p_ca$rotation
# plot loading barplots in multiple panels
par(mfrow=c(n_weights/2,2))
par(mar=c(2, 2, 2, 1), oma=c(0, 0, 0, 0))
for (or_der in 1:n_weights) {
  barplot(p_ca$rotation[, or_der], 
        las=3, xlab="", ylab="", main="")
  title(paste0("PC", or_der), line=-2.0, 
        col.main="red")
}  # end for
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/pca_loadings.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Principal Component Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The time series of the \emph{principal components} can be calculated by multiplying the loadings (weights) times the original data,
      \vskip1ex
      Higher order \emph{principal components} are gradually less volatile,
      <<echo=TRUE,eval=FALSE>>=
# principal component time series
pca_ts <- xts(re_turns %*% p_ca$rotation, 
                order.by=in_dex)
pca_ts <- cumsum(pca_ts)
# plot principal component time series in multiple panels
par(mfrow=c(n_weights/2,2))
par(mar=c(2, 2, 0, 1), oma=c(0, 0, 0, 0))
ra_nge <- range(pca_ts)
for (or_der in 1:n_weights) {
  plot.zoo(pca_ts[, or_der], 
           ylim=ra_nge, 
           xlab="", ylab="")
  title(paste0("PC", or_der), line=-2.0)
}  # end for
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/pca_time_series.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Time Series from Principal Components}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The original time series data can be calculated exactly from the time series of \emph{principal components}, by inverting the loadings matrix, 
      \vskip1ex
      The original time series can be calculated approximately from just the first few \emph{principal components}, which demonstrates that \emph{PCA} is a form of \emph{dimensionality reduction}, 
      \vskip1ex
      The function \texttt{solve()} solves a system of linear equations, and also inverts a square matrix, 
      <<echo=TRUE,eval=FALSE>>=
# invert principal component time series
pca_rets <- re_turns %*% p_ca$rotation
sol_ved <- pca_rets %*% solve(p_ca$rotation)
all.equal(re_turns, sol_ved)
sol_ved <- pca_rets[, 1:3] %*% solve(p_ca$rotation)[1:3, ]
# plot the solved returns
par(mfrow=c(n_weights/2,2))
par(mar=c(2, 2, 0, 1), oma=c(0, 0, 0, 0))
col_names <- colnames(re_turns)
for (or_der in 1:n_weights) {
  plot.zoo(
    cumsum(as.xts(cbind(re_turns[, or_der], sol_ved[, or_der]))), 
    plot.type="single", col=c("black", "blue"), xlab="", ylab="")
  legend(x="topright", 
         legend=paste0(col_names[or_der], c("", " solved")),
         title="", inset=0.05, cex=1.0, lwd=c(6, 6),
         lty=c(1, 1), col=c("black", "blue"))
}  # end for
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/pca_time_series_solved.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Principal Component Returns Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
\vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(PerformanceAnalytics)  # load package "PerformanceAnalytics"
# PC returns from rotation and scaled re_turns
re_turns_scaled <- apply(re_turns, 2, scale)
pca_rets <- re_turns_scaled %*% p_ca$rotation
# "x" matrix contains time series of PC returns
dim(p_ca$x)
class(p_ca$x)
head(p_ca$x[, 1:3], 3)
# convert PC matrix to xts and rescale to decimals
pca_rets <- xts(p_ca$x/100, 
    order.by=index(re_turns))
      @
\vspace{-1em}
      <<pca_cum_returns,echo=(-1),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PerformanceAnalytics)  # load package "PerformanceAnalytics"
chart.CumReturns(
  pca_rets[, 1:3], lwd=2, ylab="", 
  legend.loc="topright", main="")
# add title
title(main="ETF cumulative returns", line=-1)
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/pca_cum_returns-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Principal Component Returns Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-1),eval=FALSE>>=
library(PerformanceAnalytics)
# Calculate PC correlation matrix
cor_mat <- cor(pca_rets)
colnames(cor_mat) <- colnames(pca_rets)
rownames(cor_mat) <- colnames(pca_rets)
cor_mat[1:3, 1:3]
table.CAPM(Ra=pca_rets[, 1:3], 
    Rb=re_turns[, "VTI"], scale=252)
      @
    \column{0.5\textwidth}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{old - Principal Component Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<pca_plot,echo=(-(1:2)),fig.height=5,fig.show='hide',eval=FALSE>>=
par(oma=c(1,0,1,0), mgp=c(2,1,0), mar=c(2,1,2,1), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(2,1))  # set plot panels
### Perform principal component analysis PCA
re_turns <- na.omit(rutils::env_etf$re_turns)
p_ca <- prcomp(re_turns, center=TRUE, scale=TRUE)
barplot(p_ca$sdev[1:10], 
        names.arg=colnames(p_ca$rotation)[1:10], 
        las=3, ylab="STDEV", xlab="PCVec", 
        main="PCA Explain VAR")
# Show first three principal component loadings
head(p_ca$rotation[,1:3], 3)
# Permute second principal component loadings by size
pca_vec2 <- as.matrix(
  p_ca$rotation[order(p_ca$rotation[, 2], 
  decreasing=TRUE), 2])
colnames(pca_vec2) <- "pca2"
head(pca_vec2, 3)
# The option las=3 rotates the names.arg labels
barplot(as.vector(pca_vec2), 
        names.arg=rownames(pca_vec2), 
        las=3, ylab="Loadings", 
        xlab="Symbol", main="Loadings pca2")
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/pca_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{old - Principal Component Vectors}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<pca_vec,echo=(-(1:2)),eval=FALSE,fig.height=5,fig.show='hide'>>=
par(oma=c(1,0,1,0), mgp=c(2,1,0), mar=c(2,1,2,1), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(3,1))  # set plot panels
# get list of principal component vectors
pca_vecs <- lapply(1:3, function(or_der) {
  pca_vec <- as.matrix(
    p_ca$rotation[
    order(p_ca$rotation[, or_der], 
    decreasing=TRUE), or_der])
  colnames(pca_vec) <- paste0("pca", or_der)
  pca_vec
})  # end lapply
names(pca_vecs) <- c("pca1", "pca2", "pca3")
# The option las=3 rotates the names.arg labels
for (or_der in 1:3) {
  barplot(as.vector(pca_vecs[[or_der]]), 
        names.arg=rownames(pca_vecs[[or_der]]), 
        las=3, xlab="", ylab="", 
        main=paste("Loadings", 
          colnames(pca_vecs[[or_der]])))
}  # end for
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/pca_vec-1}
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Factor Analysis}


%%%%%%%%%%%%%%%
\subsection{Correlation and Factor Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<corr_plot,echo=(-(1:1)),eval=FALSE,fig.show='hide'>>=
library(quantmod)
### perform pair-wise correlation analysis
# calculate correlation matrix
cor_mat <- cor(re_turns)
colnames(cor_mat) <- colnames(re_turns)
rownames(cor_mat) <- colnames(re_turns)
# reorder correlation matrix based on clusters
# calculate permutation vector
library(corrplot)
or_der <- corrMatOrder(cor_mat, 
              order="hclust", 
              hclust.method="complete")
# apply permutation vector
cor_mat <- cor_mat[or_der, or_der]
# plot the correlation matrix
col_ors <- colorRampPalette(c("red", "white", "blue"))
corrplot(cor_mat, 
    tl.col="black", tl.cex=0.8, 
    method="square", col=col_ors(8), 
    cl.offset=0.75, cl.cex=0.7, 
    cl.align.text="l", cl.ratio=0.25)
# draw rectangles on the correlation matrix plot
corrRect.hclust(cor_mat, k=NROW(cor_mat) %/% 2, 
                method="complete", col="red")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/corr_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Hierarchical Clustering Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{as.dist()} converts a matrix representing the \emph{distance} (dissimilarity) between elements, into an object of class \texttt{"dist"},
      \vskip1ex
      For example, \texttt{as.dist()} converts \texttt{(1-correlation)} to distance,
      \vskip1ex
      The function \texttt{hclust()} recursively combines elements into clusters based on their mutual \emph{distance},
      \vskip1ex
      First \texttt{hclust()} combines individual elements that are closest to each other,
      \vskip1ex
      Then it combines elements to the closest clusters, then clusters with other clusters, until all elements are combined into one cluster,
      \vskip1ex
      This process of recursive clustering can be represented as a \emph{dendrogram} (tree diagram), 
      \vskip1ex
      Branches of a \emph{dendrogram} represent clusters,
      \vskip1ex
      Neighboring branches contain elements that are close to each other (have small distance),
      \vskip1ex
      Neighboring branches combine into larger branches, that then combine with their closest branches, etc.
    \column{0.5\textwidth}
      \vspace{-2em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/cluster_plot-1}
      \vspace{-4em}
      <<cluster_plot,echo=TRUE,eval=FALSE,fig.width=6,fig.height=6,fig.show='hide'>>=
# convert correlation matrix into distance object
dis_tance <- as.dist(1-cor_mat)
# Perform hierarchical clustering analysis
clus_ter <- hclust(dis_tance)
plot(clus_ter, ann=FALSE, xlab="", ylab="")
title("Dissimilarity = 1-Correlation", 
      line=-0.5)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package \protect\emph{factorAnalytics}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The package \emph{factorAnalytics} performs estimation and risk analysis of linear factor models for portfolio asset returns,
    \column{0.6\textwidth}
      \vspace{-1em}
      <<eval=FALSE>>=
library(factorAnalytics)  # load package "factorAnalytics"
# get documentation for package "factorAnalytics"
packageDescription("factorAnalytics")  # get short description
help(package="factorAnalytics")  # load help page
      @
      \vspace{-1em}
      <<eval=FALSE,echo=(-(1:2)),tidy=TRUE>>=
options(width=50)
library(factorAnalytics)  # load package "factorAnalytics"
# list all objects in "factorAnalytics"
ls("package:factorAnalytics")

# list all datasets in "factorAnalytics"
# data(package="factorAnalytics")

# remove factorAnalytics from search path
detach("package:factorAnalytics")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Fitting Factor Models Using PCA}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(factorAnalytics)
# fit a three-factor model using PCA
factor_pca <- fitSfm(rutils::env_etf$re_turns, k=3)
head(factor_pca$loadings, 3)  # factor loadings
# factor realizations (time series)
head(factor_pca$factors)
# residuals from regression
factor_pca$residuals[1:3, 1:3]
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(factorAnalytics)
factor_pca$alpha  # estimated alphas
factor_pca$r2  # R-squared regression
# covariance matrix estimated by factor model
factor_pca$Omega[1:3, 4:6]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Factor Loadings}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      <<fact_load,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=10,fig.show='hide'>>=
library(factorAnalytics)
# load(file="C:/Develop/data/portf_optim.RData")
plot(factor_pca, which.plot.group=3, 
     n.max=30, loop=FALSE)
# ?plot.sfm
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/fact_load-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Time Series of Factors}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_tsplot,eval=FALSE,echo=TRUE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# plot factor cumulative returns
chart.CumReturns(factor_pca$factors, 
    lwd=2, ylab="", legend.loc="topleft", 
    main="")

# plot time series of factor returns
# plot(factor_pca, which.plot.group=2, 
#   loop=FALSE)
      @
    \column{0.6\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/fact_tsplot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Asset Correlations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_corr_plot,eval=FALSE,echo=TRUE,fig.width=7,fig.height=7,fig.show='hide'>>=
# asset correlations "hclust" hierarchical clustering order
plot(factor_pca, which.plot.group=7, 
     loop=FALSE, order="hclust", 
     method="ellipse")
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/fact_corr_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Time Series of Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_plot,eval=FALSE,echo=TRUE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# plot residual cumulative returns
chart.CumReturns(
  factor_pca$residuals[, c("IEF", 
                  "DBC", "XLF")], 
  lwd=2, ylab="", legend.loc="topleft", 
  main="")
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/fact_resid_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Residual Returns Histogram}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_hist,eval=FALSE,echo=TRUE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# plot residual histogram with normal curve
plot(factor_pca, asset.name="VTI", 
     which.plot.single=8, 
     plot.single=TRUE, loop=FALSE, 
     xlim=c(-0.007, 0.007))
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/fact_resid_hist-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Residual Returns \texttt{Q-Q} Plot}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_qq,eval=FALSE,echo=(-1),fig.width=7,fig.height=6,fig.show='hide'>>=
library(PortfolioAnalytics)
# residual Q-Q plot
plot(factor_pca, asset.name="VTI", 
     which.plot.single=9, 
     plot.single=TRUE, loop=FALSE)
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/fact_resid_qq-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Autocorrelation of Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \vspace{-1em}
      <<fact_resid_autocorr,eval=FALSE,echo=TRUE,fig.width=7,fig.height=9,fig.show='hide'>>=
# SACF and PACF of residuals
plot(factor_pca, asset.name="VTI", 
     which.plot.single=5, 
     plot.single=TRUE, loop=FALSE)
      @
    \column{0.6\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/fact_resid_autocorr-1}
  \end{columns}
\end{block}

\end{frame}



\end{document}
