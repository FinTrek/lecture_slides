% FRE6871_Lecture_6

% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size='scriptsize', fig.width=4, fig.height=4)
options(width=60, dev='pdf')
options(digits=3)
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@
  
  
% Define document options
\documentclass[10pt]{beamer}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
% \usepackage{mathtools}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape,bg=red,fg=red}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}


% Title page setup
\title[FRE6871 Lecture\#6]{FRE6871 \texttt{R} in Finance}
\subtitle{Lecture\#6, Fall 2016}
% \subject{Getting Started With R}
\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@poly.edu}
\date{October 17, 2016}
% \date{\today}
% \pgfdeclareimage[height=0.5cm]{university-logo}{engineering_long_white}
% \logo{\pgfuseimage{engineering_long_white}}


%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle


%%%%%%%%%%%%%%%
\section{Classification}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Logistic} Function}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{logistic} function expresses the cumulative probability of a numerical variable ranging over the whole interval of real numbers: 
      \begin{displaymath}
        p(x) = \frac{1}{1 + \exp(-\lambda x)}
      \end{displaymath}
      Where $\lambda$ is the scale (dispersion) parameter,
      \vskip1ex
      The \emph{logistic} function can be inverted to obtain the \emph{Odds Ratio} (the ratio of probabilities for favorable to unfavorable outcomes): 
      \begin{displaymath}
        \frac{p(x)}{1 - p(x)} = \exp(\lambda x)
      \end{displaymath}
      The function \texttt{plogis()} gives the cumulative probability of the \emph{Logistic} distribution, 
        <<echo=(-(1:1)),eval=FALSE>>=
par(oma=c(1, 1, 1, 1), mar=c(2, 1, 1, 1), mgp=c(2, 1, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
lamb_da <- c(0.5, 1, 1.5)
col_ors <- c("red", "black", "blue")
# plot three curves in loop
for (in_dex in 1:3) {
  curve(expr=plogis(x, scale=lamb_da[in_dex]),
        xlim=c(-4, 4), type="l", 
        xlab="", ylab="", lwd=2,
        col=col_ors[in_dex], add=(in_dex>1))
}  # end for
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/logistic_func.png}
      \vspace{-2em}
        <<echo=TRUE,eval=FALSE>>=
# add title
title(main="Logistic function", line=0.5)
# add legend
legend("topleft", title="Scale parameters", 
       paste("lambda", lamb_da, sep="="),
       inset=0.05, cex=0.8, lwd=2, 
       lty=c(1, 1, 1), col=col_ors)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Performing \protect\emph{Logistic} Regression Using the Function \texttt{glm()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Linear} regression isn't suitable when the response variable represents categorical data (\texttt{factor}), 
      \vskip1ex
      But \emph{logistic} regression (\emph{logit}) can be used to model data with a categorical response variable, 
      \vskip1ex
      The function \texttt{glm()} fits generalized linear models, including \emph{logistic} regressions, 
      \vskip1ex
      \texttt{glm()} can fit two different types of response variables: categorical data (\texttt{factors}) from individual observations, or counts of categorical data (\texttt{integers}) from groups of observations, 
      \vskip1ex
      The family object \texttt{binomial(link="logit")} specifies a binomial distribution of residuals in the \emph{logistic} regression model, 
      <<echo=TRUE,eval=FALSE>>=
# simulate categorical data
sco_re <- sort(runif(100))
thresh_old <- 0.5  # probability threshold
ac_tive <- ((sco_re + rnorm(100, sd=0.1)) > thresh_old)
# Wilcoxon test for sco_re predictor
wilcox.test(sco_re[ac_tive], sco_re[!ac_tive])
# perform logit regression
log_it <- glm(ac_tive ~ sco_re, family=binomial(logit))
summary(log_it)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/logistic_density.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
plot(x=sco_re, y=log_it$fitted.values, type="l", lwd=3, 
     main="Category densities and logistic function", 
     xlab="score", ylab="probability")
den_sity <- density(sco_re[ac_tive])
den_sity$y <- den_sity$y/max(den_sity$y)
lines(den_sity, col="red")
polygon(c(min(den_sity$x), den_sity$x, max(den_sity$x)), c(min(den_sity$y), den_sity$y, min(den_sity$y)), col=rgb(1, 0, 0, 0.2), border=NA)
den_sity <- density(sco_re[!ac_tive])
den_sity$y <- den_sity$y/max(den_sity$y)
lines(den_sity, col="blue")
polygon(c(min(den_sity$x), den_sity$x, max(den_sity$x)), c(min(den_sity$y), den_sity$y, min(den_sity$y)), col=rgb(0, 0, 1, 0.2), border=NA)
# add legend
legend(x="top", bty="n", lty=c(1, NA, NA), lwd=c(3, NA, NA), pch=c(NA, 15, 15), 
       legend=c("logistic fit", "active", "non-active"),
       col=c("black", "red", "blue"), 
       text.col=c("black", "red", "blue"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package \texttt{ISLR} With Datasets for Machine Learning}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \texttt{ISLR} contains datasets used in the book \emph{"Introduction to Statistical Learning"}:\
      \fullcite{islbook}
    \column{0.5\textwidth}
      <<echo=TRUE,eval=FALSE>>=
library(ISLR)  # load package ISLR
# get documentation for package tseries
packageDescription("ISLR")  # get short description

help(package="ISLR")  # load help page

library(ISLR)  # load package ISLR

data(package="ISLR")  # list all datasets in ISLR

ls("package:ISLR")  # list all objects in ISLR

detach("package:ISLR")  # remove ISLR from search path
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{Default} Dataset}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \texttt{Default} dataset is a data frame in package \texttt{ISLR}, with credit default data, 
      \vskip1ex
      The \texttt{Default} data frame contains two columns of binary categorical data (\texttt{factors}): \texttt{default} and \texttt{student}, and two columns of numerical data: \texttt{balance} and \texttt{income}, 
      \vskip1ex
      The columns \texttt{student}, \texttt{balance}, and \texttt{income} can be used as \emph{predictors} to predict the \texttt{default} column, 
      <<echo=TRUE,eval=FALSE>>=
library(ISLR)  # load package ISLR
# load credit default data
attach(Default)
summary(Default)
sapply(Default, class)
dim(Default); head(Default)
x_lim <- range(balance)
y_lim <- range(income)
# plot data points for non-defaulters
default_ed <- (default=="Yes")
plot(income ~ balance, 
     main="Default dataset from package ISLR", 
     xlim=x_lim, ylim=y_lim, 
     data=Default[!default_ed, ], 
     pch=4, col="blue")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/islr_default_data.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# plot data points for defaulters
points(income ~ balance, 
       data=Default[default_ed, ], 
       pch=4, col="red")
# add legend
legend(x="topright", bty="n", 
       legend=c("non-defaulters", "defaulters"),
       col=c("blue", "red"), lty=1, pch=4)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Boxplots of the \texttt{Default} Dataset}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A \emph{Box Plot} (box-and-whisker plot) is a graphical display of a distribution of values, 
      \vskip1ex
      The \emph{box} represents the upper and lower quartiles, \\
      the vertical lines (whiskers) represent values beyond the quartiles, \\
      and open circles represent values beyond the nominal range (outliers),
      \vskip1ex
      The function \texttt{boxplot()} plots a box-and-whisker plot for a distribution of values,
      \vskip1ex
      \texttt{boxplot()} has two \texttt{methods}: one for \texttt{formula} objects (involving categorical variables), and another for \texttt{data frames},
      \vskip1ex
      The \emph{Wilcoxon} test shows that the \texttt{balance} column provides a strong separation between defaulters and non-defaulters, but the \texttt{income} column doesn't, 
      <<echo=TRUE,eval=FALSE>>=
default_ed <- (default=="Yes")
# Wilcoxon test for balance predictor
wilcox.test(balance[default_ed], balance[!default_ed])
# Wilcoxon test for income predictor
wilcox.test(income[default_ed], income[!default_ed])
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/islr_default_boxplot.png}
      \vspace{-2em}
      <<echo=(-(1:2)),eval=FALSE>>=
library(ISLR)  # load package ISLR
attach(Default)  # load credit default data
par(mfrow=c(1,2))  # set plot panels
# balance boxplot
boxplot(formula=balance ~ default, 
        col="lightgrey", 
        main="balance", xlab="default")
# income boxplot
boxplot(formula=income ~ default, 
        col="lightgrey", 
        main="income", xlab="default")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Modeling Credit Defaults Using \protect\emph{Logistic} Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \texttt{balance} column can be used to calculate the probability of default using \emph{logistic} regression, 
      \vskip1ex
      The residuals in \emph{logistic} regression are the differences betweeen the actual response values (\texttt{0} and \texttt{1}), and the calculated probabilities of default, 
      \vskip1ex
      The \emph{logit} residuals are not normally distributed, so the data is fitted using the \emph{maximum-likelihood} method, instead of least squares, 
      \vskip1ex
      The family object \texttt{binomial(link="logit")} specifies a binomial distribution of residuals in the \emph{logistic} regression model, 
      <<echo=TRUE,eval=FALSE>>=
# fit logistic regression model
log_it <- glm(default ~ balance, 
              family=binomial(logit))
summary(log_it)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/islr_logistic_reg.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
plot(x=balance, y=default_ed, 
     main="Logistic regression of credit defaults", col="orange", 
     xlab="credit balance", ylab="defaults")
or_der <- order(balance)
lines(x=balance[or_der], y=log_it$fitted.values[or_der], 
      col="blue", lwd=2)
legend(x="topleft", inset=0.1, 
       legend=c("defaults", "logit fitted values"),
       col=c("orange", "blue"), lty=c(NA, 1), pch=c(1, NA), lwd=c(3, 3))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Modeling Cumulative Defaults Using \protect\emph{Logistic} Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The cumulative count of defaults with respect to a single predictor can be modelled as a \emph{logistic} function, using the function \texttt{glm()}, 
      \vskip1ex
      The response variable should be specified as a matrix with two columns, one containing the number of defaults, and other the number of non-defaults, 
      <<echo=(-(1:2)),eval=FALSE>>=
library(ISLR)  # load package ISLR
attach(Default)  # load credit default data
# calculate cumulative defaults
default_ed <- (default=="Yes")
to_tal <- sum(default_ed)
default_s <- sapply(balance, function(ba_lance) {
    sum(default_ed[balance <= ba_lance])
})  # end sapply
# perform logit regression
log_it <- glm(
  cbind(default_s, to_tal-default_s) ~ 
    balance, 
  family=binomial(logit))
summary(log_it)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/islr_logistic_count.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
plot(x=balance, y=default_s/to_tal, col="orange", lwd=1, 
     main="Cumulative defaults versus balance", 
     xlab="credit balance", ylab="cumulative defaults")
or_der <- order(balance)
lines(x=balance[or_der], y=log_it$fitted.values[or_der], 
      col="blue", lwd=2)
legend(x="topleft", inset=0.1, 
       legend=c("cumulative defaults", "fitted values"),
       col=c("orange", "blue"), lty=c(NA, 1), pch=c(1, NA), lwd=c(3, 3))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Multifactor \protect\emph{Logistic} Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Logistic} regression calculates the probability of categorical variables, from the \emph{Odds Ratio} of continuous explanatory variables: 
      \begin{displaymath}
        p = \frac{1}{1 + \exp(- \lambda_0 - \sum_{i=1}^{n} \lambda_i x_i)}
      \end{displaymath}
      The \emph{generic} function \texttt{summary()} produces a list of regression model summary and diagnostic statistics:
      \begin{itemize}
        \item coefficients: matrix with estimated coefficients, their \emph{z}-values, and \emph{p}-values, 
        \item \emph{Null} deviance: measures the differences betweeen the response values and the probabilities calculated using only the intercept, 
        \item \emph{Residual} deviance: measures the differences betweeen the response values and the model probabilities, 
      \end{itemize}
      The \texttt{balance} and \texttt{student} columns are statistically significant, but the \texttt{income} column is not, 
    \column{0.5\textwidth}
      \vspace{-2em}
      <<echo=(-(1:3)),eval=TRUE>>=
library(ISLR)  # load package ISLR
attach(Default)  # load credit default data
# fit multifactor logistic regression model
col_names <- colnames(Default)
for_mula <- as.formula(paste(col_names[1], 
  paste(col_names[-1], collapse="+"), sep=" ~ "))
log_it <- glm(for_mula, data=Default, 
              family=binomial(logit))
summary(log_it)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Confounding Variables in Multifactor \protect\emph{Logistic} Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \texttt{student} column is a confounding variable since it's correlated with the \texttt{balance} column, 
      \vskip1ex
      Students are less likely to default than non-students with the same \texttt{balance}, 
      \vskip1ex
      But on average students have higher \texttt{balances} than non-students, which makes them more likely to default, 
      \vskip1ex
      That's why the multifactor regression coefficient for \texttt{student} is negative, while the single factor coefficient for \texttt{student} is positive, 
      <<echo=(-(1:2)),eval=FALSE>>=
library(ISLR)  # load package ISLR
attach(Default)  # load credit default data
default_ed <- (default=="Yes")
stu_dent <- (student=="Yes")
# calculate cumulative defaults
default_s <- sapply(balance, 
  function(ba_lance) {
    c(stu_dent=sum(default_ed[stu_dent & (balance <= ba_lance)]), 
      non_student=sum(default_ed[(!stu_dent) & (balance <= ba_lance)]))
})  # end sapply
to_tal <- c(sum(default_ed[stu_dent]), sum(default_ed[!stu_dent]))
default_s <- t(default_s / to_tal)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/islr_student_boxplot.png}
      \vspace{-2em}
      <<echo=(-(1:2)),eval=FALSE>>=
library(ISLR)  # load package ISLR
attach(Default)  # load credit default data
# plot cumulative defaults
par(mfrow=c(1,2))  # set plot panels
or_der <- order(balance)
plot(x=balance[or_der], y=default_s[or_der, 1], 
     col="red", t="l", lwd=2, 
     main="Cumulative defaults of\n students and non-students", 
     xlab="credit balance", ylab="")
lines(x=balance[or_der], y=default_s[or_der, 2], 
      col="blue", lwd=2)
legend(x="topleft", bty="n", 
       legend=c("students", "non-students"),
       col=c("red", "blue"), text.col=c("red", "blue"), 
       lwd=c(3, 3))
# balance boxplot for student factor
boxplot(formula=balance ~ student, 
        col="lightgrey", 
        main="balance", xlab="student")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Forecasting of Credit Defaults using Logistic Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{predict()} is a generic function for forecasting based on a given model,
      \vskip1ex
      \emph{Logistic} regression calculates the probability of categorical variables, based on continuous explanatory variables, 
      \vskip1ex
      A \emph{type I error} is the incorrect rejection of a \texttt{TRUE} case (i.e. a "false positive"), 
      \vskip1ex
      That is, a \emph{type I error} is when there is no default, but it's classified as a default, 
      \vskip1ex
      A \emph{type II error} is the incorrect acceptance of a \texttt{FALSE} case (i.e. a "false negative"), 
      \vskip1ex
      That is, a \emph{type II error} is when there is a default, but it's classified as no default, 
      \vskip1ex
      A confusion matrix is a table that summarizes the performance of a classification model on a set of test data for which the true values are known, 
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# fit full logistic regression model
for_mula <- default ~ balance
for_mula <- as.formula(paste(col_names[1], 
  paste(col_names[-1], collapse="+"), sep=" ~ "))
log_it <- glm(for_mula, data=Default, 
              family=binomial(logit))
fore_casts <- predict(log_it, type="response")
length(fore_casts)
fore_casts[1:10]
thresh_old <- 0.5  # probability threshold
# calculate confusion matrix
table((fore_casts>thresh_old), default_ed)
sum(default_ed)

# fit logistic regression over training data
sam_ple <- sample(x=1:NROW(Default), size=NROW(Default)/2)
train_data <- Default[sam_ple, ]
log_it <- glm(for_mula, data=train_data, 
              family=binomial(link="logit"))

# forecast over test data
test_data <- Default[-sam_ple, ]
fore_casts <- predict(log_it, newdata=test_data, type="response")
# calculate confusion matrix
table((fore_casts>thresh_old), test_data$default=="Yes")
detach(Default)
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Homework Assignment}


%%%%%%%%%%%%%%%
\subsection{Homework Assignment}
\begin{frame}[t]{\subsecname}
\vspace{-1em}
\begin{block}{Required}
  Read all the lecture slides in \texttt{FRE6871\_Lecture\_6.pdf}, and run all the code in \texttt{FRE6871\_Lecture\_6.R}
\end{block}
\begin{block}{Recommended}
  Read about \emph{Logistic Regression} in the book \emph{"Introduction to Statistical Learning"}:\
      \fullcite{islbook}
\end{block}

\end{frame}


\end{document}
