% FRE6871_Lecture_6
% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size='scriptsize', fig.width=4, fig.height=4)
options(width=60, dev='pdf')
options(digits=3)
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[10pt]{beamer}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{array}
\usepackage{multirow}
\usepackage{mathtools}
% bbold package for unitary vector or matrix symbol
\usepackage{bbold}
% bbm package for unitary vector or matrix symbol
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
\usepackage{listings}
\usepackage{xcolor}
\definecolor{anti_flashwhite}{rgb}{0.95, 0.95, 0.96}
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}


% Title page setup
\title[FRE6871 Lecture\#6]{FRE6871 \texttt{R} in Finance}
\subtitle{Lecture\#6, Spring 2019}

\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@poly.edu}
\date{May 13, 2019}
% \date{\today}
% \pgfdeclareimage[height=0.5cm]{university-logo}{engineering_long_white}
% \logo{\pgfuseimage{engineering_long_white}}


%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle


%%%%%%%%%%%%%%%
\section{Robust Estimation}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Kolmogorov-Smirnov} Test for Probability Distributions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Kolmogorov-Smirnov} test is designed to test the \emph{null hypothesis} that two samples: $\{x_1, \ldots , x_n\}$ and $\{y_1, \ldots , y_n\}$ were obtained from the same probability distribution,
      \vskip1ex
      The \emph{Kolmogorov-Smirnov} statistic is the maximum difference between two empirical cumulative distribution functions (cumulative frequencies):
      \begin{displaymath}
        D = \sup_i | P(x_i) - P(y_i) |
      \end{displaymath}
      The function \texttt{ks.test()} calculates the \emph{Kolmogorov-Smirnov} statistic and its \emph{p}-value,
      \vskip1ex
      The second argument is either a \texttt{numeric} vector of data values, or a name of a cumulative distribution function,
      \vskip1ex
      The \emph{Kolmogorov-Smirnov} test can be used as a \emph{goodness of fit} test, to test if a set of observations fits a probability distribution,
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# KS-test for normal distribution
ks.test(rnorm(100), pnorm)
# KS-test for uniform distribution
ks.test(runif(100), pnorm)
# KS-test for two similar normal distributions
ks.test(rnorm(100), rnorm(100, mean=0.1))
# KS-test for two different normal distributions
ks.test(rnorm(100), rnorm(100, mean=1.0))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Student's t-test} for the Distribution Mean}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Student's t-test} is designed to test the \emph{null hypothesis} that a sample: $\{x_1, \ldots , x_n\}$ was obtained from a normal distribution with a \emph{mean} equal to $\mu$. 
      \vskip1ex
      The test statistic is equal to the \emph{t-ratio}:
      \begin{displaymath}
        t = \frac{\bar{x} - \mu}{\hat\sigma / \sqrt{n}}
      \end{displaymath}
      Where $\bar{x}=\frac{1}{n} \sum_{i=1}^n x_i$ is the sample mean and $\hat\sigma^2=\frac{1}{n-1} \sum_{i=1}^n (x_i-\bar{x})^2$ is the sample variance,
      \vskip1ex
      Under the \emph{null hypothesis} the \emph{t-ratio} follows the \emph{t-distribution} with $n$ degrees of freedom, with the probability density function: 
      \begin{displaymath}
        P(x) = \frac{\Gamma((n+1)/2)}{\sqrt{\pi n} \, \Gamma(n/2)} \, (1 + x^2/n)^{-(n+1)/2}
      \end{displaymath}
      \emph{Student's t-test} can also be used to test if two different normally distributed samples have equal \emph{population means},
      \vskip1ex
      \emph{Student's t-test} is not valid for random variables that do not follow the normal distribution.
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/t_dist_norm.png}\\
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# t-test for single sample
t.test(rnorm(100))
# t-test for two samples
t.test(rnorm(100),
       rnorm(100, mean=1))
# Plot the normal and t-distribution densities
x11(width=6, height=5)
par(mar=c(3, 3, 3, 1), oma=c(0, 0, 0, 0))
curve(expr=dnorm, xlim=c(-4, 4),
      xlab="", ylab="", lwd=3)
curve(expr=dt(x, df=3),
      xlab="", ylab="", lwd=3,
      col="red", add=TRUE)
# Add title
title(main="Normal and t-distribution densities", line=0.5)
# Add legend
legend("topright", inset=0.05, bty="n",
       title=NULL, c("normal", "t-dist"),
       cex=0.8, lwd=6, lty=1,
       col=c("black", "red"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Wilcoxon} Test for the Distribution Mean}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Wilcoxon} test is designed to test the \emph{null hypothesis} that two samples: $\{x_1, \ldots , x_n\}$ and $\{y_1, \ldots , y_n\}$ were obtained from two probability distributions with equal \emph{population means}.
      \vskip1ex
      The function \texttt{wilcox.test()} calculates the \emph{Wilcoxon} statistic and its \emph{p}-value.
      \vskip1ex
      If a single sample is passed into \texttt{wilcox.test()} then it tests if the data was produced by a probability distribution with zero mean.
      \vskip1ex
      For many distributions, the \emph{Wilcoxon} test has greater \emph{sensitivity} than the \emph{Student's t-test}.
      \vskip1ex
      The \emph{sensitivity} of a statistical test is the ability to correctly identify \emph{true positive} cases (when the null hypothesis is \texttt{FALSE}).
      \vskip1ex
      The \emph{specificity} of a statistical test is the ability to correctly identify \emph{true negative} cases (when the null hypothesis is \texttt{TRUE}).
      \vskip1ex
      The \emph{Wilcoxon} test is also more \emph{robust} with respect to data outliers, iie. it reports fewer \emph{false positive} cases when there are outliers in the data.
      \vskip1ex
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Wilcoxon test for normal distribution
wilcox.test(rnorm(100))
# Wilcoxon test for two normal distributions
sample1 <- rnorm(100)
sample2 <- rnorm(100, mean=0.1)
wilcox.test(sample1, sample2)$p.value
t.test(sample1, sample2)$p.value
# Wilcoxon test with data outliers
sample2 <- sample1
sample2[1:11] <- sample2[1:11] + 5
wilcox.test(sample1, sample2)$p.value
t.test(sample1, sample2)$p.value
# Wilcoxon test for two normal distributions
wilcox.test(rnorm(100), rnorm(100, mean=1.0))
# Wilcoxon test for a uniform versus normal distribution
wilcox.test(runif(100)-0.5, rnorm(100))
# Wilcoxon test for a uniform versus normal distribution
wilcox.test(runif(100), rnorm(100))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{W} statistic of the \protect\emph{Wilcoxon} Test}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Wilcoxon} test statistic \emph{W} is equal to the sum of the ranks $r_i = \operatorname{rank}(|x_i - y_i|)$ of the absolute differences $|x_i - y_i|$ weighted by their signs:
      \begin{displaymath}
        W = \sum _{i=1}^n \operatorname{sgn}(x_i - y_i) r_i
      \end{displaymath}
      The \emph{Wilcoxon} test statistic \emph{W} follows a distribution without a simple formula, which converges to the normal distribution for large sample size $n$, with an expected value equal to $0$ and a variance equal to $\frac{n(n+1)(2n+1)}{6}$.
      \vskip1ex
      The \emph{Wilcoxon} test sums the ranks $r_i = \operatorname{rank}(|x_i - y_i|)$ of the sample differences $(x_i - y_i)$, not the differences themselves, so it's \emph{robust} with respect to data outliers.
      \vskip1ex
      The \emph{Wilcoxon} test doesn't assume that the sample is taken from the \emph{normal} distribution (as \emph{Student's t-test} does), or from any other distribution, so it's considered to be \emph{nonparametric}.
      \vskip1ex
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Wilcoxon test for random data around 0
n_row <- 1e3
da_ta <- (runif(n_row) - 0.5)
wil_cox <- wilcox.test(da_ta)
# Calculate V statistic of Wilcoxon test
wil_cox$statistic
sum(rank(abs(da_ta))[da_ta>0])
# Calculate W statistic of Wilcoxon test
sum(sign(da_ta)*rank(abs(da_ta)))
# Calculate distributon of Wilcoxon W statistic
wilcox_w <- sapply(1:1e3, function(x) {
  da_ta <- (runif(n_row) - 0.5)
  sum(sign(da_ta)*rank(abs(da_ta)))
})  # end sapply
wilcox_w <- wilcox_w/sqrt(n_row*(n_row+1)*(2*n_row+1)/6)
var(wilcox_w)
hist(wilcox_w)
      @
      \vspace{-1em}
      The function \texttt{wilcox.test()} returns the \emph{V} statistic, not the the \emph{W} statistic:       \begin{displaymath}
        V = \sum _{i=1}^n \operatorname{H}(x_i - y_i) r_i
      \end{displaymath}
      Where $\operatorname{H}(x) = 1$ if $x > 0$, and $0$ otherwise.
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Classification}


%%%%%%%%%%%%%%%
\subsection{The \protect\emph{Logistic} Function}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{logistic} function expresses the probability of a numerical variable ranging over the whole interval of real numbers:
      \begin{displaymath}
        p(x) = \frac{1}{1 + \exp(-\lambda x)}
      \end{displaymath}
      Where $\lambda$ is the scale (dispersion) parameter,
      \vskip1ex
      The \emph{logistic} function can be inverted to obtain the \emph{Odds Ratio} (the ratio of probabilities for favorable to unfavorable outcomes):
      \begin{displaymath}
        \frac{p(x)}{1 - p(x)} = \exp(\lambda x)
      \end{displaymath}
      The function \texttt{plogis()} gives the cumulative probability of the \emph{Logistic} distribution,
        <<echo=(-(1:1)),eval=FALSE>>=
par(oma=c(1, 1, 1, 1), mar=c(2, 1, 1, 1), mgp=c(2, 1, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
lamb_da <- c(0.5, 1, 1.5)
col_ors <- c("red", "blue", "green")
# Plot three curves in loop
for (in_dex in 1:3) {
  curve(expr=plogis(x, scale=lamb_da[in_dex]),
        xlim=c(-4, 4), type="l",
        xlab="", ylab="", lwd=4,
        col=col_ors[in_dex], add=(in_dex>1))
}  # end for
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/logistic_func.png}
      \vspace{-2em}
        <<echo=TRUE,eval=FALSE>>=
# Add title
title(main="Logistic function", line=0.5)
# Add legend
legend("topleft", title="Scale parameters",
       paste("lambda", lamb_da, sep="="),
       inset=0.05, cex=0.8, lwd=6, bty="n",
       lty=1, col=col_ors)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Performing \protect\emph{Logistic} Regression Using the Function \texttt{glm()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Linear} regression isn't suitable when the response variable is categorical data (\texttt{factor}),
      \vskip1ex
      But \emph{logistic} regression (\emph{logit}) can be used to model data with a categorical response variable,
      \vskip1ex
      The function \texttt{glm()} fits generalized linear models, including \emph{logistic} regressions,
      \vskip1ex
      \texttt{glm()} can fit two different types of response variables: categorical data (\texttt{factors}) from individual observations, or counts of categorical data (\texttt{integers}) from groups of observations,
      \vskip1ex
      The family object \texttt{binomial(link="logit")} specifies a binomial distribution of residuals,
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
set.seed(1121)
# Simulate overlapping scores data
sample1 <- runif(100, max=0.6)
sample2 <- runif(100, min=0.4)
# Perform Wilcoxon test for mean
wilcox.test(sample1, sample2)
# Combine scores and add categorical variable
predic_tor <- c(sample1, sample2)
res_ponse <- c(logical(100), !logical(100))
# Perform logit regression
g_lm <- glm(res_ponse ~ predic_tor, family=binomial(logit))
class(g_lm)
summary(g_lm)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/logistic_density.png}
      \vspace{-2em}
      <<echo=(-(1:2)),eval=FALSE>>=
x11(width=7, height=5)
par(mar=c(3, 3, 2, 2), mgp=c(2, 1, 0), oma=c(0, 0, 0, 0))
or_der <- order(predic_tor)
plot(x=predic_tor[or_der], y=g_lm$fitted.values[or_der], 
     type="l", lwd=4, col="orange",
     main="Category Densities and Logistic Function",
     xlab="score", ylab="density")
den_sity <- density(predic_tor[res_ponse])
den_sity$y <- den_sity$y/max(den_sity$y)
lines(den_sity, col="red")
polygon(c(min(den_sity$x), den_sity$x, max(den_sity$x)), c(min(den_sity$y), den_sity$y, min(den_sity$y)), col=rgb(1, 0, 0, 0.2), border=NA)
den_sity <- density(predic_tor[!res_ponse])
den_sity$y <- den_sity$y/max(den_sity$y)
lines(den_sity, col="blue")
polygon(c(min(den_sity$x), den_sity$x, max(den_sity$x)), c(min(den_sity$y), den_sity$y, min(den_sity$y)), col=rgb(0, 0, 1, 0.2), border=NA)
# Add legend
legend(x="top", cex=1.0, bty="n", lty=c(1, NA, NA), 
       lwd=c(6, NA, NA), pch=c(NA, 15, 15),
       legend=c("logistic fit", "TRUE", "FALSE"),
       col=c("orange", "red", "blue"), 
       text.col=c("black", "red", "blue"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package \protect\emph{ISLR} With Datasets for Machine Learning}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \emph{ISLR} contains datasets used in the book \emph{"Introduction to Statistical Learning"}:\
      \fullcite{islbook}
    \column{0.5\textwidth}
      <<echo=TRUE,eval=FALSE>>=
library(ISLR)  # load package ISLR
# get documentation for package tseries
packageDescription("ISLR")  # get short description

help(package="ISLR")  # load help page

library(ISLR)  # load package ISLR

data(package="ISLR")  # list all datasets in ISLR

ls("package:ISLR")  # list all objects in ISLR

detach("package:ISLR")  # Remove ISLR from search path
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{Default} Dataset}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \texttt{Default} dataset is a data frame in package \emph{ISLR}, with credit default data,
      \vskip1ex
      The \texttt{Default} data frame contains two columns of binary categorical data (\texttt{factors}): \texttt{default} and \texttt{student}, and two columns of numerical data: \texttt{balance} and \texttt{income},
      \vskip1ex
      The columns \texttt{student}, \texttt{balance}, and \texttt{income} can be used as \emph{predictors} to predict the \texttt{default} column,
      <<echo=TRUE,eval=FALSE>>=
library(ISLR)  # load package ISLR
# load credit default data
attach(Default)
summary(Default)
sapply(Default, class)
dim(Default); head(Default)
x_lim <- range(balance)
y_lim <- range(income)
# Plot data points for non-defaulters
default_ed <- (default=="Yes")
plot(income ~ balance,
     main="Default Dataset from Package ISLR",
     xlim=x_lim, ylim=y_lim,
     data=Default[!default_ed, ],
     pch=4, col="blue")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/islr_default_data.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Plot data points for defaulters
points(income ~ balance,
       data=Default[default_ed, ],
       pch=4, lwd=2, col="red")
# Add legend
legend(x="topright", bty="n",
       legend=c("non-defaulters", "defaulters"),
       col=c("blue", "red"), lty=1, lwd=6, pch=4)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Boxplots of the \texttt{Default} Dataset}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A \emph{Box Plot} (box-and-whisker plot) is a graphical display of a distribution of values,
      \vskip1ex
      The \emph{box} represents the upper and lower quartiles, \\
      the vertical lines (whiskers) represent values beyond the quartiles, \\
      and open circles represent values beyond the nominal range (outliers),
      \vskip1ex
      The function \texttt{boxplot()} plots a box-and-whisker plot for a distribution of values,
      \vskip1ex
      \texttt{boxplot()} has two \texttt{methods}: one for \texttt{formula} objects (involving categorical variables), and another for \texttt{data frames},
      \vskip1ex
      The \emph{Wilcoxon} test shows that the \texttt{balance} column provides a strong separation between defaulters and non-defaulters, but the \texttt{income} column doesn't,
      <<echo=TRUE,eval=FALSE>>=
default_ed <- (default=="Yes")
# Wilcoxon test for balance predictor
wilcox.test(balance[default_ed], balance[!default_ed])
# Wilcoxon test for income predictor
wilcox.test(income[default_ed], income[!default_ed])
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/islr_default_boxplot.png}
      \vspace{-2em}
      <<echo=(-(1:2)),eval=FALSE>>=
library(ISLR)  # load package ISLR
attach(Default)  # load credit default data
par(mfrow=c(1,2))  # Set plot panels
# balance boxplot
boxplot(formula=balance ~ default,
        col="lightgrey",
        main="balance", xlab="default")
# income boxplot
boxplot(formula=income ~ default,
        col="lightgrey",
        main="income", xlab="default")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Modeling Credit Defaults Using \protect\emph{Logistic} Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \texttt{balance} column can be used to calculate the probability of default using \emph{logistic} regression,
      \vskip1ex
      The residuals in \emph{logistic} regression are the differences betweeen the actual response values (\texttt{0} and \texttt{1}), and the calculated probabilities of default,
      \vskip1ex
      The \emph{logit} residuals are not normally distributed, so the data is fitted using the \emph{maximum-likelihood} method, instead of least squares,
      \vskip1ex
      The family object \texttt{binomial(link="logit")} specifies a binomial distribution of residuals in the \emph{logistic} regression model,
      <<echo=TRUE,eval=FALSE>>=
# fit logistic regression model
g_lm <- glm(default ~ balance,
              family=binomial(logit))
class(g_lm)
summary(g_lm)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/islr_logistic_reg.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
plot(x=balance, y=default_ed,
     main="Logistic Regression of Credit Defaults", col="orange",
     xlab="credit balance", ylab="defaults")
or_der <- order(balance)
lines(x=balance[or_der], y=g_lm$fitted.values[or_der],
      col="blue", lwd=3)
legend(x="topleft", inset=0.1, bty="n",
       legend=c("defaults", "logit fitted values"),
       col=c("orange", "blue"), lty=c(NA, 1), pch=c(1, NA), lwd=6)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Modeling Cumulative Defaults Using \protect\emph{Logistic} Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{glm()} can model a \emph{logistic} regression using either a \texttt{Boolean} response variable, or using a response variable specified as a frequency, 
      \vskip1ex
      In the second case, the response variable should be defined as a two-column matrix, with the cumulative frequency of success (\texttt{TRUE}) and a cumulative frequency of failure (\texttt{FALSE}),
      \vskip1ex
      These two different ways of specifying the \emph{logistic} regression are related, but they are not equivalent, because they have different error terms,
      <<echo=(-(1:2)),eval=FALSE>>=
library(ISLR)  # load package ISLR
attach(Default)  # load credit default data
# Calculate cumulative defaults
default_ed <- (default=="Yes")
to_tal <- sum(default_ed)
default_s <- sapply(balance, function(ba_lance) {
    sum(default_ed[balance <= ba_lance])
})  # end sapply
# Perform logit regression
g_lm <- glm(
  cbind(default_s, to_tal-default_s) ~
    balance,
  family=binomial(logit))
summary(g_lm)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/islr_logistic_count.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
plot(x=balance, y=default_s/to_tal, col="orange", lwd=1,
     main="Cumulative Defaults Versus Balance",
     xlab="credit balance", ylab="cumulative defaults")
or_der <- order(balance)
lines(x=balance[or_der], y=g_lm$fitted.values[or_der],
      col="blue", lwd=3)
legend(x="topleft", inset=0.1, bty="n",
       legend=c("cumulative defaults", "fitted values"),
       col=c("orange", "blue"), lty=c(NA, 1), pch=c(1, NA), lwd=6)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Multifactor \protect\emph{Logistic} Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Logistic} regression calculates the probability of categorical variables, from the \emph{Odds Ratio} of continuous \emph{predictors}:
      \begin{displaymath}
        p = \frac{1}{1 + \exp(- \lambda_0 - \sum_{i=1}^n \lambda_i x_i)}
      \end{displaymath}
      The \emph{generic} function \texttt{summary()} produces a list of regression model summary and diagnostic statistics:
      \begin{itemize}
        \item coefficients: matrix with estimated coefficients, their \emph{z}-values, and \emph{p}-values,
        \item \emph{Null} deviance: measures the differences betweeen the response values and the probabilities calculated using only the intercept,
        \item \emph{Residual} deviance: measures the differences betweeen the response values and the model probabilities,
      \end{itemize}
      The \texttt{balance} and \texttt{student} columns are statistically significant, but the \texttt{income} column is not,
    \column{0.5\textwidth}
      \vspace{-2em}
      <<echo=(-(1:3)),eval=TRUE>>=
library(ISLR)  # load package ISLR
attach(Default)  # load credit default data
# fit multifactor logistic regression model
col_names <- colnames(Default)
for_mula <- as.formula(paste(col_names[1],
  paste(col_names[-1], collapse="+"), sep=" ~ "))
g_lm <- glm(for_mula, data=Default,
              family=binomial(logit))
summary(g_lm)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Confounding Variables in Multifactor \protect\emph{Logistic} Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \texttt{student} column is a confounding variable since it's correlated with the \texttt{balance} column,
      \vskip1ex
      Students are less likely to default than non-students with the same \texttt{balance},
      \vskip1ex
      But on average students have higher \texttt{balances} than non-students, which makes them more likely to default,
      \vskip1ex
      That's why the multifactor regression coefficient for \texttt{student} is negative, while the single factor coefficient for \texttt{student} is positive,
      <<echo=(-(1:2)),eval=FALSE>>=
library(ISLR)  # load package ISLR
attach(Default)  # load credit default data
default_ed <- (default=="Yes")
stu_dent <- (student=="Yes")
# Calculate cumulative defaults
default_s <- sapply(balance,
  function(ba_lance) {
    c(stu_dent=sum(default_ed[stu_dent & (balance <= ba_lance)]),
      non_student=sum(default_ed[(!stu_dent) & (balance <= ba_lance)]))
})  # end sapply
to_tal <- c(sum(default_ed[stu_dent]), sum(default_ed[!stu_dent]))
default_s <- t(default_s / to_tal)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/islr_student_boxplot.png}
      \vspace{-2em}
      <<echo=(-(1:2)),eval=FALSE>>=
library(ISLR)  # load package ISLR
attach(Default)  # load credit default data
# Plot cumulative defaults
par(mfrow=c(1,2))  # Set plot panels
or_der <- order(balance)
plot(x=balance[or_der], y=default_s[or_der, 1],
     col="red", t="l", lwd=2,
     main="Cumulative defaults of\n students and non-students",
     xlab="credit balance", ylab="")
lines(x=balance[or_der], y=default_s[or_der, 2],
      col="blue", lwd=2)
legend(x="topleft", bty="n",
       legend=c("students", "non-students"),
       col=c("red", "blue"), text.col=c("red", "blue"),
       lwd=3)
# balance boxplot for student factor
boxplot(formula=balance ~ student,
        col="lightgrey",
        main="balance", xlab="student")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Forecasting Credit Defaults using Logistic Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{predict()} is a generic function for forecasting based on a given model.
      \vskip1ex
      The method \texttt{predict.glm()} produces forecasts for a generalized linear model, in the form of probabilities for the \texttt{Boolean} response variable.
      \vskip1ex
      The \texttt{Boolean} forecasts are obtained by comparing the forecast probabilities with a discrimination threshold.
      \vskip1ex
      The null hypothesis is that \texttt{default="No"}.
      \vskip1ex
      A positive result corresponds to rejecting the null hypothesis, while a negative result corresponds to accepting the null hypothesis.
      \vskip1ex
      The forecasts are subject to two different types of errors: \emph{type I} and \emph{type II} errors.
      \vskip1ex
      A \emph{type I} error is the incorrect rejection of a \texttt{TRUE} null hypothesis (i.e. a "false positive"), for example, when there is no default, but it's forecast to be a default.
      \vskip1ex
      A \emph{type II} error is the incorrect acceptance of a \texttt{FALSE} null hypothesis (i.e. a "false negative"), for example, when there is a default, but it's forecast to be no default.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# fit multifactor logistic regression model
col_names <- colnames(Default)
for_mula <- as.formula(paste(col_names[1],
  paste(col_names[-1], collapse="+"), sep=" ~ "))
g_lm <- glm(for_mula, data=Default, family=binomial(logit))
fore_casts <- predict(g_lm, type="response")
fore_casts[1:6]
all.equal(g_lm$fitted.values, fore_casts)
# Discrimination threshold
thresh_old <- 0.05
# Calculate confusion matrix
table(default_ed, (fore_casts>thresh_old))
sum(default_ed)
sum(Default$default=="Yes")
# fit logistic regression over training data
set.seed(1121)  # Reset random number generator
n_rows <- NROW(Default)
sam_ple <- sample.int(n=n_rows, size=n_rows/2)
train_data <- Default[sam_ple, ]
g_lm <- glm(for_mula, data=train_data, family=binomial(link="logit"))
# forecast over test data
test_data <- Default[-sam_ple, ]
fore_casts <- predict(g_lm, newdata=test_data, type="response")
# Calculate confusion matrix
table(test_data$default=="No",
      (fore_casts<thresh_old))
# FALSE positive (type I error)
sum(test_data$default=="No" & (fore_casts>thresh_old))
# FALSE negative (type II error)
sum(test_data$default=="Yes" & (fore_casts<thresh_old))
detach(Default)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Confusion Matrix of a Classification Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The confusion matrix summarizes the performance of a classification model on a set of test data for which the true values are known.
      \vskip1ex
      The \emph{true positive} rate (known as the \emph{sensitivity}) is the fraction of \texttt{FALSE} null hypothesis cases that are correctly classified as \texttt{FALSE}.
      \vskip1ex
      The \emph{false negative} rate is the fraction of \texttt{FALSE} null hypothesis cases that are incorrectly classified as \texttt{TRUE} (\emph{type II} error).
      \vskip1ex
      The sum of the \emph{true positive} plus the \emph{false negative} rate is equal to \texttt{1}.
      \vskip1ex
      The \emph{true negative} rate (known as the \emph{specificity}) is the fraction of \texttt{TRUE} null hypothesis cases that are correctly classified as \texttt{TRUE}.
      \vskip1ex
      The \emph{false positive} rate is the fraction of \texttt{TRUE} null hypothesis cases that are incorrectly classified as \texttt{FALSE} (\emph{type I} error).
      \vskip1ex
      The sum of the \emph{true negative} plus the \emph{false positive} rate is equal to \texttt{1}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:12)),eval=TRUE>>=
library(ISLR)  # load package ISLR
attach(Default)  # load credit default data
col_names <- colnames(Default)
for_mula <- as.formula(paste(col_names[1], paste(col_names[-1], collapse="+"), sep=" ~ "))
set.seed(1121)  # Reset random number generator
n_rows <- NROW(Default)
sam_ple <- sample(x=1:n_rows, size=n_rows/2)
train_data <- Default[sam_ple, ]
g_lm <- glm(for_mula, data=train_data, family=binomial(link="logit"))
test_data <- Default[-sam_ple, ]
fore_casts <- predict(g_lm, newdata=test_data, type="response")
thresh_old <- 0.05
# Calculate confusion matrix
confu_sion <- table(test_data$default=="No",
                    (fore_casts<thresh_old))
dimnames(confu_sion) <- list(actual=rownames(confu_sion),
  forecast=colnames(confu_sion))
confu_sion
confu_sion <- confu_sion / rowSums(confu_sion)
c(typeI=confu_sion[2, 1], typeII=confu_sion[1, 2])
      @
      <<eval=FALSE,results='asis',echo=FALSE>>=
# below is an unsuccessful attempt to draw confusion matrix using xtable
confusion_matrix <- matrix(c("| true positive \\\\ (sensitivity)", "| false negative \\\\ (type II error)", "| false positive \\\\ (type I error)", "| true negative \\\\ (specificity)"), nc=2)
dimnames(confusion_matrix) <- list(forecast=c("FALSE", "TRUE"),
                                   actual=c("FALSE", "TRUE"))
print(xtable::xtable(confusion_matrix,
      caption="Confusion Matrix"),
      caption.placement="top",
      comment=FALSE, size="scriptsize",
      include.rownames=TRUE,
      include.colnames=TRUE)
# end unsuccessful attempt to draw confusion table using xtable
      @
      \newcommand\MyBox[2]{
        \fbox{\lower0.75cm
          \vbox to 1.2cm{\vfil
            \hbox to 1.7cm{\parbox{\textwidth}{#1\\#2}}
            \vfil}
        }
      }
      \renewcommand\arraystretch{0.3}
      \setlength\tabcolsep{0pt}
      \begin{tabular}{c >{\bfseries}r @{\hspace{0.5em}}c @{\hspace{0.4em}}c @{\hspace{0.5em}}l}
      \multirow{10}{*}{\parbox{0.5cm}{\bfseries Actual}} &
      & \multicolumn{2}{c}{\bfseries Forecast} & \\
      & & \bfseries FALSE & \bfseries TRUE \\
      & FALSE & \MyBox{True Positive}{(sensitivity)} & \MyBox{False Negative}{(type II error)} \\[2.4em]
      & TRUE & \MyBox{False Positive}{(type I error)} & \MyBox{True Negative}{(specificity)}
      \end{tabular}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Receiver Operating Characteristic (ROC) Curve}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The ROC curve is the plot of the \emph{true positive} rate, as a function of the \emph{false positive} rate, and illustrates the performance of a binary classifier,
      \vskip1ex
      The area under the ROC curve (AUC) is a measure of the performance of a binary classification model,
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Confusion matrix as function of thresh_old
con_fuse <- function(actu_al, fore_casts, thresh_old) {
    confu_sion <- table(actu_al, (fore_casts<thresh_old))
    confu_sion <- confu_sion / rowSums(confu_sion)
    c(typeI=confu_sion[2, 1], typeII=confu_sion[1, 2])
  }  # end con_fuse
con_fuse(test_data$default=="No", fore_casts, thresh_old=thresh_old)
# Define vector of discrimination thresholds
threshold_s <- seq(0.01, 0.95, by=0.01)^2
# Calculate error rates
error_rates <- sapply(threshold_s, con_fuse,
  actu_al=(test_data$default=="No"),
  fore_casts=fore_casts)  # end sapply
error_rates <- t(error_rates)
# Calculate area under ROC curve (AUC)
true_pos <- sort(1- c(error_rates[, "typeII"], 0))
true_pos <- (true_pos + rutils::lag_it(true_pos))/2
false_pos <- c(sort(error_rates[, "typeI"]), 1)
false_pos <- rutils::diff_it(false_pos)
sum(true_pos*false_pos)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/islr_defaults_roc.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Plot ROC Curve for Defaults
plot(x=error_rates[, "typeI"],
     y=1-error_rates[, "typeII"],
     xlab="FALSE positive rate",
     ylab="TRUE positive rate",
     main="ROC Curve for Defaults",
     type="l", lwd=3, col="blue")
abline(a=0.0, b=1.0, lwd=3, col="orange")
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Debugging and Exception Handling}


%%%%%%%%%%%%%%%
\subsection{Exception Conditions: Errors and Warnings}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Exception conditions} are \texttt{R} objects containing information about \emph{errors} or \emph{warnings} produced while evaluating expressions,
      \vskip1ex
      The function \texttt{warning()} produces a \emph{warning} condition, but doesn't halt function execution, and returns its message to the warning handler,
      \vskip1ex
      The function \texttt{stop()} produces an \emph{error} condition, halts function execution, and returns its message to the error handler,
      \vskip1ex
      The handling of \emph{warning} conditions depends on the value of \texttt{options("warn")}:
      \begin{itemize}
        \item \emph{negative} then warnings are ignored,
        \item \emph{zero} then warnings are stored and printed after the top-level function has completed,
        \item \emph{one} - warnings are printed as they occur,
        \item \emph{two} or larger - warnings are turned into errors,
      \end{itemize}
      The function \texttt{suppressWarnings()} evaluates its expressions and ignores all warnings,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# ?options  # get info on global options
getOption("warn")  # global option for "warn"
options("warn")  # global option for "warn"
getOption("error")  # global option for "error"
sqrt_safe <- function(in_put) {
# returns its argument
  if (in_put<0) {
    warning("sqrt_safe: in_put is negative")
    NULL  # return NULL for negative argument
  } else {
    sqrt(in_put)
  }  # end if
}  # end sqrt_safe
sqrt_safe(5)
sqrt_safe(-1)
options(warn=-1)
sqrt_safe(-1)
options(warn=0)
sqrt_safe()
options(warn=1)
sqrt_safe()
options(warn=3)
sqrt_safe()
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Validating Function Arguments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Argument validation consists of first determining if any arguments are \emph{missing}, and then determining if the arguments are of the correct \emph{type},
      \vskip1ex
      An argument is \emph{missing} when the formal argument is not bound to an actual value in the function call,
      \vskip1ex
      The function \texttt{missing()} returns \texttt{TRUE} if an argument is missing, and \texttt{FALSE} otherwise,
      \vskip1ex
      Missing arguments can be detected by:\\
      - assigning a \texttt{NULL} default value to formal arguments and then calling  \texttt{is.null()} on them,\\
      - calling the function \texttt{missing()} on the arguments,
      \vskip1ex
      The argument \emph{type} can be validated using functions such as \texttt{is.numeric()}, \texttt{is.character()}, etc.
      \vskip1ex
      The function \texttt{return()} returns its argument and terminates futher function execution,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# function vali_date validates its arguments
vali_date <- function(in_put=NULL) {
# check if argument is valid and return double
  if (is.null(in_put)) {
    return("vali_date: in_put is missing")
  } else if (is.numeric(in_put)) {
    2*in_put
  } else cat("vali_date: in_put not numeric")
}  # end vali_date
vali_date(3)
vali_date("a")
vali_date()
# vali_date validates arguments using missing()
vali_date <- function(in_put) {
# check if argument is valid and return double
  if (missing(in_put)) {
    return("vali_date: in_put is missing")
  } else if (is.numeric(in_put)) {
    2*in_put
  } else cat("vali_date: in_put is not numeric")
}  # end vali_date
vali_date(3)
vali_date("a")
vali_date()
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Validating Assertions Inside Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If assertions about variables inside a function are \texttt{FALSE}, then \texttt{stop()} can be called to halt its execution,
      \vskip1ex
      Calling \texttt{stop()} is preferable to calling \texttt{return()}, or inserting \texttt{cat()} statements into the code,
      \vskip1ex
      Using \texttt{stop()} inside a function allows calling the function \texttt{traceback()}, if an error was produced,
      \vskip1ex
      The function \texttt{traceback()} prints the call stack, showing the function that produced the \emph{error} condition,
      \vskip1ex
      \texttt{cat()} statements inside the function body provide information about the state of its variables,
    \column{0.5\textwidth}
      \vspace{-1em}
            <<echo=TRUE,eval=FALSE>>=
# vali_date() validates its arguments and assertions
vali_date <- function(in_put) {
# check if argument is valid and return double
  if (missing(in_put)) {
    stop("vali_date: in_put is missing")
  } else if (!is.numeric(in_put)) {
    cat("in_put=", in_put)
    stop("vali_date: in_put is not numeric")
  } else 2*in_put
}  # end vali_date
vali_date(3)
vali_date("a")
vali_date()
      @
      \vspace{-2em}
      <<eval=FALSE>>=
# print the call stack
traceback()
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Validating Assertions Using \texttt{stopifnot()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{R} provides robust validation and debugging tools through \emph{type} validation functions, and functions \texttt{missing()}, \texttt{stop()}, and \texttt{stopifnot()},
      \vskip1ex
      If the argument to function \texttt{stopifnot()} is \texttt{FALSE}, then it produces an \emph{error} condition, and halts function execution,
      \vskip1ex
      \texttt{stopifnot()} is a convenience wrapper for \texttt{stop()}, and eliminates the need to use \texttt{if ()} statements,
      \vskip1ex
      \texttt{stopifnot()} is often used to check the validity of function arguments,
      \vskip1ex
      \texttt{stopifnot()} can be inserted anywhere in the function body in order to check assertions about its variables,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
vali_date <- function(in_put) {
# check argument using long form '&&' operator
  stopifnot(!missing(in_put) &&
              is.numeric(in_put))
  2*in_put
}  # end vali_date
vali_date(3)
vali_date()
vali_date("a")
vali_date <- function(in_put) {
# check argument using logical '&' operator
  stopifnot(!missing(in_put) & is.numeric(in_put))
  2*in_put
}  # end vali_date
vali_date()
vali_date("a")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Validating Function Arguments and Assertions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The functions \texttt{stop()} and \texttt{stopifnot()} halt function execution and produce \emph{error} conditions if certain assertions are \texttt{FALSE},
      \vskip1ex
      The \emph{type} validation functions, such as \texttt{is.numeric()}, \texttt{is.na()}, etc., and \texttt{missing()}, allow for validation of arguments and variables inside functions,
      \vskip1ex
      \texttt{cat()} statements can provide information about the state of variables inside a function,
      \vskip1ex
      \texttt{cat()} statements don't return values, so they provide information even when a function produces an \texttt{error},
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# sum_two() returns the sum of its two arguments
sum_two <- function(in_put1, in_put2) {  # even more robust
# check if at least one argument is not missing
  stopifnot(!missing(in_put1) &&
              !missing(in_put2))
# check if arguments are valid and return sum
  if (is.numeric(in_put1) &&
      is.numeric(in_put2)) {
    in_put1 + in_put2  # both valid
  } else if (is.numeric(in_put1)) {
    cat("in_put2 is not numeric\n")
    in_put1  # in_put1 is valid
  } else if (is.numeric(in_put2)) {
    cat("in_put1 is not numeric\n")
    in_put2  # in_put2 is valid
  } else {
    stop("none of the arguments are numeric")
  }
}  # end sum_two
sum_two(1, 2)
sum_two(5, 'a')
sum_two('a', 5)
sum_two('a', 'b')
sum_two()
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{R} Debugger Facility}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{debug()} flags a function for future debugging, but doesn't invoke the debugger,
      \vskip1ex
      After a function is flagged for debugging with the call \texttt{"debug(my\_func)"}, then the function call \texttt{"my\_func()"} automatically invokes the debugger (browser),
      \vskip1ex
      When the debugger is first invoked, it prints the function code to the console, and produces a \emph{browser} prompt: \texttt{"Browse[2]>"},
      \vskip1ex
      Once inside the debugger, the user can execute the function code one command at a time by pressing the \emph{Enter} key,
      \vskip1ex
      The user can examine the function arguments and variables with standard \texttt{R} commands, and can also change the values of objects or create new ones,
      \vskip1ex
      The command \texttt{"c"} executes the remainder of the function code without pausing,
      \vskip1ex
      The command \texttt{"Q"} exits the debugger (browser),
      \vskip1ex
      The call \texttt{"undebug(my\_func)"} at the \texttt{R} prompt unflags the function for debugging,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<eval=FALSE>>=
# flag "vali_date" for debugging
debug(vali_date)
# calling "vali_date" starts debugger
vali_date(3)
# unflag "vali_date" for debugging
undebug(vali_date)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Debugging Using \texttt{browser()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      As an alternative to flagging a function for debugging, the user can insert the function \texttt{browser()} into the function body,
      \vskip1ex
      \texttt{browser()} pauses the execution of a function and invokes the debugger (browser) at the point where \texttt{browser()} was called,
      \vskip1ex
      Once inside the debugger, the user can execute all the same browser commands as when using \texttt{debug()},
      \vskip1ex
      \texttt{browser()} is usually inserted just before the command that is suspected of producing an \emph{error} condition,
      \vskip1ex
      Another alternative to flagging a function for debugging, or inserting \texttt{browser()} calls, is setting the \texttt{"error"} option equal to \texttt{"recover"},
      \vskip1ex
      Setting the \texttt{"error"} option equal to \texttt{"recover"} automatically invokes the debugger when an \emph{error} condition is produced,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
vali_date <- function(in_put) {
  browser()  # pause and invoke browser
# check argument using long form '&&' operator
  stopifnot(!missing(in_put) &&
              is.numeric(in_put))
  2*in_put
}  # end vali_date
vali_date()  # invokes debugger
options("error")  # show default NULL "error" option
options(error=recover)  # set "error" option to "recover"
options(error=NULL)  # set back to default "error" option
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Using the Debugger in \protect\emph{RStudio}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{RStudio} has several built-in debugging facilities that complement those already installed in \texttt{R}:
      \begin{itemize}
        \item toggling breakpoints, instead of inserting \texttt{browser()} commands,
        \item stepping into functions,
        \item environment pane with environment stack, instead of calling \texttt{ls()},
        \item traceback pane, instead of calling \texttt{traceback()},
      \end{itemize}
      \emph{RStudio} provides an online debugging tutorial:
      \hskip1em\url{https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio}
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{image/rstudio_debug.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Handling Exception Conditions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{tryCatch()} executes functions and expressions, and handles any \emph{exception conditions} produced when they are evaluated.
      \vskip1ex
      \texttt{tryCatch()} first evaluates its \texttt{"expression"} argument.
      \vskip1ex
      If no error or warning \texttt{condition} is produced then \texttt{tryCatch()} just returns the value of the expression.
      \vskip1ex
      If an \texttt{exception condition} is produced then \texttt{tryCatch()} invokes error and warning \emph{handlers} and executes other expressions to provide information about the \texttt{exception condition}.
      \vskip1ex
      If a \emph{handler} is provided to \texttt{tryCatch()} then the error is captured by the \emph{handler}, instead of being broadcast to the console.
      \vskip1ex
      At the end, \texttt{tryCatch()} evaluates the expression provided to the \texttt{finally} argument.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
str(tryCatch)  # get arguments of tryCatch()
tryCatch(  # without error handler
  {  # evaluate expressions
    num_var <- 101  # assign
    stop('my error')  # produce error
  },
  finally=print(paste("num_var=", num_var))
)  # end tryCatch

tryCatch(  # with error handler
  {  # evaluate expressions
    num_var <- 101  # assign
    stop('my error')  # produce error
  },
  # error handler captures error condition
  error=function(error_cond) {
    print(paste("error handler: ", error_cond))
  },  # end error handler
  # warning handler captures warning condition
  warning=function(warning_cond) {
    print(paste("warning handler: ", warning_cond))
  },  # end warning handler
  finally=print(paste("num_var=", num_var))
)  # end tryCatch
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Error Conditions in Loops}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If an \emph{error} occurs in an \texttt{apply()} loop, then the loop exits without returning any result,
      \vskip1ex
      \texttt{apply()} collects the values returned by the function supplied to its \texttt{FUN} argument, and returns them only after the loop is finished,
      \vskip1ex
      If one of the function calls produces an error, then the loop is interrupted and \texttt{apply()} exits without returning any result,
      \vskip1ex
      The function \texttt{tryCatch()} captures errors, allowing loops to continue after the error \texttt{condition},
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1))>>=
rm(list=ls())
# apply loop without tryCatch
apply(as.matrix(1:5), 1, function(num_var) {  # anonymous function
    stopifnot(num_var != 3)  # check for error
    # broadcast message to console
    cat("(cat) num_var =", num_var, "\n")
    # return a value
    paste("(return) num_var =", num_var)
  }  # end anonymous function
)  # end apply
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Exception Handling in Loops}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If the body of the function supplied to the \texttt{FUN} argument is wrapped in \texttt{tryCatch()}, then the loop can finish without interruption and return its results,
      \vskip1ex
      The messages produced by \emph{errors} and \emph{warnings} can be caught by \emph{handlers} (functions) that are supplied to \texttt{tryCatch()},
      \vskip1ex
      The \emph{error} and \emph{warning} messages are bound (passed) to the formal arguments of the \emph{handler} functions that are supplied to \texttt{tryCatch()},
      \vskip1ex
      \texttt{tryCatch()} always evaluates the expression provided to the \texttt{finally} argument, even after an \emph{error} occurs,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE>>=
# apply loop with tryCatch
apply(as.matrix(1:5), 1, function(num_var) {  # anonymous function
    tryCatch(  # with error handler
      {  # body
        stopifnot(num_var != 3)  # check for error
        # broadcast message to console
        cat("(cat) num_var =", num_var, "\t")
        # return a value
        paste("(return) num_var =", num_var)
      },
      # error handler captures error condition
      error=function(error_cond)
        paste("handler: ", error_cond),
      finally=print(paste("(finally) num_var =", num_var))
    )  # end tryCatch
  }  # end anonymous function
)  # end apply
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Writing and Reading Data from Files}


%%%%%%%%%%%%%%%
\subsection{Writing Text Strings}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{cat()} concatenates strings and writes them to standard output or to files.
      \vskip1ex
      \texttt{cat()} interprets its argument character string and its escape sequences (\texttt{"\textbackslash{}"}), but doesn't return a value.
      \vskip1ex
      The function \texttt{print()} doesn't interpret its argument, and simply prints it to standard output and invisibly returns it.
      \vskip1ex
      Typing the name of an object in \texttt{R} implicitly calls \texttt{print()} on that object.
      \vskip1ex
      The function \texttt{save()} writes objects to compressed binary \texttt{.RData} files.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
cat("Enter\ttab")  # Cat() interprets backslash escape sequences
print("Enter\ttab")

my_text <- print("hello")
my_text  # print() returns its argument

# Create string
my_text <- "Title: My Text\nSome numbers: 1,2,3,...\nRprofile files contain code executed at R startup,\n"

cat(my_text, file="mytext.txt")  # Write to text file

cat("Title: My Text",  # Write several lines to text file
    "Some numbers: 1,2,3,...",
    "Rprofile files contain code executed at R startup,",
    file="mytext.txt", sep="\n")

save(my_text, file="mytext.RData")  # Write to binary file
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Displaying Numeric Data}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{print()} displays numeric data objects, with the number of digits given by the global option \texttt{"digits"},
      \vskip1ex
      The function \texttt{sprintf()} returns strings formatted from text strings and numeric data,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=TRUE>>=
print(pi)
print(pi, digits=10)
getOption("digits")
foo <- 12
bar <- "months"
sprintf("There are %i %s in the year", foo, bar)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Reading Text from Files}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{scan()} reads text or data from a file and returns it as a vector or a list,
      \vskip1ex
      The function \texttt{readLines()} reads lines of text from a connection (file or console), and returns them as a vector of \texttt{character} strings,
      \vskip1ex
      The function \texttt{readline()} reads a single line from the console, and returns it as a \texttt{character} string,
      \vskip1ex
      The function \texttt{file.show()} reads text or data from a file and displays in editor,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Read text from file
scan(file="mytext.txt", what=character(), sep="\n")

# Read lines from file
readLines(con="mytext.txt")

# Read text from console
in_put <- readline("Enter a number: ")
class(in_put)
# Coerce to numeric
in_put <- as.numeric(in_put)

# Read text from file and display in editor:
# file.show("mytext.txt")
# file.show("mytext.txt", pager="")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Writing and Reading \protect\emph{Data Frames} from \protect\emph{Text} Files}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The functions \texttt{write.table()} and \texttt{read.table()} write and read \emph{data frames} from text files.
      \vskip1ex
      \texttt{write.table()} coerces objects to \emph{data frames} before it writes them,
      \vskip1ex
      \texttt{read.table()} returns a \emph{data frame}, and coerces non-numeric values to \texttt{factors} (unless the \texttt{stringsAsFactors=FALSE} option is set),
      \vskip1ex
      \texttt{write.table()} and \texttt{read.table()} can be used to write and read matrices from text files, but they have to be coerced back to matrices,
      \vskip1ex
      \texttt{write.table()} and \texttt{read.table()} are inefficient for very large data sets,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:4)),eval=FALSE>>=
setwd("C:/Develop/R/lecture_slides/data")
data_frame <- data.frame(type=c("rose", "daisy", "tulip"), color=c("red", "white", "yellow"), price=c(1.5, 0.5, 1.0), row.names=c("flower1", "flower2", "flower3"))  # end data.frame
mat_rix <- matrix(sample(1:12), ncol=3, dimnames=list(NULL, c("col1", "col2", "col3")))
rownames(mat_rix) <- paste("row", 1:NROW(mat_rix), sep="")
# Write data frame to text file, and then read it back
write.table(data_frame, file="florist.txt")
data_read <- read.table(file="florist.txt")
data_read  # A data frame

# Write matrix to text file, and then read it back
write.table(mat_rix, file="matrix.txt")
mat_read <- read.table(file="matrix.txt")
mat_read  # write.table() coerced matrix to data frame
class(mat_read)
# Coerce from data frame back to matrix
mat_read <- as.matrix(mat_read)
class(mat_read)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Copying \protect\emph{Data Frames} Between the \protect\emph{clipboard} and \texttt{R}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Data frames} stored in the \emph{clipboard} can be copied into \texttt{R} using the function \texttt{read.table()},
      \vskip1ex
      \emph{Data frames} in \texttt{R} can be copied into the \emph{clipboard} using the function \texttt{write.table()},
      \vskip1ex
      This allows convenient copying of \emph{data frames} between \texttt{R} and \emph{Excel},
      \vskip1ex
      \emph{Data frames} can also be manipulated directly in the \texttt{R} spreadsheet-style data editor,
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=(-(1:3)),eval=FALSE>>=
setwd("C:/Develop/R/lecture_slides/data")
data_frame <- data.frame(small=c(3, 5), medium=c(9, 11), large=c(15, 13))
data_frame <- read.table("mydata.txt", header=TRUE)
data_frame <- read.table("clipboard", header=TRUE)

write.table(x=data_frame, file="clipboard", sep="\t")

# Wrapper function for copying data frame from clipboard into R
# by default, data is tab delimited, with a header
read_clip <- function(file="clipboard", sep="\t",
                      header=TRUE, ...) {
  read.table(file=file, sep=sep, header=header, ...)
}  # end read_clip

data_frame <- read_clip()

# Wrapper function for copying data frame from R into clipboard
# by default, data is tab delimited, with a header
write_clip <- function(data, row.names=FALSE,
                       col.names=TRUE, ...) {
  write.table(x=data, file="clipboard", sep="\t",
              row.names=row.names, col.names=col.names, ...)
}  # end write_clip

write_clip(data=data_frame)

# Launch spreadsheet-style data editor
data_frame <- edit(data_frame)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Writing and Reading \protect\emph{Data Frames} From \texttt{.csv} Files}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The easiest way to share data between \texttt{R} and \emph{Excel} is through \texttt{.csv} files.
      \vskip1ex
      The functions \texttt{write.csv()} and \texttt{read.csv()} write and read \emph{data frames} from \texttt{.csv} format files.
      \vskip1ex
      The functions \texttt{write.csv()} and \texttt{read.csv()} write and read \emph{data frames} from \texttt{.csv} format files.
      \vskip1ex
      These functions are \emph{wrappers} for \texttt{write.table()} and \texttt{read.table()},
      \vskip1ex
      \texttt{read.csv()} coerces non-numeric values to \texttt{factors}, unless the \texttt{stringsAsFactors=FALSE} option is set,
      \vskip1ex
      \texttt{read.csv()} reads row names as an extra column, unless the \texttt{row.names=1} argument is used,
      \vskip1ex
      The argument \texttt{"row.names"} accepts either the number or the name of the column containing the row names,
      \vskip1ex
      The \texttt{*.csv()} functions are very inefficient for large data sets,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Write data frame to CSV file, and then read it back
write.csv(data_frame, file="florist.csv")
data_read <- read.csv(file="florist.csv",
                       stringsAsFactors=FALSE)
data_read  # the row names are read in as extra column
# Restore row names
rownames(data_read) <- data_read[, 1]
data_read <- data_read[, -1]  # Remove extra column
data_read
# Read data frame, with row names from first column
data_read <- read.csv(file="florist.csv", row.names=1)
data_read
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Writing and Reading \protect\emph{Data Frames} From \texttt{.csv} Files (cont.)}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The functions \texttt{write.csv()} and \texttt{read.csv()} can write and read \emph{data frames} from \texttt{.csv} format files \emph{without using row names},
      \vskip1ex
      Row names can be omitted from the output file by calling \texttt{write.csv()} with the argument \texttt{row.names=FALSE},
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Write data frame to CSV file, without row names
write.csv(data_frame, row.names=FALSE, file="florist.csv")
data_read <- read.csv(file="florist.csv")
data_read  # A data frame without row names
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Writing and Reading Matrices From \texttt{.csv} Files}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The functions \texttt{write.csv()} and \texttt{read.csv()} can write and read matrices from \texttt{.csv} format files.
      \vskip1ex
      If row names can be omitted in the output file, then \texttt{write.csv()} can be called with argument \texttt{row.names=FALSE},
      \vskip1ex
      If the input file doesn't contain row names, then \texttt{read.csv()} can be called without the \texttt{"row.names"} argument,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Write matrix to csv file, and then read it back
write.csv(mat_rix, file="matrix.csv")
mat_read <- read.csv(file="matrix.csv", row.names=1)
mat_read  # Read.csv() reads matrix as data frame
class(mat_read)
mat_read <- as.matrix(mat_read)  # Coerce to matrix
identical(mat_rix, mat_read)
write.csv(mat_rix, row.names=FALSE,
          file="matrix_ex_rows.csv")
mat_read <- read.csv(file="matrix_ex_rows.csv")
mat_read <- as.matrix(mat_read)
mat_read  # A matrix without row names
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Writing and Reading Matrices (cont.)}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      There are several ways of writing and reading matrices from \texttt{.csv} files, with tradeoffs between simplicity, data size, and speed.
      \vskip1ex
      The function \texttt{write.matrix()} writes a matrix to a text file, without its row names.
      \vskip1ex
      \texttt{write.matrix()} is part of package \emph{MASS}.
      \vskip1ex
      The advantage of function \texttt{scan()} is its speed, but it doesn't handle row names easily.
      \vskip1ex
      Removing row names simplifies the writing and reading of matrices.
      \vskip1ex
      The function \texttt{readLines} reads whole lines and returns them as single strings.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
setwd("C:/Develop/R/lecture_slides/data")
library(MASS)  # Load package "MASS"
# Write to CSV file by row - it's very SLOW!!!
MASS::write.matrix(mat_rix,
  file="matrix.csv", sep=",")
# Read using scan() and skip first line with colnames
mat_read <- scan(file="matrix.csv",
  sep=",", skip=1, what=numeric())
# Read colnames
col_names <- readLines(con="matrix.csv", n=1)
col_names  # this is a string!
# Convert to char vector
col_names <- strsplit(col_names,
  s=",")[[1]]
mat_read  # mat_read is a vector, not matrix!
# Coerce by row to matrix
mat_read <- matrix(mat_read,
  ncol=NROW(col_names), byrow=TRUE)
# Restore colnames
colnames(mat_read) <- col_names
mat_read
# Scan() is a little faster than read.csv()
library(microbenchmark)
summary(microbenchmark(
  read_csv=read.csv("matrix.csv"),
  scan=scan(file="matrix.csv", sep=",",
    skip=1, what=numeric()),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Reading Matrices Containing Bad Data}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Very often data that is read from external sources contains elements with bad data.
      \vskip1ex
      An example of bad data are \texttt{character} strings within sets of \texttt{numeric} data.
      \vskip1ex
      Columns of numeric data that contain strings are coerced to \texttt{character} or \texttt{factor}, when they're read by \texttt{read.csv()}.
      \vskip1ex
      The function \texttt{as.numeric()} coerces complex data objects into \texttt{numeric} vectors, and removes all their \emph{attributes}.
      \vskip1ex
      \texttt{as.numeric()} coerces strings that don't represent numbers into \texttt{NA} values.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Read data from a csv file, including row names
mat_rix <- read.csv(file="matrix_bad.csv",
  row.names=1, stringsAsFactors=FALSE)
mat_rix
class(mat_rix)
# Columns with bad data are character or factor
sapply(mat_rix, class)
# Copy row names
row_names <- row.names(mat_rix)
# sapply loop over columns and coerce to numeric
mat_rix <- sapply(mat_rix, as.numeric)
# Restore row names
row.names(mat_rix) <- row_names
# Replace NAs with zero
mat_rix[is.na(mat_rix)] <- 0
# matrix without NAs
mat_rix
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Writing and Reading Time Series From \protect\emph{Text} Files}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \emph{zoo} contains functions \texttt{write.zoo()} and \texttt{read.zoo()} for writing and reading \emph{zoo} time series from \texttt{.txt} and \texttt{.csv} files.
      \vskip1ex
      The functions \texttt{write.zoo()} and \texttt{read.zoo()} are \emph{wrappers} for \texttt{write.table()} and \texttt{read.table()}.
      \vskip1ex
      The function \texttt{write.zoo()} writes the \emph{zoo} series index as a character string in quotations \texttt{""}, to make it easier to read (parse) by \texttt{read.zoo()}.
      \vskip1ex
      Users may also directly use \texttt{write.table()} and \texttt{read.table()}, instead of \texttt{write.zoo()} and \texttt{read.zoo()}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:4)),eval=FALSE>>=
setwd("C:/Develop/R/lecture_slides/data")
rm(list=ls())
set.seed(1121)  # Reset random number generator
library(zoo)  # Load package zoo
# Create zoo with Date index
in_dex <- seq(from=as.Date("2013-06-15"),
              by="day", length.out=100)
zoo_series <- zoo(rnorm(NROW(in_dex)), order.by=in_dex)
head(zoo_series, 3)
# Write zoo series to text file, and then read it back
write.zoo(zoo_series, file="zoo_series.txt")
zoo_read <- read.zoo("zoo_series.txt")  # Read it back
all.equal(zoo_read, zoo_series)
# Perform the same using write.table() and read.table()
# first coerce zoo_series into data frame
data_frame <- as.data.frame(zoo_series)
data_frame <- cbind(in_dex, data_frame)
# Write zoo_series to text file using write.table
write.table(data_frame, file="zoo_series.txt",
            row.names=FALSE, col.names=FALSE)
# Read data frame from file
zoo_read <- read.table(file="zoo_series.txt",
                       stringsAsFactors=FALSE)
sapply(zoo_read, class)  # A data frame
# Coerce data frame into zoo_series
zoo_read <- zoo::zoo(
  drop(as.matrix(zoo_read[, -1])),
  order.by=as.Date(zoo_read[, 1]))
all.equal(zoo_read, zoo_series)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Writing and Reading Time Series From \texttt{.csv} Files}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      By default the functions \texttt{zoo::write.zoo()} and \texttt{zoo::read.zoo()} write data in \emph{space}-delimited text format, but they can also write to \emph{comma}-delimited \texttt{.csv} files by passing the parameter \texttt{sep=","}.
      \vskip1ex
      Single column \emph{zoo} time series usually don't have a dimension attribute, and they don't have a column name, unlike multi-column \emph{zoo} time series, and this can cause hard to detect bugs.
      \vskip1ex
      It's best to always pass the argument \texttt{"col.names=TRUE"} to the function \texttt{write.zoo()}, to make sure it writes a column name for a single column \emph{zoo} time series.
      \vskip1ex
      Reading a \texttt{.csv} file containing a single column of data using the function \texttt{read.zoo()} produces a \emph{zoo} time series with a \texttt{NULL} dimension, unless the argument \texttt{"drop=FALSE"} is passed to \texttt{read.zoo()}.
      \vskip1ex
      Users may also directly use \texttt{write.table()} and \texttt{read.table()}, instead of \texttt{write.zoo()} and \texttt{read.zoo()}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(zoo)  # Load package zoo
# Write zoo series to CSV file, and then read it back
write.zoo(zoo_series, file="zoo_series.csv",
          sep=",", col.names=TRUE)
zoo_read <- read.zoo(file="zoo_series.csv", 
  header=TRUE, sep=",", drop=FALSE)
all.equal(zoo_series, drop(zoo_read))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Writing and Reading Time Series With \protect\emph{Date-time} Index}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{read.csv.zoo()} reads \emph{zoo} time series from \texttt{.csv} files.
      \vskip1ex
      The function \texttt{xts::as.xts()} coerces \emph{zoo} time series into \emph{xts} series.
      \vskip1ex
      If the index of a \emph{zoo} time series is a \emph{date-time}, then \texttt{write.zoo()} writes the date and time fields as character strings separated by a \emph{space} between them, inside quotations \texttt{""}.
      \vskip1ex
      Very often \texttt{.csv} files contain custom \emph{date-time} formats, which need to be passed as parameters into \texttt{read.zoo()} for proper formatting.
      \vskip1ex
      The \texttt{"FUN"} argument of \texttt{read.zoo()} accepts a function for coercing the date and time columns of the input data into a \emph{date-time} object suitable for the \emph{zoo} index.
      \vskip1ex
      The function \texttt{as.POSIXct()} coerces \texttt{character} strings into \texttt{POSIXct} \emph{date-time} objects.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
set.seed(1121)  # Reset random number generator
# Create zoo with POSIXct date-time index
in_dex <- seq(from=as.POSIXct("2013-06-15"),
              by="hour", length.out=100)
zoo_series <- zoo(rnorm(NROW(in_dex)), order.by=in_dex)
head(zoo_series, 3)
# Write zoo series to CSV file, and then read it back
write.zoo(zoo_series, file="zoo_series.csv",
          sep=",", col.names=TRUE)
# Read from CSV file using read.csv.zoo()
zoo_read <- read.csv.zoo(file="zoo_series.csv")
all.equal(zoo_series, zoo_read)
# Coerce to xts series
x_ts <- xts::as.xts(zoo_read)
class(x_ts); head(x_ts, 3)
# Coerce zoo series into data frame with custom date format
data_frame <- as.data.frame(zoo_series)
data_frame <- cbind(format(in_dex, "%m-%d-%Y %H:%M:%S"), data_frame)
head(data_frame, 3)
# Write zoo series to csv file using write.table
write.table(data_frame, file="zoo_series.csv",
            sep=",", row.names=FALSE, col.names=FALSE)
# Read from CSV file using read.csv.zoo()
zoo_read <- read.zoo(file="zoo_series.csv",
  header=FALSE, sep=",", FUN=as.POSIXct, 
  format="%m-%d-%Y %H:%M:%S", tz="America/New_York")
# Or using read.csv.zoo()
zoo_read <- read.csv.zoo(file="zoo_series.csv", 
  header=FALSE,  format="%m-%d-%Y %H:%M:%S", tz="America/New_York")
head(zoo_read, 3)
all.equal(zoo_series, zoo_read)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Reading Time Series With \texttt{Numeric} \protect\emph{Date-time} Index}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If the index of a time series is \texttt{numeric} (representing the \emph{moment of time}, either as the number of days or seconds), then it must be coerced to a proper \emph{date-time} class.
      \vskip1ex
      A convenient way of reading time series with a numeric index is by using \texttt{read.table()}, and then coercing the \emph{data frame} into a time series.
      \vskip1ex
      The function \texttt{as.POSIXct.numeric()} coerces a \texttt{numeric} value representing the \emph{moment of time} into a \texttt{POSIXct} \emph{date-time}, equal to the \emph{clock time} in the local \emph{time zone}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Read time series from CSV file, with numeric date-time
zoo_read <- read.table(file="C:/Develop/R/lecture_slides/data/es_ohlc.csv", 
  header=TRUE, sep=",")
# A data frame
class(zoo_read)
sapply(zoo_read, class)
# Coerce data frame into xts series
zoo_read <- xts::xts(as.matrix(zoo_read[, -1]),
  order.by=as.POSIXct.numeric(zoo_read[, 1], tz="America/New_York", origin="1970-01-01"))
# An xts series
class(zoo_read)
head(zoo_read, 3)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Passing Arguments to the \texttt{save()} Function}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{save()} writes objects to a binary file,
      \vskip1ex
      Object names can be passed into \texttt{save()} either through the \texttt{"..."} argument, or the \texttt{"list"} argument,
      \vskip1ex
      Objects passed through the \texttt{"..."} argument are not evaluated, so they must be either object names or character strings,
      \vskip1ex
      Object names aren't surrounded by quotes \texttt{""}, while character strings that represent object names are surrounded by quotes \texttt{""},
      \vskip1ex
      Objects passed through the \texttt{"list"} argument are evaluated, so they may be variables containing character strings,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-1)>>=
rm(list=ls())  # Remove all objects
var1 <- 1; var2 <- 2
ls()  # List all objects
ls()[1]  # List first object
args(save)  # List arguments of save function
# Save "var1" to a binary file using string argument
save("var1", file="my_data.RData")
# Save "var1" to a binary file using object name
save(var1, file="my_data.RData")
# Save multiple objects
save(var1, var2, file="my_data.RData")
# Save first object in list by passing to "..." argument
# Ls()[1] is not evaluated
save(ls()[1], file="my_data.RData")
# Save first object in list by passing to "list" argument
save(list=ls()[1], file="my_data.RData")
# Save whole list by passing it to the "list" argument
save(list=ls(), file="my_data.RData")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Writing and Reading Lists of Objects}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{load()} reads data from \texttt{.RData} files, and \emph{invisibly} returns a vector of names of objects created in the workspace.
      \vskip1ex
      The vector of names can be used to manipulate the objects in loops, or to pass them to functions.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
rm(list=ls())  # Remove all objects
# Load objects from file
load_ed <- load(file="my_data.RData")
load_ed  # vector of loaded objects
ls()  # List objects
# Assign new values to objects in  global environment
sapply(load_ed, function(sym_bol) {
  assign(sym_bol, runif(1), envir=globalenv())
})  # end sapply
ls()  # List objects
# Assign new values to objects using for loop
for (sym_bol in load_ed) {
  assign(sym_bol, runif(1))
}  # end for
ls()  # List objects
# Save vector of objects
save(list=load_ed, file="my_data.RData")
# Remove only loaded objects
rm(list=load_ed)
# Remove the object "load_ed"
rm(load_ed)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Saving Output of \texttt{R} to a File}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{sink()} diverts \texttt{R} \emph{text} output (excluding graphics) to a file, or ends the diversion,
      \vskip1ex
      Remember to call \texttt{sink()} to end the diversion!
      \vskip1ex
      The function \texttt{pdf()} diverts graphics output to a \emph{pdf} file (text output isn't diverted), in vector graphics format,
      \vskip1ex
      The functions \texttt{png()}, \texttt{jpeg()}, \texttt{bmp()}, and \texttt{tiff()} divert graphics output to graphics files (text output isn't diverted),
      \vskip1ex
      The function \texttt{dev.off()} ends the diversion,
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
sink("sinkdata.txt")# Redirect text output to file

cat("Redirect text output from R\n")
print(runif(10))
cat("\nEnd data\nbye\n")

sink()  # turn redirect off

pdf("Rgraph.pdf", width=7, height=4)  # Redirect graphics to pdf file

cat("Redirect data from R into pdf file\n")
my_var <- seq(-2*pi, 2*pi, len=100)
plot(x=my_var, y=sin(my_var), main="Sine wave",
   xlab="", ylab="", type="l", lwd=2, col="red")
cat("\nEnd data\nbye\n")

dev.off()  # turn pdf output off

png("r_plot.png")  # Redirect graphics output to png file

cat("Redirect graphics from R into png file\n")
plot(x=my_var, y=sin(my_var), main="Sine wave",
 xlab="", ylab="", type="l", lwd=2, col="red")
cat("\nEnd data\nbye\n")

dev.off()  # turn png output off
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{High Performance Data Management}


%%%%%%%%%%%%%%%
\subsection{Package \protect\emph{data.table} for High Performance Data Management}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package 
      \href{https://cran.r-project.org/web/packages/data.table/}{\emph{data.table}} 
      is designed for high performance data management.
      \vskip1ex
      The package \emph{data.table} implements \emph{data table} objects, which are a special type of \emph{data frame}, and an extension of the \emph{data frame} class.
      \vskip1ex
      \emph{Data tables} are faster and more convenient to work with than \emph{data frames}.
      \vskip1ex
      \emph{data.table} functions are optimized for high performance (speed), because they are written in \texttt{C++} and they perform operations by reference (in place) without copying data in memory.
      \vskip1ex
      Some of the attractive features of package \emph{data.table} are:
      \begin{itemize}
        \item Very fast writing and reading from files,
        \item Very fast sorting and merging operations,
        \item Subsetting using multiple logical clauses,
        \item Columns of type \texttt{character} are never converted to factors,
      \end{itemize}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<eval=FALSE>>=
# Install package data.table
install.packages("data.table")
# Load package data.table
library(data.table)
# get documentation for package data.table
# get short description
packageDescription("data.table")
# Load help page
help(package="data.table")
# List all datasets in "data.table"
data(package="data.table")
# List all objects in "data.table"
ls("package:data.table")
# Remove data.table from search path
detach("package:data.table")
      @
      \vspace{-1em}
      The package \emph{data.table} has extensive documentation:\\
      \hskip1em\url{https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html}\\
      \hskip1em\url{https://github.com/Rdatatable/data.table/wiki}
      \vskip1ex
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Data Table} Objects}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Data table} objects are a special type of \emph{data frame}, and are derived from the class \texttt{data.frame}.
      \vskip1ex
      \emph{Data table} objects resemble databases, with columns of different types of data, and rows of records containing individual observations.
      \vskip1ex
      The function \texttt{data.table::data.table()} creates a \emph{data table} object.
      \vskip1ex
      \emph{Data table} columns can be referenced directly by their names (without quotes), and their rows can be referenced without a following comma.
      \vskip1ex
      When a \emph{data table} is printed (by typing its name) then only the top \texttt{5} and bottom \texttt{5} rows are displayed (unless \texttt{getOption("datatable.print.nrows")} is less than \texttt{100}).
      \vskip1ex
      The operator \texttt{.N} returns the number of observations (rows) in the \emph{data table}.
      \vskip1ex
      \emph{Data table} computations are usually much faster than equivalent \texttt{R} computations, but not always.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Create a data table
library(data.table)
data_table <- data.table::data.table(
  col1=sample(7), col2=sample(7), col3=sample(7))
# Print data_table
class(data_table); data_table
# column referenced without quotes
data_table[, col2]
# row referenced without a following comma
data_table[2]
# Print option "datatable.print.nrows"
getOption("datatable.print.nrows")
options(datatable.print.nrows=10)
getOption("datatable.print.nrows")
# Number of rows in data_table
NROW(data_table)
# Or
data_table[, NROW(col1)]
# Or
data_table[, .N]
# microbenchmark speed of data.table syntax
library(microbenchmark)
summary(microbenchmark(
  dt=data_table[, .N],
  pure_r=NROW(data_table),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Coercing \protect\emph{Data Table} Objects Into \protect\emph{Data Frames}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The functions \texttt{data.table::setDT()} and \texttt{data.table::setDF()} coerce \emph{data frames} to \emph{data tables}, and vice versa.
      \vskip1ex
      The \emph{set} functions \texttt{data.table::set*()} perform their operations by reference, without returning any values or copying data to a new memory location, which makes them very fast.
      \vskip1ex
      \emph{Data table} objects can also be coerced into \emph{data frames} using the function \texttt{as.data.frame()}, but it's much slower because it makes copies of data.
      \vskip1ex
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Create data frame and coerce it to data table
data_table <- data.frame(
  col1=sample(7), col2=sample(7), col3=sample(7))
class(data_table); data_table
data.table::setDT(data_table)
class(data_table); data_table
# Coerce data_table into data frame
data.table::setDF(data_table)
class(data_table); data_table
# Or
data_table <- data.table:::as.data.frame.data.table(data_table)
# SetDF() is much faster than as.data.frame()
summary(microbenchmark(
  as.data.frame=data.table:::as.data.frame.data.table(data_table),
  setDF=data.table::setDF(data_table),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Coercing \texttt{xts} Time Series Into \protect\emph{Data Frames}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      An \texttt{xts} time series can be coerced into a \emph{data table} by first coercing it into a \emph{data frame} and then into a \emph{data table} using the function \texttt{data.table::setDT()}.
      \vskip1ex
      But then the time index of the \texttt{xts} series is coerced into strings, not dates.
      \vskip1ex
      An \texttt{xts} time series can also be coerced directly into a \emph{data table} using the function \texttt{data.table::as.data.table()}.
      \vskip1ex
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Coerce xts to a data frame
price_s <- rutils::etf_env$VTI
class(price_s); head(price_s)
price_s <- as.data.frame(price_s)
class(price_s); head(price_s)
# Coerce data frame to a data table
data.table::setDT(price_s, keep.rownames=TRUE)
class(price_s); head(price_s)
# Dates are coerced to strings
sapply(price_s, class)
# Coerce xts directly to a data table
data_table <- as.data.table(rutils::etf_env$VTI,
  keep.rownames=TRUE)
class(data_table); head(data_table)
# Dates are not coerced to strings
sapply(data_table, class)
all.equal(price_s, data_table, check.attributes=FALSE)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Writing and Reading Data Using Package \protect\emph{data.table}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The easiest way to share data between \texttt{R} and \emph{Excel} is through \texttt{.csv} files.
      \vskip1ex
      The function \texttt{data.table::fread()} reads from \texttt{.csv} files and returns a \emph{data table} object of class \texttt{data.table}.
      \vskip1ex
      \emph{Data table} objects are a special type of \emph{data frame}, and are derived from the class \texttt{data.frame}.
      \vskip1ex
      The function \texttt{data.table::fread()} is over \texttt{6} times faster than \texttt{read.csv()}!
      \vskip1ex
      The function \texttt{data.table::fwrite()} writes to \texttt{.csv} files over \texttt{12} times faster than the function \texttt{write.csv()}, and \texttt{300} times faster than function \texttt{cat()}!
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Read a data table from CSV file
dir_name <- "C:/Develop/R/lecture_slides/data/"
file_name <- file.path(dir_name, "weather_delays14.csv")
data_table <- data.table::fread(file_name)
class(data_table); dim(data_table)
data_table
# fread() reads the same data as read.csv()
all.equal(read.csv(file_name, stringsAsFactors=FALSE),
          setDF(fread(file_name)))
# fread() is much faster than read.csv()
summary(microbenchmark(
  pure_r=read.csv(file_name),
  data.table=setDF(fread(file_name)),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
# Write data table to file in different ways
data.table::fwrite(data_table, file="data_table.csv")
write.csv(data_table, file="data_table2.csv")
cat(unlist(data_table), file="data_table3.csv")
# microbenchmark speed of data.table::fwrite()
summary(microbenchmark(
  fwrite=data.table::fwrite(data_table, file="data_table.csv"),
  write_csv=write.csv(data_table, file="data_table2.csv"),
  cat=cat(unlist(data_table), file="data_table3.csv"),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Subsetting \protect\emph{Data Table} Objects}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The square braces (brackets) \texttt{"[]"} operator subsets (references) the rows and columns of \emph{data tables}. 
      \vskip1ex
      \emph{Data table} rows can be subset without a following comma.
      \vskip1ex
      \emph{Data table} columns can be referenced directly by their names (without quotes, as if they were variables) after a comma.
      \vskip1ex
      Multiple \emph{data table} columns can be referenced by passing a list of their names.
      \vskip1ex
      The dot \texttt{.()} operator is equivalent to the function \texttt{list()}.
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Select first five rows of data_table
data_table[1:5]
# Select rows with JFK flights
jfk_flights <- data_table[origin=="JFK"]
# Select rows JFK flights in June
jfk_flights <- data_table[origin=="JFK" & month==6]
# Select rows without JFK flights
jfk_flights <- data_table[!(origin=="JFK")]
# Select flights with carrier_delay
data_table[carrier_delay > 0]
# Select column of data_table and return a vector
head(data_table[, origin])
# Select column of data_table and return a data_table, not vector
head(data_table[, list(origin)])
# Or
head(data_table[, .(origin)])
# Select two columns of data_table
data_table[, list(origin, month)]
# Or
data_table[, .(origin, month)]
# Select two columns and rename them
data_table[, list(or=origin, mo=month)]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Computations on \protect\emph{Data Table} Columns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Computations on \emph{data tables} can be performed using commands resembling the \emph{SQL} database language.
      \vskip1ex
      \emph{Data table} computations are usually much faster than equivalent \texttt{R} computations, but not always.
      \vskip1ex
      The operator \texttt{.N} returns the number of observations (rows) in the \emph{data table}.
      \vskip1ex
      The dot \texttt{.()} operator is equivalent to the function \texttt{list()}.
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Select flights with positive carrier_delay
data_table[carrier_delay > 0]
# Number of flights with carrier_delay
data_table[, sum(carrier_delay > 0)]
# Or
NROW(data_table[carrier_delay > 0])
# microbenchmark speed of data.table syntax
summary(microbenchmark(
  dt=data_table[, sum(carrier_delay > 0)],
  pure_r=NROW(data_table[carrier_delay > 0]),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
# Average carrier_delay
data_table[, mean(carrier_delay)]
# Average carrier_delay and aircraft_delay
data_table[, .(carrier=mean(carrier_delay), 
               aircraft=mean(aircraft_delay))]
# Average aircraft_delay from JFK
data_table[origin=="JFK", mean(aircraft_delay)]
# Number of flights from JFK
data_table[origin=="JFK", NROW(aircraft_delay)]
# Or
data_table[origin=="JFK", .N]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Aggregating \protect\emph{Data Table} Columns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      A \emph{data table} can be \emph{aggregated} over groups defined by one or more columns, passed to the \texttt{by} operator.
      \vskip1ex
      The square braces (brackets) \texttt{"[]"} operator accepts three arguments separated by commas:      \begin{itemize}
        \item row numbers to select, 
        \item list of columns to select, 
        \item the \texttt{by} operator with the aggregation columns (function).
      \end{itemize}
      The \texttt{keyby} operator sorts the output according to the aggregation columns.
      \vskip1ex
      Multiple \emph{data table} columns can be referenced by passing a list of their names.
      \vskip1ex
      The dot \texttt{.()} operator is equivalent to the function \texttt{list()}.
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Number of flights from each airport
data_table[, .N, by=origin]
# Or with names for output
data_table[, .(flights=.N), by=.(airport=origin)]
# Number of AA flights from each airport
data_table[carrier=="AA", .(flights=.N), 
           by=.(airport=origin)]
# Number of flights from each airport and airline
data_table[, .(flights=.N), 
           by=.(airport=origin, airline=carrier)]
# Average aircraft_delay
data_table[, mean(aircraft_delay)]
# Average aircraft_delay from JFK
data_table[origin=="JFK", mean(aircraft_delay)]
# Average aircraft_delay from each airport
data_table[, .(delay=mean(aircraft_delay)), 
           by=.(airport=origin)]
# Average and max delays from each airport and month
data_table[, .(mean_delay=mean(aircraft_delay), max_delay=max(aircraft_delay)), 
           by=.(airport=origin, month=month)]
# Average and max delays from each airport and month
data_table[, .(mean_delay=mean(aircraft_delay), max_delay=max(aircraft_delay)), 
           keyby=.(airport=origin, month=month)]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Sorting \protect\emph{Data Table} Columns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Standard \texttt{R} functions can be used inside the brackets \texttt{"[]"} operator.
      \vskip1ex
      The function \texttt{order()} calculates the permutation index to sort a given vector into ascending order.
      \vskip1ex
      The brackets \texttt{"[]"} operators can be chained together to perform several computations.
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Sort data_table by origin in ascending order, then by dest in descending order
order_table <- data_table[order(origin, -dest)]
order_table
# Doesn't work outside data_table
order(origin, -dest)
# Average aircraft_delay by month
order_table[, .(mean_delay=mean(aircraft_delay)), 
            by=.(month=month)]
# Sort output by month
order_table[, .(mean_delay=mean(aircraft_delay)), 
            by=.(month=month)][order(month)]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Selecting and Aggregating \protect\emph{Data Table} Columns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The operator \texttt{.SD} returns the \emph{data table} columns passed to the \texttt{by} operator, followed by all the other columns.
      \vskip1ex
      The operator \texttt{.SDcols} allows selecting the additional columns after the \texttt{.SD} operator columns.
      \vskip1ex
      The operator \texttt{.SDcols} selects the additional columns returned after the \texttt{.SD} operator columns.
      \vskip1ex
      Standard \texttt{R} functions can be used inside the brackets \texttt{"[]"} operator.
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Return all columns except origin and dest
data_table[1:7]
data_table[1:7, .SD, by=.(origin, dest)]
# Return first two rows from each month
data_table[, head(.SD, 2), by=.(month)]
# Return all columns except origin and dest
data_table[1:7, .SD, 
           by=.(origin, dest), .SDcols="aircraft_delay"]
# Return the columns carrier_delay, weather_delay, aircraft_delay
data_table[1:7, .SD, 
           by=.(origin, dest), 
           .SDcols=c("carrier_delay", "weather_delay", "aircraft_delay")]
# Calculate mean of weather_delay and aircraft_delay by origin
data_table[, 
           lapply(.SD, mean), 
           by=.(origin), 
           .SDcols=c("weather_delay", "aircraft_delay")]
# Or simply
data_table[, 
           .(weather_delay=mean(weather_delay), aircraft_delay=mean(aircraft_delay)), 
           by=.(origin)]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package \protect\emph{fst} for High Performance Data Management}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package 
      \href{https://cran.r-project.org/web/packages/fst/}{\emph{fst}} 
      provides functions for very fast writing and reading of \emph{data frames} from \emph{compressed binary files}.
      \vskip1ex
      The package \emph{fst} writes to \emph{compressed binary files} in the
\texttt{fst} fast-storage format. 
      \vskip1ex
      The package \emph{fst} uses the \texttt{LZ4} and \texttt{ZSTD} compression algorithms, and utilizes multithreaded (parallel) processing on multiple CPU cores.
      \vskip1ex
      The package \emph{fst} has extensive documentation:\\
      \hskip1em\url{http://www.fstpackage.org/}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<eval=FALSE>>=
# Install package fst
install.packages("fst")
# Load package fst
library(fst)
# get documentation for package fst
# get short description
packageDescription("fst")
# Load help page
help(package="fst")
# List all datasets in "fst"
data(package="fst")
# List all objects in "fst"
ls("package:fst")
# Remove fst from search path
detach("package:fst")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Writing and Reading Data Using Package \protect\emph{fst}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The easiest way to share data between \texttt{R} and \emph{Excel} is through \texttt{.csv} files.
      \vskip1ex
      The function \texttt{fst::write\_fst()} writes to \texttt{.fst} files over \texttt{10} times faster than the function \texttt{write.csv()}, and \texttt{300} times faster than function \texttt{cat()} write to \texttt{.csv} files!
      \vskip1ex
      The function \texttt{fst::fread()} reads from \texttt{.fst} files over \texttt{10} times faster than the function \texttt{read.csv()} from \texttt{.csv} files!
      \vskip1ex
      The function \texttt{fst::fst()} reads an \texttt{.fst} file and returns an \emph{fst\_table} reference object (pointer) to the data, without loading the data.
      \vskip1ex
      The \emph{fst\_table} reference provides access to the data similar to a regular \emph{data frame}, but it requires only a small amount of memory because the data isn't loaded into memory.
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Read a data frame from CSV file
dir_name <- "C:/Develop/R/lecture_slides/data/"
file_name <- file.path(dir_name, "weather_delays14.csv")
data.table::setDF(data_frame)
class(data_frame); dim(data_frame)
# Write data frame to .fst file in different ways
fst::write_fst(data_frame, path="data_frame.fst")
write.csv(data_frame, file="data_frame2.csv")
# microbenchmark speed of fst::write_fst()
library(microbenchmark)
summary(microbenchmark(
  fst=fst::write_fst(data_frame, path="data_frame.csv"),
  write_csv=write.csv(data_frame, file="data_frame2.csv"),
  cat=cat(unlist(data_frame), file="data_frame3.csv"),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
# fst::read_fst() reads the same data as read.csv()
all.equal(read.csv(file_name, stringsAsFactors=FALSE),
          fst::read_fst("data_frame.fst"))
# fst::read_fst() is 10 times faster than read.csv()
summary(microbenchmark(
  fst=fst::read_fst("data_frame.fst"),
  read_csv=read.csv(file_name),
  times=10))[, c(1, 4, 5)]  # end microbenchmark summary
# Create reference to data file similar to a data frame
fs_t <- fst::fst("data_frame.fst")
class(fs_t)
dim(data_frame); dim(fs_t)
# Get classes of data frame columns
sapply(data_frame, class)
sapply(fs_t, class)
# Get sizes of all objects in workspace
sort(sapply(mget(ls()), object.size))
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Homework Assignment}


%%%%%%%%%%%%%%%
\subsection{Homework Assignment}
\begin{frame}[t]{\subsecname}
\vspace{-1em}
\begin{block}{Required}
  \begin{itemize}[]
    \item Study all the lecture slides in \emph{FRE6871\_Lecture\_6.pdf}, and run all the code in \emph{FRE6871\_Lecture\_6.R}
  \end{itemize}
\end{block}
\begin{block}{Recommended}
  \begin{itemize}[]
    \item Read about \emph{PCA} in:\\
    \emph{pca-handout.pdf}\\
    \emph{pcaTutorial.pdf}\\
    \item Read about \emph{optimization methods}:\\
    \emph{Bolker Optimization Methods.pdf}\\
    \emph{Yollin Optimization.pdf}\\
    \emph{Boudt DEoptim Large Portfolio Optimization.pdf}\\
  \end{itemize}
\end{block}

\end{frame}


\end{document}
