% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, eval=FALSE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size='scriptsize', fig.width=4, fig.height=4)
options(width=60, dev='pdf')
options(digits=3)
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[10pt]{beamer}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
\usepackage{mathtools}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}



% Title page setup
\title[Investment Strategies]{Investment Strategies}
\subtitle{FRE6871 \& FRE7241, Spring 2017}
\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@nyu.edu}
\date{\today}



%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle



%%%%%%%%%%%%%%%
\section{Investor Risk Preferences and Portfolio Selection}


%%%%%%%%%%%%%%%
\subsection{Single Period Binary Gamble}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Consider a binary betting game (gamble) with the probability of winning equal to \texttt{p}, the winning amount (gain) equal to \texttt{b}, and the loss equal to \texttt{-a},
      \vskip1ex
      The investor makes no up-front payments, and either wins an amount \texttt{b}, or loses an amount \texttt{-a},
      \vskip1ex
      Assuming an investor makes decisions exclusively on the basis of the expected value (level) of future wealth, then she would choose to bet all her wealth on the gamble if its expected value is positive, and choose not to bet at all if its expected value is negative,
    \column{0.5\textwidth}
      <<results='asis',echo=FALSE,eval=FALSE>>=
library(xtable)
binbet_table <- data.frame(win=c("p", "b"), lose=c("q = 1 - p", "a"))
rownames(binbet_table) <- c("probability", "payout")
# print(xtable(binbet_table), comment=FALSE, size="tiny")
print(xtable(binbet_table), comment=FALSE)
      @
      The expected value of the gamble is equal to: $ev=p \cdot b - q \cdot a$,
      \vskip1ex
      The variance of the gamble is equal to: $var=p \cdot q \cdot (a+b)^2$,
      \vskip1ex
      Without loss of generality we can assume $p=q=\frac{1}{2}$,\\
      $ev=0.5 \cdot (b-a)$,\\
      $var=0.25 \cdot (a+b)^2$,
      \vskip1ex
      The \emph{Sharpe} ratio of the gamble is then equal to:
      \begin{displaymath}
        S_r=\frac{ev}{sqrt(var)}=\frac{(b-a)}{(a+b)}
      \end{displaymath}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Investor Utility and Fractional Betting}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{expected utility} hypothesis states that investor risk preferences are based on the expected value of the \emph{utility} of their wealth, instead of on the level of wealth,
      \vskip1ex
      In 1738 Daniel Bernoulli introduced the concept of \emph{logarithmic utility} in his work "\emph{Specimen Theoriae Novae de Mensura Sortis}" (New Theory of the Measurement of Risk),
      \vskip1ex
      \emph{Logarithmic utility} is defined as the logarithm of wealth, 
      \vskip1ex
      The expected value of \emph{logarithmic utility} for the binary gamble is equal to: $g(f)=p \cdot log(1+fb) + q \cdot log(1-fa)$,
      \vskip1ex
      Under \emph{logarithmic utility} investor preferences are based on the percentage change of their wealth, instead of the absolute change of their wealth,
      \vskip1ex
      An investor under \emph{logarithmic utility} doesn't bet either all her wealth or nothing at all, but instead bets only a certain fraction \texttt{f} of wealth, depending on the risk/return of the gamble,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<util_plot,eval=FALSE,echo=(-1),fig.show='hide'>>=
par(mar=c(5, 2, 2, 2), mgp=c(1.5, 0.5, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
# define utility
utility <- function(frac, p=0.5, a=1, b=4) {
  p*log(1+frac*b) + (1-p)*log(1-frac*a)
}  # end utility
# plot utility
curve(expr=utility, xlim=c(0, 1), 
      ylim=c(-0.5, 0.3), xlab="betting fraction", 
      ylab="utility", main="", lwd=2)
title(main="logarithmic utility", line=-0.8)
      @
      \vspace{-2.5em}
    \includegraphics[width=0.5\paperwidth]{figure/util_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimal Fractional Betting and the Kelly Criterion}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Given the odds and probability of winning, there's an optimal fraction \texttt{f} of wealth that the investor should risk on each bet, 
      \vskip1ex
      The betting fraction that maximizes the \emph{utility} can be found by equating the derivative of \emph{utility} to zero:
      \begin{displaymath}
        \frac{\mathrm{d}g(f)}{\mathrm{d}f}=\frac{p \cdot b}{1+fb} - \frac{q \cdot a}{1-fa} = 0
      \end{displaymath}
      \begin{displaymath}
        f=\frac{p}{a}-\frac{q}{b}=\frac{p \cdot b-q \cdot a}{a \cdot b}
      \end{displaymath}
      The optimal \texttt{f} is called the \emph{Kelly} fraction, and it depends on the parameters of the gamble,
      \vskip1ex
      The \emph{Kelly} fraction can be greater than \texttt{1} (leverage), or be negative (shorting),
      \vskip1ex
      If we assume $a=1$, then: $f=\frac{p(b+1)-1}{b}$
      \vskip1ex
      The \emph{Kelly} fraction is equal to the expected net winnings divided by the odds,
    \column{0.5\textwidth}
      \vspace{-1.5em}
      <<kelly_plot,eval=FALSE,echo=(-1),fig.show='hide'>>=
par(mar=c(5, 2, 2, 2), mgp=c(1.5, 0.5, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
# define and plot Kelly fraction
kelly <- function(b, p=0.5, a=1) {
  p/a - (1-p)/b
}  # end kelly
curve(expr=kelly, xlim=c(0, 5), 
      ylim=c(-2, 1), xlab="betting odds", 
      ylab="kelly", main="", lwd=2)
abline(h=0.5, lwd=2, col="red")
text(x=1.5, y=0.5, pos=3, cex=0.8, labels="max Kelly fraction=0.5")
title(main="Kelly fraction", line=-0.8)
      @
      \vspace{-2.5em}
    \includegraphics[width=0.5\paperwidth]{figure/kelly_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Kelly Fractional Betting}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Investors under \emph{logarithmic utility} are sensitive to the risk of ruin (losing all their wealth),
      \vskip1ex
      The loss amount \texttt{"a"} determines the risk of ruin, with larger values of \texttt{"a"} increasing the risk of ruin,
      \vskip1ex
      Therefore investors will choose a smaller betting fraction \texttt{f} for larger values of \texttt{"a"},
      \vskip1ex
      This means that even for huge odds in their favor, investors may choose not to bet all their wealth, because of the risk of ruin,
      \vskip1ex
      For example, if the betting odds are very large $b \to \infty$, then the \emph{Kelly} fraction: $f=\frac{p}{a}$,
      \vspace{-1em}
      <<kelly_max_plot,eval=FALSE,echo=(-1),fig.show='hide'>>=
par(mar=c(5, 2, 2, 2), mgp=c(1.5, 0.5, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
# plot several Kelly fractions
curve(expr=kelly, xlim=c(0, 5), 
      ylim=c(-1, 1.5), xlab="betting odds", 
      ylab="kelly", main="", lwd=2)
abline(h=0.5, lwd=2, col="red")
text(x=1.5, y=0.5, pos=3, cex=0.8, labels="a=1.0; max fraction=0.5")
kelly2 <- function(b) {kelly(b=b, a=0.5)}
curve(expr=kelly2, add=TRUE, main="", lwd=2)
abline(h=1.0, lwd=2, col="red")
text(x=1.5, y=1.0, pos=3, cex=0.8, labels="a=0.5; max fraction=1.0")
title(main="Kelly fraction", line=-0.8)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
    \includegraphics[width=0.5\paperwidth]{figure/kelly_max_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Multiperiod Betting}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Multiperiod betting consists of \texttt{n} rounds of betting, with random returns equal to $r_i$, 
      \vskip1ex
      Then after \texttt{n} rounds the wealth is equal to: $w=(1+r_1) (1+r_2) \ldots (1+r_n)$,
      \vskip1ex
      The expected value of wealth after \texttt{n} rounds is equal to: $E[w]=(1+E[r_i])^n$ (since the $r_i$ are i.i.d. - independent and identically distributed),
      \vskip1ex
      If only a fraction \texttt{f} of wealth is bet each time, then the wealth is equal to: $w=(1+f \cdot r_1) (1+f \cdot r_2) \ldots (1+f \cdot r_n)$, \\
      and the expected wealth is equal to: $E[w]=(1+f \cdot E[r_i])^n$,
      \vskip1ex
      The utility is equal to the logarithm of wealth: $g(w)=log(w)=\sum_{i=1}^n log(1+f \cdot r_i)$, \\
      and the expected utility is equal to: $E[g(w)]=n \cdot E[log(1+f \cdot r_i)]$,
      \vskip1ex
      The expected utility for multiperiod betting is \texttt{n} times the expected utility for single period betting,
      \vskip1ex
      The \emph{Kelly} fraction for multiperiod betting is the same as for single period betting,
    \column{0.5\textwidth}
      \vspace{-1em}
        <<multi_betting,eval=FALSE,echo=(-(1:2)),fig.show='hide'>>=
par(mar=c(5, 2, 2, 2), mgp=c(1.5, 0.5, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
set.seed(1121)  # reset random number generator
# simulated wealth path
wealth_path <- cumprod(1+runif(1000, 
                      min=-0.1, max=0.1))
plot(wealth_path, type="l", 
     lty="solid", xlab="", ylab="")
title(main="wealth path", line=-1)
      @
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/multi_betting-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating Wealth Paths}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Consider an investment strategy with a probability of gain equal to \texttt{win\_prob}, and with binary payouts equal to either \texttt{pro\_fit} or \texttt{-lo\_ss}, 
      \vskip1ex
      The investor makes no up-front payments, and either gains an amount equal to \texttt{pro\_fit}, or loses an amount \texttt{-lo\_ss},
      \vskip1ex
      Daily stock returns typically have a slightly greater probability of gaining over losing, and almost equal \texttt{pro\_fit} or \texttt{lo\_ss}, 
      \vskip1ex
      On the other hand returns on lottery tickets typically have very small probabilities of gains, but very large \texttt{pro\_fit} versus small \texttt{lo\_ss}, 
      \vskip1ex
      The investor makes no up-front payments, and either wins an amount equal to \texttt{pro\_fit}, or loses an amount \texttt{-lo\_ss},
      \vskip1ex
      Simulations in \texttt{R} can be accelerated by pre-computing a vector of random numbers, instead of generatng them one at a time in a loop,
      \vskip1ex
      Vectors of random numbers allow using \emph{vectorized} functions, instead of inefficient (slow) \texttt{while()} loops,
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
len_gth <- 1000  # number of simulation steps
n_simu <- 100  # number of simulation paths
# parameters for stock returns
prob_ab <- 0.51
pro_fit <- 0.001
lo_ss <- 0.001
# parameters for lottery ticket returns
prob_ab <- 0.01
pro_fit <- 0.001*51
lo_ss <- 0.001/(99/49)
# simulate random binary wealth paths
set.seed(1121)  # reset random number generator
path_s <- matrix(
  rbinom(n=n_simu*len_gth, size=1, prob=prob_ab), 
  ncol=n_simu)
path_s <- (pro_fit + lo_ss)*path_s - lo_ss
path_s <- matrixStats::colCumsums(path_s)
x11()
ts.plot(path_s, xlab="number of steps", ylab="wealth")
title(main="wealth paths for stocks", line=-1)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/simu_brown_barrier.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Binomial Multiperiod Betting}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Kelly} fraction for multiperiod betting can be found by maximizing the expected \emph{utility} of the final wealth distribution:
      \begin{multline*}
        g(f)=\sum_{k=0}^n \binom{n}{k} p^k q^{n-k} log((1+fb)^k (1-fa)^{n-k})\\
        =log(1+fb) \sum_{k=0}^n {\binom{n}{k} p^k q^{n-k} k} + \\
        log(1-fa) \sum_{k=0}^n {\binom{n}{k} p^k q^{n-k} (n-k)} \\
        =n \cdot p \cdot log(1+fb) + n \cdot q \cdot log(1-fa)
      \end{multline*}
      The above is just the single period \emph{utility} multiplied by the number of rounds of betting \texttt{n},
      \vskip1ex
      The \emph{Kelly} fraction \texttt{f} for multiperiod betting is the same as for single period betting:
      \begin{displaymath}
        f=\frac{p}{a}-\frac{q}{b}
      \end{displaymath}
    \column{0.5\textwidth}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimal Multiperiod Betting}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      In multiperiod betting the investor participates in \texttt{n} rounds of betting,
      \vskip1ex
      Each round of betting multiplies the wealth by either $(1+fb)$ or $(1-fa)$, 
      \vskip1ex
      If there were \texttt{i} wins and \texttt{j} losses, then the final wealth is equal to: 
      \begin{displaymath}
        w=(1+fb)^i \cdot (1-fa)^j
      \end{displaymath}
      The betting fraction that maximizes the final wealth is equal to:
      \begin{displaymath}
        f=\frac{pfreq}{a}-\frac{qfreq}{b}
      \end{displaymath}
      where $pfreq=\frac{i}{n}$ and $qfreq=1-pfreq$,
      \vskip1ex
      The most likely value of \texttt{pfreq} is equal to the probability of winning \texttt{p}, 
      \vskip1ex
      So the \emph{Kelly} fraction is the betting fraction that maximizes the final wealth in multiperiod betting, provided the fraction of wins is equal to the probability of winning \texttt{p},
    \column{0.5\textwidth}
      \vspace{-1em}
      <<kelly_multi,eval=FALSE,echo=(-1),fig.show='hide'>>=
par(mar=c(5, 2, 2, 2), mgp=c(1.5, 0.5, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
# wealth of multiperiod binary betting
wealth <- function(f, b=2, a=1, n=100, i=51) {
  (1+f*b)^i * (1-f*a)^(n-i)
}  # end wealth
curve(expr=wealth, xlim=c(0, 1), 
      xlab="betting fraction", 
      ylab="wealth", main="", lwd=2)
title(main="wealth of multiperiod betting", line=0.1)
      @
    \vspace{-2em}
    \includegraphics[width=0.5\paperwidth]{figure/kelly_multi-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Utility Function of Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Let the returns over a short time period be equal to \texttt{r}, with probability distribution \texttt{p(r)},
      \vskip1ex
      The mean return $\bar{r}$, and variance ${\sigma}^2$ are:
      \begin{displaymath}
        \bar{r} = \int {r \, p(r) \, \mathrm{d}r} \; ; \quad
        {\sigma}^2 = \int {(r - \bar{r})^2 \, p(r) \, \mathrm{d}r}
      \end{displaymath}
      Since the returns are over a short time period, we have: $r \ll 1$ and $\bar{r} \ll \sigma$, so that we can replace $r - \bar{r}$ with \texttt{r} as follows:
      \begin{displaymath}
        \int {(r - \bar{r})^2 \, p(r) \, \mathrm{d}r} \approx \int {r^2 \, p(r) \, \mathrm{d}r}
      \end{displaymath}
      The logarithmic utility $g(w)$ is given by:
      \begin{multline*}
        g(w) = \int {log(1+f \cdot r) \, p(r) \, \mathrm{d}r} \\
        \hspace*{-1em}
        = \int {(f \cdot r - \frac{(f \cdot r)^2}{2} + 
        \frac{(f \cdot r)^3}{3} - \frac{(f \cdot r)^4}{4}) \, p(r) \, \mathrm{d}r}\\
        \hspace*{-2em}
        = f\bar{r} - \frac{f^2 {\sigma}^2}{2} + \frac{f^3 {\sigma}^3 \hat{s}}{3} - \frac{f^4 {\sigma}^4 \hat{k}}{4}
      \end{multline*}
      Where $\hat{s}$ is the skewness, and $\hat{k}$ is the kurtosis,
    \column{0.5\textwidth}
      \vspace{-2em}
      <<utility_returns,eval=FALSE,echo=(-(1:2)),fig.show='hide'>>=
par(mar=c(5, 2, 2, 2), mgp=c(1.5, 0.5, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
library(HighFreq)
library(PerformanceAnalytics)
ts_rets <- rutils::env_etf$re_turns[, "VTI"]
c(mean(ts_rets), sd(ts_rets))
utility <- function(frac, r=ts_rets) {
sapply(frac, function (fract) sum(log(1+fract*r)))
}  # end utility
curve(expr=utility, 
      xlim=c(0.1, 2*PerformanceAnalytics::KellyRatio(R=ts_rets, method="full")), 
      xlab="kelly", ylab="utility", main="", lwd=2)
title(main="utility", line=-2)
      @
    \vspace{-3em}
    \includegraphics[width=0.5\paperwidth]{figure/utility_returns-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Kelly Criterion for Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Kelly} fraction can be found by equating the derivative of \emph{utility} to zero:
      \begin{displaymath}
        \frac{\mathrm{d}g(f)}{\mathrm{d}f} = \bar{r} - f{\sigma}^2 + f^2 {\sigma}^3 \hat{s} - f^3 {\sigma}^4 \hat{k} = 0
      \end{displaymath}
      Assuming $\hat{s}$ and $\hat{k}$ are small and can be neglected, we get:
      \begin{displaymath}
        f = \frac{\bar{r}}{{\sigma}^2} = \frac{S_r}{\sigma} \; ; \quad g(w) = \frac{1}{2} \frac{{\bar{r}}^2}{{\sigma}^2} = \frac{1}{2} S_r^2
      \end{displaymath}
      Where $S_r$ is the \emph{Sharpe} ratio, 
      \vskip1ex
      The \emph{Kelly} fraction is equal to the \emph{Sharpe} ratio divided by the \emph{standard deviation},
      \vskip1ex
      The optimal utility $g(w)$ is equal to half the \emph{Sharpe} ratio squared,
      \vskip1ex
      The \emph{standard deviation} and \emph{Sharpe} ratio are calculated over the same time interval as the returns (not annualized),
    \column{0.5\textwidth}
    \vspace{-1em}
      <<eval=FALSE,echo=(-(1:3))>>=
par(mar=c(5, 2, 2, 2), mgp=c(1.5, 0.5, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
library(PerformanceAnalytics)
ts_rets <- rutils::env_etf$re_turns[, "VTI"]
PerformanceAnalytics::KellyRatio(R=ts_rets, method="full")
      @
%    \vspace{-1em}
%    \includegraphics[width=0.5\paperwidth]{figure/kelly_returns-1}
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Active Investment Strategies}


%%%%%%%%%%%%%%%
\subsection{draft: \protect\emph{RSI} Price Technical Indicator}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Relative Strength Index} (\emph{RSI}) is defined as the weighted average of prices over a rolling window:
      \begin{displaymath}
        P_i^{RSI} = (1-\exp(-\lambda)) \sum_{j=0}^{\infty} \exp(-\lambda j) P_{i-j}
      \end{displaymath}
      Where the decay parameter $\lambda$ determines the rate of decay of the \emph{RSI} weights, with larger values of $\lambda$ producing faster decay, giving more weight to recent prices, and vice versa, 
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(HighFreq)  # load package HighFreq
# Get close prices and calculate close-to-close returns
# price_s <- quantmod::Cl(rutils::env_etf$VTI)
price_s <- quantmod::Cl(HighFreq::SPY)
colnames(price_s) <- rutils::get_name(colnames(price_s))
re_turns <- TTR::ROC(price_s)
re_turns[1] <- 0
# Calculate the RSI indicator
r_si <- TTR::RSI(price_s, 2)
# Calculate the long (up) and short (dn) signals
sig_up <- ifelse(r_si < 10, 1, 0)
sig_dn <- ifelse(r_si > 90, -1, 0)
# Lag signals by one period
sig_up <- rutils::lag_xts(sig_up, 1)
sig_dn <- rutils::lag_xts(sig_dn, 1)
# Replace NA signals with zero position
sig_up[is.na(sig_up)] <- 0
sig_dn[is.na(sig_dn)] <- 0
# Combine up and down signals into one
sig_nals <- sig_up + sig_dn
# Calculate cumulative returns
eq_up <- exp(cumsum(sig_up*re_turns))
eq_dn <- exp(cumsum(-1*sig_dn*re_turns))
eq_all <- exp(cumsum(sig_nals*re_turns))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/rsi_indic.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Plot daily cumulative returns in panels
in_dex <- endpoints(re_turns, on="days")
plot.zoo( cbind(eq_all, eq_up, eq_dn)[in_dex], lwd=c(2, 2, 2), 
          ylab=c("Total","Long","Short"), col=c("red","green","blue"),
          main=paste("RSI(2) strategy for", colnames(price_s), "from", 
                     format(start(re_turns), "%B %Y"), "to", 
                     format(end(re_turns), "%B %Y")))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{EWMA} Price Technical Indicator}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Exponentially Weighted Moving Average Price} (\emph{EWMA}) is defined as the weighted average of prices over a rolling window:
      \begin{displaymath}
        P_i^{EWMA} = (1-\exp(-\lambda)) \sum_{j=0}^{\infty} \exp(-\lambda j) P_{i-j}
      \end{displaymath}
      Where the decay parameter $\lambda$ determines the rate of decay of the \emph{EWMA} weights, with larger values of $\lambda$ producing faster decay, giving more weight to recent prices, and vice versa, 
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(HighFreq)  # load package HighFreq
# select OHLC data
oh_lc <- rutils::env_etf$VTI["/2011"]
# calculate close prices
cl_ose <- Cl(oh_lc)
# define aggregation window and decay parameter
win_dow <- 51
lamb_da <- 0.05
# calculate EWMA prices
weight_s <- exp(-lamb_da*1:win_dow)
weight_s <- weight_s/sum(weight_s)
ew_ma <- stats::filter(cl_ose, filter=weight_s, sides=1)
ew_ma[1:(win_dow-1)] <- ew_ma[win_dow]
ew_ma <- xts(cbind(cl_ose, ew_ma), 
             order.by=index(oh_lc))
colnames(ew_ma) <- c("VTI", "VTI EWMA")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/ewma_indic.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# plot EWMA prices with custom line colors
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("orange", "blue")
chart_Series(ew_ma, theme=plot_theme, 
             name="EWMA prices")
legend("top", legend=colnames(ew_ma), 
       inset=0.1, bg="white", lty=c(1, 1), lwd=c(2, 2), 
       col=plot_theme$col$line.col, bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating The \protect\emph{EWMA} Crossover Strategy}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      In a trend-following \emph{EWMA Crossover} strategy, the risk position switches depending if the current price is above or below the \emph{EWMA},
      \vskip1ex
      If the current price crosses above the \emph{EWMA}, then the strategy switches its risk position to a fixed unit of long risk, and if it crosses below, to a fixed unit of short risk, 
      \vskip1ex
      The strategy holds the same position until the \emph{EWMA} crosses over the current price (either from above or below), and then it switches its position,
      \vskip1ex
      The strategy is therefore always either in a long risk, or in a short risk position,
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(HighFreq)  # load package HighFreq
# determine dates right after EWMA has crossed prices
in_dic <- sign(cl_ose - ew_ma[, 2])
trade_dates <- (rutils::diff_xts(in_dic) != 0)
trade_dates <- which(trade_dates) + 1
# calculate positions, either: -1, 0, or 1
position_s <- rep(NA_integer_, NROW(cl_ose))
position_s[1] <- 0
position_s[trade_dates] <- 
  rutils::lag_xts(in_dic)[trade_dates]
position_s <- na.locf(position_s)
position_s <- xts(position_s, order.by=index(oh_lc))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/ewma_strat.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# plot EWMA prices with position shading
chart_Series(ew_ma, theme=plot_theme, 
             name="EWMA prices")
add_TA(position_s > 0, on=-1,
       col="lightgreen", border="lightgreen")
add_TA(position_s < 0, on=-1,
       col="lightgrey", border="lightgrey")
legend("top", legend=colnames(ew_ma), 
       inset=0.1, bg="white", lty=c(1, 1), lwd=c(2, 2), 
       col=plot_theme$col$line.col, bty="n")
@
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Performance of \protect\emph{EWMA} Crossover Strategy}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The strategy trades at the \emph{Open} price on the next day after prices cross the \emph{EWMA}, since in practice it may not be possible to trade immediately, 
      \vskip1ex
      The Profit and Loss (\emph{PnL}) on a trade date is the sum of the realized \emph{PnL} from closing the old position, plus the unrealized \emph{PnL} after opening the new position, 
      <<echo=(-(1:1)),eval=FALSE>>=
library(HighFreq)  # load package HighFreq
# calculate open and lagged prices
op_en <- Op(oh_lc)
prices_lag <- rutils::lag_xts(cl_ose)
position_lagged <- rutils::lag_xts(position_s)
# calculate daily profits and losses
re_turns <- position_lagged*(cl_ose - prices_lag)
re_turns[trade_dates] <- 
  position_lagged[trade_dates] * 
  (op_en[trade_dates] - prices_lag[trade_dates]) +
  position_s[trade_dates] * 
  (cl_ose[trade_dates] - op_en[trade_dates])
# calculate annualized Sharpe ratio of strategy returns
sqrt(260)*sum(re_turns)/sd(re_turns)/NROW(re_turns)
pnl_s <- cumsum(re_turns)
pnl_s <- cbind(cl_ose-as.numeric(cl_ose[1, ]), pnl_s)
colnames(pnl_s) <- c("VTI", "EWMA PnL")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/ewma_strat_pnl.png}
      \vspace{-2em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(HighFreq)  # load package HighFreq
# plot EWMA PnL with position shading
chart_Series(pnl_s, theme=plot_theme, 
             name="Performance of EWMA Strategy")
add_TA(position_s > 0, on=-1,
       col="lightgreen", border="lightgreen")
add_TA(position_s < 0, on=-1,
       col="lightgrey", border="lightgrey")
legend("top", legend=colnames(pnl_s), 
       inset=0.05, bg="white", lty=c(1, 1), lwd=c(2, 2), 
       col=plot_theme$col$line.col, bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Function for \protect\emph{EWMA} Crossover Strategy}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The \emph{EWMA} strategy can be performed by a single function, which allows the analysis of its performance depending on its parameters,
      \vskip1ex
      The function \texttt{simu\_ewma()} performs a simulation of the \emph{EWMA} strategy, given an \emph{OHLC} time series of prices, and a decay parameter $\lambda$, 
      \vskip1ex
      The function \texttt{simu\_ewma()} returns the \emph{EWMA} strategy positions and returns, in a two-column \emph{xts} time series, 
    \column{0.6\textwidth}
      \vspace{-2em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(HighFreq)  # load package HighFreq
simu_ewma <- function(oh_lc, lamb_da=0.05, win_dow=51) {
  # calculate EWMA prices
  weight_s <- exp(-lamb_da*1:win_dow)
  weight_s <- weight_s/sum(weight_s)
  cl_ose <- Cl(oh_lc)
  ew_ma <- stats::filter(as.numeric(cl_ose), filter=weight_s, sides=1)
  ew_ma[1:(win_dow-1)] <- ew_ma[win_dow]
  # determine dates right after EWMA has crossed prices
  in_dic <- xts(sign(as.numeric(cl_ose) - ew_ma), order.by=index(oh_lc))
  trade_dates <- (rutils::diff_xts(in_dic) != 0)
  trade_dates <- which(trade_dates) + 1
  trade_dates <- trade_dates[trade_dates<NROW(oh_lc)]
  # calculate positions, either: -1, 0, or 1
  position_s <- rep(NA_integer_, NROW(cl_ose))
  position_s[1] <- 0
  position_s[trade_dates] <- rutils::lag_xts(in_dic)[trade_dates]
  position_s <- xts(na.locf(position_s), order.by=index(oh_lc))
  op_en <- Op(oh_lc)
  prices_lag <- rutils::lag_xts(cl_ose)
  position_lagged <- rutils::lag_xts(position_s)
  # calculate daily profits and losses
  re_turns <- position_lagged*(cl_ose - prices_lag)
  re_turns[trade_dates] <- 
    position_lagged[trade_dates] * 
    (op_en[trade_dates] - prices_lag[trade_dates]) +
    position_s[trade_dates] * 
    (cl_ose[trade_dates] - op_en[trade_dates])
  out_put <- cbind(position_s, re_turns)
  colnames(out_put) <- c("position_s", "re_turns")
  out_put
}  # end simu_ewma
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating Multiple \protect\emph{EWMA} Strategies}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The performance of the trend-following \emph{EWMA} strategy depends on the decay parameter $\lambda$, 
      \vskip1ex
      The best performing strategy can be found by performing an \texttt{sapply()} loop over a vector of $\lambda$ parameters,
      <<echo=TRUE,eval=FALSE>>=
lamb_das <- seq(0.001, 0.03, 0.001)
sharpe_ratios <- sapply(lamb_das, function(lamb_da) {
  re_turns <- simu_ewma(oh_lc=oh_lc, 
              lamb_da=lamb_da)[, 2]
  # calculate annualized Sharpe ratio of strategy returns
  sqrt(260)*sum(re_turns)/sd(re_turns)/NROW(re_turns)
})  # end sapply
plot(x=lamb_das, y=sharpe_ratios, t="l", 
     main="Performance of EWMA trend-following strategies 
     as function of the decay parameter lambda")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ewma_trending.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimal Trend-following \protect\emph{EWMA} Strategy}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The best performing trend-following \emph{EWMA} strategy has a relatively small $\lambda$ parameter, corresponding to slower weight decay (giving more weight to past prices), and producing less frequent trading, 
      <<echo=TRUE,eval=FALSE>>=
# simulate best performing strategy
ewma_trend <- simu_ewma(oh_lc=oh_lc, 
        lamb_da=lamb_das[which.max(sharpe_ratios)])
position_s <- ewma_trend[, 1]
pnl_s <- cumsum(ewma_trend[, 2])
pnl_s <- cbind(cl_ose-as.numeric(cl_ose[1, ]), 
              pnl_s)
colnames(pnl_s) <- c("VTI", "EWMA PnL")
# plot EWMA PnL with position shading
chart_Series(pnl_s, theme=plot_theme, 
             name="Performance of EWMA Strategy")
add_TA(position_s > 0, on=-1,
       col="lightgreen", border="lightgreen")
add_TA(position_s < 0, on=-1,
       col="lightgrey", border="lightgrey")
legend("top", legend=colnames(pnl_s), 
       inset=0.05, bg="white", lty=c(1, 1), lwd=c(2, 2), 
       col=plot_theme$col$line.col, bty="n")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ewma_best_trend.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Mean-reverting \protect\emph{EWMA} Strategies}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The trend-following \emph{EWMA} strategy experiences losses for large values of the decay parameter $\lambda$ (for our data sample - for different data this may not be true), 
      \vskip1ex
      Reverting the rules of the trend-following \emph{EWMA} strategy creates a mean-reverting strategy,
      <<echo=TRUE,eval=FALSE>>=
lamb_das <- seq(0.05, 0.12, 0.01)
sharpe_ratios <- sapply(lamb_das, function(lamb_da) {
  re_turns <- -simu_ewma(oh_lc=oh_lc, 
              lamb_da=lamb_da)[, 2]
  # calculate annualized Sharpe ratio of strategy returns
  sqrt(260)*sum(re_turns)/sd(re_turns)/NROW(re_turns)
})  # end sapply
plot(x=lamb_das, y=sharpe_ratios, t="l", 
     main="Performance of EWMA mean-reverting strategies 
     as function of the decay parameter lambda")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ewma_reverting.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Optimal Mean-reverting \protect\emph{EWMA} Strategy}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The best performing mean-reverting \emph{EWMA} strategy has a relatively large $\lambda$ parameter, corresponding to faster weight decay (giving more weight to recent prices), and producing more frequent trading, 
      <<echo=TRUE,eval=FALSE>>=
# simulate best performing strategy
ewma_revert <- -simu_ewma(oh_lc=oh_lc, 
        lamb_da=lamb_das[which.max(sharpe_ratios)])
position_s <- ewma_revert[, 1]
pnl_s <- cumsum(ewma_revert[, 2])
pnl_s <- cbind(cl_ose-as.numeric(cl_ose[1, ]), 
              pnl_s)
colnames(pnl_s) <- c("VTI", "EWMA PnL")
# plot EWMA PnL with position shading
chart_Series(pnl_s, theme=plot_theme, 
             name="Performance of EWMA Strategy")
add_TA(position_s > 0, on=-1,
       col="lightgreen", border="lightgreen")
add_TA(position_s < 0, on=-1,
       col="lightgrey", border="lightgrey")
legend("top", legend=colnames(pnl_s), 
       inset=0.05, bg="white", lty=c(1, 1), lwd=c(2, 2), 
       col=plot_theme$col$line.col, bty="n")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ewma_best_revert.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Combining Trend-following and Mean-reverting Strategies}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The returns of trend-following and mean-reverting strategies are usually negatively correlated to each other, so combining them can achieve significant diversification of risk, 
      <<echo=TRUE,eval=FALSE>>=
# calculate correlation between trend-following and mean-reverting strategies
trend_ing <- ewma_trend[, 2]
colnames(trend_ing) <- "trend"
revert_ing <- ewma_revert[, 2]
colnames(revert_ing) <- "revert"
corr_matrix <- cor(cbind(trend_ing, revert_ing))
corr_matrix
# calculate combined strategy
re_turns <- trend_ing + revert_ing
# calculate annualized Sharpe ratio of strategy returns
sapply(cbind(rutils::diff_xts(cl_ose), 
    trend_ing, revert_ing, re_turns), 
      function(re_turns) {
        sqrt(260)*sum(re_turns)/sd(re_turns)/NROW(re_turns)
      })  # end sapply
pnl_s <- cumsum(re_turns)
pnl_s <- cbind(cl_ose-as.numeric(cl_ose[1, ]), 
              pnl_s)
colnames(pnl_s) <- c("VTI", "EWMA combined PnL")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ewma_combined.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
chart_Series(pnl_s, theme=plot_theme, 
             name="Performance of EWMA Strategies")
add_TA(cumsum(trend_ing), on=1, lwd=2, col="green")
add_TA(cumsum(revert_ing), on=1, lwd=2, col="magenta2")
legend("topleft", legend=c(colnames(pnl_s), "trending", "reverting"), 
       inset=0.05, bg="white", lty=rep(1, 4), lwd=rep(4, 4), 
       col=c(plot_theme$col$line.col, "green", "magenta2"), bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Ensemble of \protect\emph{EWMA} Strategies}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Instead of selecting the best performing \emph{EWMA} strategy, one can choose a weighted average of strategies (ensemble), which corresponds to allocating positions according to the weights, 
      \vskip1ex
      The weights can be chosen to be proportional to the Sharpe ratios of the \emph{EWMA} strategies, 
      <<echo=TRUE,eval=FALSE>>=
lamb_das <- seq(0.001, 0.03, 0.001)
re_turns <- lapply(lamb_das, function(lamb_da) {
  simu_ewma(oh_lc=oh_lc, lamb_da=lamb_da)[, 2]
})  # end sapply
re_turns <- do.call(merge, re_turns)
weight_s <- sharpe_ratios/sum(sharpe_ratios)
re_turns <- re_turns %*% weight_s
re_turns <- xts(re_turns, order.by=index(oh_lc))
pnl_s <- cumsum(re_turns)
pnl_s <- cbind(cl_ose-as.numeric(cl_ose[1, ]), 
              pnl_s)
colnames(pnl_s) <- c("VTI", "EWMA PnL")
# plot EWMA PnL without position shading
chart_Series(pnl_s, theme=plot_theme, 
             name="Performance of EWMA Strategy")
legend("top", legend=colnames(pnl_s), 
       inset=0.05, bg="white", lty=c(1, 1), lwd=c(2, 2), 
       col=plot_theme$col$line.col, bty="n")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ewma_ensemble.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Moving Average Technical Indicators}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The Volume-Weighted Average Price (\emph{VWAP}) is defined as the sum of prices multiplied by trading volumes, divided by the sum of volumes, 
      \vskip1ex
      Moving averages (such as \emph{VWAP}) are often used to define technical indicators (trading signals), 
      <<echo=(-(1:1)),eval=FALSE>>=
library(HighFreq)  # load package HighFreq
# calculate open, close, and lagged prices
op_en <- Op(rutils::env_etf$VTI)
cl_ose <- Cl(rutils::env_etf$VTI)
prices_lag <- rutils::lag_xts(cl_ose)
# define aggregation window and calculate VWAP
win_dow <- 150
VTI_vwap <- HighFreq::roll_vwap(rutils::env_etf$VTI, 
            win_dow=win_dow)
# calculate VWAP indicator
in_dic <- sign(cl_ose - VTI_vwap)
# determine dates right after VWAP has crossed prices
trade_dates <- (rutils::diff_xts(in_dic) != 0)
trade_dates <- which(trade_dates) + 1
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/vwap_indic.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# plot prices and VWAP
chart_Series(x=cl_ose, 
  name="VTI prices", col="orange")
add_TA(VTI_vwap, on=1, lwd=2, col="blue")
legend("top", legend=c("VTI", "VWAP"), 
bg="white", lty=c(1, 1), lwd=c(2, 2), 
col=c("orange", "blue"), bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Moving Average Crossover Strategy}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      In a trend-following \emph{Moving Average Crossover} strategy, when the current price crosses above the \emph{VWAP}, then the strategy switches its position to long risk, and vice versa, 
      \vskip1ex
      The strategy trades at the \emph{Open} price in the next period after prices cross the \emph{VWAP}, to reflect that in practice it's impossible to trade immediately, 
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(HighFreq)  # load package HighFreq
# calculate positions, either: -1, 0, or 1
position_s <- NA*numeric(NROW(rutils::env_etf$VTI))
position_s[1] <- 0
position_s[trade_dates] <- in_dic[trade_dates]
position_s <- na.locf(position_s)
position_s <- xts(position_s, order.by=index((rutils::env_etf$VTI)))
position_lagged <- rutils::lag_xts(position_s)
# calculate daily profits and losses
pnl_s <- position_lagged*(cl_ose - prices_lag)
pnl_s[trade_dates] <- position_lagged[trade_dates] * 
  (op_en[trade_dates] - prices_lag[trade_dates]) +
  position_s[trade_dates] * 
  (cl_ose[trade_dates] - op_en[trade_dates])
# calculate annualized Sharpe ratio of strategy returns
sqrt(260)*sum(pnl_s)/sd(pnl_s)/NROW(pnl_s)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/vwap_strat.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# plot prices and VWAP
pnl_s <- xts(cumsum(pnl_s), order.by=index((rutils::env_etf$VTI)))
chart_Series(x=(cl_ose-as.numeric(cl_ose[1, ])), name="VTI prices", col="orange")
add_TA(pnl_s, on=1, lwd=2, col="blue")
add_TA(position_s > 0, on=-1,
       col="lightgreen", border="lightgreen")
add_TA(position_s < 0, on=-1,
       col="lightgrey", border="lightgrey")
legend("top", legend=c("VTI", "VWAP strategy"), 
       inset=0.1, bg="white", lty=c(1, 1), lwd=c(2, 2), 
       col=c("orange", "blue"), bty="n")
@
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Backtesting Active Investment Strategies}


%%%%%%%%%%%%%%%
\subsection{Look-back Intervals for Overlapping Aggregations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Overlapping aggregations can be specified by a vector of \emph{look-back} intervals attached at \emph{end points}, 
      \vskip1ex
      For example, we may specify aggregations at monthly \emph{end points}, over overlapping 12-month \emph{look-back} intervals, 
      \vskip1ex
      The \emph{look-back} intervals are spanned by the vectors of \emph{start points} and \emph{end points}, 
      \vskip1ex
      The \emph{start points} are the \emph{end points} lagged by the length of the \emph{look-back} interval, 
      \vskip1ex
      The variable \texttt{look\_back} is equal to the number of \emph{end points} in the \emph{look-back} interval, 
      \vskip1ex
      The variable \texttt{look\_backs} is a list of \emph{look-back} intervals, 
      \vskip1ex
      In the warmup period the length of the \emph{look-back} intervals expands from zero to the variable \texttt{look\_back}, 
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
library(HighFreq)
# define oh_lc series and look-back interval
oh_lc <- rutils::env_etf$VTI["/2011"]
look_back <- 12
# calculate end of month end_points
end_points <- xts::endpoints(oh_lc, on="months")
# start_points are end_points lagged by look_back
len_gth <- NROW(end_points)
start_points <- 
  end_points[c(rep_len(1, look_back-1), 
               1:(len_gth-look_back+1))]
# create list of look-back intervals
look_backs <- lapply(2:len_gth, 
  function(in_dex) start_points[in_dex]:end_points[in_dex])
# second warmup interval spans only two months
warm_up <- oh_lc[look_backs[[3]]]
dim(warm_up)
head(warm_up)
tail(warm_up)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Aggregation Function for \protect\emph{EWMA} Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The function \texttt{agg\_regate()} calculates the \emph{Sharpe} ratios of \emph{EWMA} strategies, for a given vector of lambda decay parameters,
      \vskip1ex
      The function \texttt{agg\_regate()} performs an \texttt{sapply()} loop over a vector of lambdas, calls the function \texttt{simu\_ewma()}, and then calculates the \emph{Sharpe} ratios,
      \vskip1ex
      The function \texttt{agg\_regate()} accepts three arguments: a time series, a vector of lambda parameters, and the dots \texttt{"..."}  argument to be passed to \texttt{simu\_ewma()},
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# source EWMA model simu_ewma() from file
source("C:/Develop/R/scripts/ewma_model.R")
# define aggregation function
agg_regate <- function(oh_lc, lamb_das, ...) {
  sapply(lamb_das, function(lamb_da) {
    # simulate EWMA strategy and calculate Sharpe ratio
    re_turns <- 
      simu_ewma(oh_lc=oh_lc, lamb_da=lamb_da, ...)[, "re_turns"]
    sqrt(260)*sum(re_turns)/sd(re_turns)/NROW(re_turns)
  })  # end sapply
}  # end agg_regate
# define EWMA parameters
win_dow <- 51
lamb_das <- seq(0.001, 0.01, 0.001)
# perform aggregation
agg_regate(oh_lc, lamb_das, win_dow)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Performing Overlapping Aggregations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Overlapping aggregations can be calculated by performing an \texttt{lapply()} loop over the list of \emph{look-back} intervals (\texttt{look\_backs}),
      \vskip1ex
      The resulting list of aggregations can then be collapsed into an \emph{xts} series using the function \texttt{do\_call\_rbind()}, 
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# adjust end_points so they are greater than EWMA win_dow
end_points[(end_points > 0) & 
  (end_points <= win_dow)] <- win_dow+1
# start_points are end_points lagged by look_back
len_gth <- NROW(end_points)
start_points <- end_points[c(rep_len(1, look_back-1), 
               1:(len_gth-look_back+1))]
# create list of look-back intervals
look_backs <- lapply(2:len_gth, 
  function(in_dex) start_points[in_dex]:end_points[in_dex])
# perform lapply() loop over look_backs
agg_s <- lapply(look_backs, 
  function(look_back, ...) {
    agg_regate(oh_lc[look_back], ...)
    }, lamb_das=lamb_das, win_dow=win_dow)  # end lapply
# rbind list into single xts or matrix
agg_s <- rutils::do_call_rbind(agg_s)
if (!is.xts(agg_s))
  agg_s <- xts(agg_s, order.by=index(oh_lc[end_points]))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{old: Functional for Performing Overlapping Aggregations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Overlapping aggregations can be performed by performing an \texttt{lapply()} loop over the \emph{end points}, 
      \vskip1ex
      The list of aggregations can then be collapsed into an \emph{xts} series using the function \texttt{do\_call\_rbind()}, 
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
roll_agg <- function(x_ts, end_points, look_back, FUN, ...) {
  len_gth <- NROW(end_points)
  # start_points are multi-period lag of end_points
  start_points <- end_points[c(rep_len(1, look_back-1), 1:(len_gth-look_back+1))]
  # perform lapply() loop over length of end_points
  agg_s <- lapply(2:len_gth, 
                  function(in_dex) {
                    FUN(x_ts[start_points[in_dex]:end_points[in_dex]], ...)
                  })  # end lapply
  # rbind list into single xts or matrix
  agg_s <- rutils::do_call_rbind(agg_s)
  if (!is.xts(agg_s))
    agg_s <- xts(agg_s, order.by=index(x_ts[end_points]))
  agg_s
}  # end roll_agg
sharpe_ratios <- roll_agg(x_ts=oh_lc, 
                          end_points=end_points, 
                          look_back=look_back, 
                          FUN=agg_regate, 
                          lamb_das=lamb_das,
                          win_dow=win_dow)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Functional for Performing Overlapping Aggregations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The functional \texttt{roll\_agg()} performs an \texttt{lapply()} loop over a list of \emph{look-back} intervals, each time subsetting the input \emph{xts} series, and passing it into an aggregation function \texttt{FUN()},
      \vskip1ex
      The functional \texttt{roll\_agg()} also accepts the dots \texttt{"..."} argument, and passes it into \texttt{FUN()},
      \vskip1ex
      The functional \texttt{roll\_agg()} returns an \emph{xts} series of the aggregations produced by \texttt{FUN()}, of length equal to the input list \texttt{look\_backs}, 
      \vskip1ex
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
roll_agg <- function(x_ts, look_backs, FUN, ...) {
  # perform lapply() loop over look_backs
  agg_s <- lapply(look_backs, 
                  function(look_back) {
                    FUN(x_ts[look_back], ...)
                  })  # end lapply
  # rbind list into single xts or matrix
  agg_s <- rutils::do_call_rbind(agg_s)
  if (!is.xts(agg_s))
    agg_s <- xts(agg_s, order.by=
                   index(x_ts[unlist(lapply(look_backs, last))]))
  agg_s
}  # end roll_agg
sharpe_ratios <- roll_agg(x_ts=oh_lc, 
                          look_backs=look_backs, 
                          FUN=agg_regate, 
                          lamb_das=lamb_das,
                          win_dow=win_dow)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Performance of \protect\emph{EWMA} Strategies}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The performance of \emph{EWMA} strategies depends on the $\lambda$ parameter, 
      \vskip1ex
      The performance of different \emph{EWMA} strategies can be aggregated over \emph{look-back} intervals, 
      <<echo=TRUE,eval=FALSE>>=
source("C:/Develop/R/scripts/ewma_model.R")
lamb_das <- seq(0.01, 1.0, 0.1)
# perform lapply() loop over lamb_das
re_turns <- lapply(lamb_das, function(lamb_da) {
  # simulate EWMA strategy and calculate re_turns
  simu_ewma(oh_lc=oh_lc, lamb_da=lamb_da, win_dow=win_dow)[, "re_turns"]
})  # end lapply
re_turns <- do.call(merge, re_turns)
colnames(re_turns) <- paste0("lambda=", lamb_das)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/ewma_returns.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# plot EWMA strategies with custom line colors
plot_theme <- chart_theme()
plot_theme$col$line.col <- colorRampPalette(c("red", "blue"))(NCOL(re_turns))
chart_Series(cumsum(re_turns), theme=plot_theme, name="Cumulative Returns of EWMA Strategies")
legend("bottomleft", legend=colnames(re_turns), 
       inset=0.02, bg="white", cex=0.8, lwd=rep(6, NCOL(re_turns)), 
       col=plot_theme$col$line.col, bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating \protect\emph{EWMA} Strategies Using Parallel Computing}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Simulating \emph{EWMA} strategies naturally lends itself to parallel computing, since the simulations are independent from each other, 
      \vskip1ex
      The function \texttt{parLapply()} is similar to \texttt{lapply()}, and performs apply loops under \emph{Windows}, using parallel computing on several CPU cores, 
      \vskip1ex
      The resulting list of time series can then be collapsed into a single \emph{xts} series using the functions \texttt{do\_call()} and \texttt{merge()}, 
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# initialize compute cluster under Windows
library(parallel)
clus_ter <- makeCluster(detectCores()-1)
win_dow <- 51
clusterExport(clus_ter, 
              varlist=c("oh_lc", "win_dow", "simu_ewma"))
# perform parallel loop over lamb_das under Windows
lamb_das <- seq(0.01, 1.0, 0.1)
re_turns <- parLapply(clus_ter, lamb_das, function(lamb_da) {
  library(quantmod)
  # simulate EWMA strategy and calculate re_turns
  simu_ewma(oh_lc=oh_lc, 
            lamb_da=lamb_da, win_dow=win_dow)[, "re_turns"]
})  # end parLapply
# perform parallel loop over lamb_das under Mac-OSX or Linux
re_turns <- mclapply(lamb_das, function(lamb_da) {
  library(quantmod)
  # simulate EWMA strategy and calculate re_turns
  simu_ewma(oh_lc=oh_lc, 
            lamb_da=lamb_da, win_dow=win_dow)[, "re_turns"]
})  # end mclapply
stopCluster(clus_ter)  # stop R processes over cluster under Windows
re_turns <- do.call(merge, re_turns)
colnames(re_turns) <- paste0("lambda=", lamb_das)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Aggregating \protect\emph{EWMA} Strategies}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Overlapping aggregations can be calculated by performing an \texttt{lapply()} loop over a list of \emph{look-back} intervals (\texttt{look\_backs}),
      \vskip1ex
      Non-overlapping aggregations can also be calculated over a list of \emph{look-forward} intervals (\texttt{look\_fwds}),
      \vskip1ex
      The \emph{look-back} intervals should not overlap with the \emph{look-forward} intervals, 
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
look_back <- 12
# calculate end of month end_points
end_points <- xts::endpoints(re_turns, on="months")
# start_points are end_points lagged by look_back
len_gth <- NROW(end_points)
start_points <- end_points[c(rep_len(1, look_back-1), 1:(len_gth-look_back+1))]
# Create a named list of look-back intervals.
look_backs <- lapply(2:len_gth, 
                     function(in_dex) start_points[in_dex]:end_points[in_dex])
names(look_backs) <- index(re_turns)[end_points[2:len_gth]]
# Perform loop over look_back intervals and calculate past_aggs. 
past_aggs <- sapply(look_backs, 
                   function(look_back) {
                     sapply(re_turns[look_back], sum)  # end sapply
                   })  # end sapply
past_aggs <- t(past_aggs)
past_aggs <- xts::as.xts(past_aggs)
# define forward (future) endpoints
fwd_points <- end_points[c(2:len_gth, len_gth)]
# create named list of look-forward intervals
look_fwds <- lapply(2:(len_gth-1), 
                    function(in_dex) (end_points[in_dex]+1):fwd_points[in_dex])
names(look_fwds) <- index(re_turns)[end_points[2:(len_gth-1)]]
# calculate cumulative forward returns
fwd_rets <- sapply(look_fwds, 
              function(look_fwd) {
                sapply(re_turns[look_fwd], sum)  # end sapply
              })  # end sapply
fwd_rets <- t(fwd_rets)
fwd_rets <- xts::as.xts(fwd_rets)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Performing Backtesting}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Backtesting} is the testing of a forecasting model using historical data, 
      \vskip1ex
      \emph{Backtesting} is a type of \emph{cross-validation} applied to time series data,
      \vskip1ex
      \emph{Backtesting} is performed by \emph{training} the model on past data defined by the \emph{look-back} intervals, and then \emph{testing} the model on future data defined by the \emph{look-forward} intervals, 
      <<echo=TRUE,eval=FALSE>>=
# calculate weight_s proportional to past_aggs
weight_s <- coredata(past_aggs[index(fwd_rets)])
weight_s <- weight_s/sqrt(rowSums(weight_s^2))
# select best and worst models in each period
bes_t <- apply(weight_s, 1, which.max)
wors_t <- apply(weight_s, 1, which.min)
pnl_s <- rowSums(weight_s * coredata(fwd_rets))
pnl_s <- xts(pnl_s, order.by=index(fwd_rets))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/backtest_ewma.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
chart_Series(x=cumsum(pnl_s), 
             name="Back-test of EWMA strategies")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Functional for Aggregating Asset Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The aggregations over \emph{look-back} and \emph{look-forward} intervals can be combined into a single \texttt{sapply()} loop,
      \vskip1ex
      The functional \texttt{roll\_agg()} performs an \texttt{sapply()} loop over the \emph{end\_points} and the columns of the input \texttt{re\_turns} \emph{xts} time series,
      \vskip1ex
      The functional \texttt{roll\_agg()} applies the aggregation function \texttt{agg\_fun()} to \emph{look-back} intervals, and \texttt{sum()} to \emph{look-forward} intervals,
      \vskip1ex
      The functional \texttt{roll\_agg()} also accepts the dots \texttt{"..."} argument, and passes it into \texttt{roll\_agg()},
      \vskip1ex
      The functional \texttt{roll\_agg()} returns an \emph{xts} series of the aggregations produced by \texttt{roll\_agg()} and \texttt{sum()}, 
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# define aggregation functional
roll_agg <- function(re_turns, agg_fun=sum, 
    look_back=12, re_balance="months", 
    end_points=xts::endpoints(re_turns, on=re_balance), ...) {
# define start_points and forward (future) endpoints
  len_gth <- NROW(end_points)
  start_points <- end_points[c(rep_len(1, look_back-1), 1:(len_gth-look_back+1))]
  fwd_points <- end_points[c(2:len_gth, len_gth)]
# Perform loop over end_points and calculate aggregations
  agg_s <- sapply(2:(len_gth-1), function(in_dex) {
    c(sapply(re_turns[start_points[in_dex]:end_points[in_dex]], agg_fun, ...),  # end sapply
    sapply(re_turns[(end_points[in_dex]+1):fwd_points[in_dex]], sum))  # end sapply
  })  # end sapply
  agg_s <- t(agg_s)
#  colnames(agg_s) <- c(paste0("past_", colnames(re_turns)), paste0("fwd_", colnames(re_turns)))
  xts::xts(agg_s, 
           order.by=index(re_turns[end_points[2:(len_gth-1)]]))
}  # end roll_agg
agg_fun <- function(re_turns) sum(re_turns)/sd(re_turns)
agg_s <- roll_agg(re_turns, agg_fun=agg_fun, 
                  look_back=12, re_balance="months")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Aggregating \protect\emph{ETF} Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Overlapping aggregations can be calculated by performing an \texttt{lapply()} loop over a list of \emph{look-back} intervals (\texttt{look\_backs}),
      \vskip1ex
      Non-overlapping aggregations can also be calculated over a list of \emph{look-forward} intervals (\texttt{look\_fwds}),
      \vskip1ex
      The \emph{look-back} intervals should not overlap with the \emph{look-forward} intervals, 
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# define agg_fun() equal to the Sharpe ratio 
agg_fun <- function(re_turns) sum(re_turns)/sd(re_turns)
# Define vector of symbols for the model:
sym_bols <- c("VTI", "IEF", "DBC")
# apply roll_agg() to ETF returns
agg_s <- roll_agg(rutils::env_etf$re_turns[, sym_bols], 
                  agg_fun=agg_fun, 
                  look_back=52, 
                  re_balance="weeks")
# select aggregations over look-back intervals
past_aggs <- agg_s[, seq_along(sym_bols)]
# select aggregations over look-forward intervals
fwd_rets <- agg_s[, NROW(sym_bols) + seq_along(sym_bols)]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Momentum} Portfolio Weights}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A \emph{momentum} strategy consists of investing in a portfolio of assets according to their relative past performance,
      \vskip1ex
      In a \emph{momentum} strategy portfolio weights are proportional to the past performance of the assets,
      \vskip1ex
      For example, the \emph{ETF} portfolio weights can be calculated, as proportional to the \texttt{past\_aggs}, 
      \vskip1ex
      Constraints can also be applied to the portfolio weights, 
      \vskip1ex
      For example, the portfolio weights can be scaled (so that their sum of squares is equal to \texttt{1}), to maintain constant portfolio leverage, 
      \vskip1ex
      The portfolio weights can also be de-meaned (so that their sum is equal to zero), to create a long-short portfolio with a small beta, 
      <<echo=TRUE,eval=FALSE>>=
# calculate the portfolio weights proportional to past_aggs
weight_s <- past_aggs
# scale weight_s so that their sum of squares is equal to 1
weight_s <- weight_s/sqrt(rowSums(weight_s^2))
# plot the weights in multiple verticle panels
zoo::plot.zoo(weight_s, xlab=NULL, main="Momentum Portfolio Weights")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/momentum_weights.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Momentum} Strategy Market Beta}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The strategy market beta can be calculated by multiplying the \emph{ETF} betas by the \emph{ETF} portfolio weights, 
      <<echo=TRUE,eval=FALSE>>=
# calculate betas
beta_s <- c(1, rutils::env_etf$capm_stats[
  match(sym_bols[-1], 
        rownames(rutils::env_etf$capm_stats)), 
  "Beta"])
names(beta_s)[1] <- sym_bols[1]
# weights times betas
beta_s <- weight_s %*% beta_s
beta_s <- xts(beta_s, order.by=index(weight_s))
colnames(beta_s) <- "portf_beta"
x11()
plot.zoo(cbind(beta_s, 
  rutils::env_etf$VTI[, 4])[index(beta_s)],
  main="betas & VTI", xlab="")
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/momentum_betas.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Backtesting the \protect\emph{Momentum} Strategy}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The hypothetical out-of-sample \emph{momentum} strategy returns can be calculated by multiplying the \texttt{fwd\_rets} by the forecast \emph{ETF} portfolio weights, 
      \vskip1ex
      The \emph{training} data is specified by the \emph{look-back} intervals (\texttt{past\_aggs}), and the forecasts are applied to the future data defined by the \emph{look-forward} intervals (\texttt{fwd\_rets}), 
      <<echo=TRUE,eval=FALSE>>=
# calculate portfolio profits and losses
pnl_s <- rowSums(weight_s * fwd_rets)
pnl_s <- xts(pnl_s, order.by=index(fwd_rets))
# calculate vector of transaction costs
# bid_offer is equal to 10 bps for liquid ETFs
bid_offer <- 0.001
cost_s <- bid_offer*abs(rutils::diff_xts(weight_s))
cost_s <- rowSums(cost_s)
# subtract cost_s from pnl_s and calculate cumulative strategy pnl_s
pnl_s <- pnl_s - cost_s
pnl_s <- exp(cumsum(pnl_s))
# bind model returns with VTI
pnl_s <- merge(rutils::env_etf$VTI[index(pnl_s), 4],
               pnl_s)
pnl_s[, 1] <- pnl_s[, 1] / as.numeric(pnl_s[1, 1])
colnames(pnl_s) <- c("VTI", "momentum")
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/momentum_backtest.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# plot momentum strategy with VTI
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("orange", "blue")
chart_Series(pnl_s, theme=plot_theme, lwd=c(2, 2), 
             name="Momentum PnL")
legend("topleft", legend=colnames(pnl_s), 
       inset=0.1, bg="white", lty=c(1, 1), lwd=c(6, 6), 
       col=plot_theme$col$line.col, bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Combining the \protect\emph{Momentum} and Static Strategies}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{momentum} strategy has attractive returns compared to a static buy-and-hold strategy,
      \vskip1ex
      But the \emph{momentum} strategy suffers from draw-downs called \emph{momentum crashes}, especially after the market rallies from a sharp-sell-off,
      \vskip1ex
      This suggests that combining the \protect\emph{momentum} strategy with a static buy-and-hold strategy can achieve significant diversification of risk, 
      <<echo=TRUE,eval=FALSE>>=
# combine momentum strategy with static
pnl_s <- merge(pnl_s, 0.5* (pnl_s[, "VTI"] + pnl_s[, "Momentum"]))
colnames(pnl_s) <- c("VTI", "momentum", "combined")
# calculate strategy annualized Sharpe ratios
sapply(pnl_s, function(cumu_lative) {
  re_turns <- na.omit(diff(log(cumu_lative)))
  sqrt(260)*sum(re_turns)/sd(re_turns)/NROW(re_turns)
})  # end sapply
# calculate strategy correlations
cor(na.omit(diff(log(pnl_s))))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/momentum_combined.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# plot momentum strategy combined with VTI
plot_theme <- chart_theme()
plot_theme$col$line.col <- c("orange", "blue", "green")
chart_Series(pnl_s, theme=plot_theme, 
             name="Momentum strategy combined with VTI")
legend("topleft", legend=colnames(pnl_s), 
       inset=0.1, bg="white", lty=c(1, 1, 1), lwd=c(6, 6, 6), 
       col=plot_theme$col$line.col, bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Backtesting Functional}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The functional \texttt{back\_test()} performs a \emph{back-test} simulation, 
      \vskip1ex
      \emph{Backtesting} is a type of \emph{cross-validation} applied to time series data, and consists of:
      \begin{itemize}
        \item aggregating past historical data (returns, etc.) into performance statistics (Sharpe ratios, etc.),
        \item applying a trading rule and forming a portfolio (\emph{training} the model),
        \item \emph{testing} the portfolio performance \emph{out-of-sample} on future data,
      \end{itemize}
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# define back-test functional
back_test <- function(re_turns, agg_fun=sum, look_back=12, 
                      re_balance="months", bid_offer=0.001) {
  stopifnot("package:quantmod" %in% search() || require("quantmod", quietly=TRUE))
  # Calculate aggregations.
  agg_s <- roll_agg(re_turns, agg_fun=agg_fun, 
                    look_back=look_back, re_balance=re_balance)
  # Select aggregations over look-back and look-forward intervals.
  past_aggs <- agg_s[, 1:NCOL(re_turns)]
  fwd_rets <- agg_s[, NCOL(re_turns)+1:NCOL(re_turns)]
  # Calculate portfolio weights.
  weight_s <- past_aggs
  weight_s <- weight_s/sqrt(rowSums(weight_s^2))
  # Calculate portfolio profits and losses. 
  pnl_s <- rowSums(weight_s * fwd_rets)
  pnl_s <- xts(pnl_s, order.by=index(fwd_rets))
  colnames(pnl_s) <- "pnl_s"
  # Calculate transaction costs. 
  cost_s <- bid_offer*abs(rutils::diff_xts(weight_s))
  cost_s <- rowSums(cost_s)
  pnl_s - cost_s
}  # end back_test
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Meta-parameter Optimization in Parallel}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# define parameters
re_turns <- rutils::env_etf$re_turns[, sym_bols]
re_balance <- "weeks"
bid_offer <- 0.001
look_backs <- 10*(1:15)
# initialize compute cluster
library(parallel)
clus_ter <- makeCluster(detectCores()-1)
clusterExport(clus_ter, 
  varlist=c("back_test", "roll_agg", "agg_fun", "re_turns", "re_balance", "bid_offer"))
# perform parallel loop over look_backs under Windows
pro_files <- parSapply(clus_ter, look_backs, 
  function(look_back) {
  # perform back-test
    sum(back_test(re_turns=re_turns, 
                  agg_fun=agg_fun, 
                  look_back=look_back, 
                  re_balance=re_balance, 
                  bid_offer=bid_offer))
  })  # end parSapply
# perform parallel loop over look_backs under Mac-OSX or Linux
pro_files <- mclapply(look_backs, function(look_back) {
  # perform back-test
  sum(back_test(re_turns=re_turns, 
    agg_fun=agg_fun, 
    look_back=look_back, 
    re_balance=re_balance, 
    bid_offer=bid_offer))
})  # end mclapply
# stop R processes over cluster under Windows
stopCluster(clus_ter)
# non-parallel loop - for reference only
pro_files <- sapply(look_backs, 
  function(look_back, ...) 
    sum(back_test(look_back=look_back, ...)),
  re_turns=rutils::env_etf$re_turns[, sym_bols], 
  agg_fun=agg_fun, 
  re_balance="weeks", 
  bid_offer=0.001)
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/look_back_profile.png}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
plot(cbind(look_backs, pro_files), t="l", 
     main="Strategy PnL as function of look_back", 
     xlab="look_back (weeks)", ylab="pnl")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{old: Backtesting Framework with Overlapping Aggregations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      An interval aggregation can be specified by a vector of look-back \emph{windows} attached at \emph{end points} spanning fixed time \emph{intervals}, 
      \vskip1ex
      For example, we may wish to perform aggregations at weekly \emph{end points}, over overlapping 40-week look-back \emph{windows}, 
      \vskip1ex
      The variable \texttt{look\_back} is equal to the number of end points in the look-back \emph{window}, while (\texttt{win\_dow-1}) is equal to the number of intervals in that window, 
      \vskip1ex
      The \emph{startpoints} are the \emph{end points} lagged by the number of window intervals (number of intervals in the window), 
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
# library(HighFreq)  # load package HighFreq
# define time interval for end points
re_balance <- "weeks"
# look-back interval is multiple of re_balance
look_back <- 41
# create index of rebalancing period end points
end_points <- xts::endpoints(rutils::env_etf$re_turns, 
                             on=re_balance)
# start_points are multi-period lag of end_points
len_gth <- NROW(end_points)
start_points <- end_points[
  c(rep_len(1, look_back-1), 
    1:(len_gth-look_back+1))]
# create list of look-back intervals
inter_vals <- lapply(2:len_gth, 
    function(in_dex) {
      start_points[in_dex]:end_points[in_dex]
  })  # end lapply
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{old: Performing Overlapping Aggregations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      An interval aggregation can be specified by a vector of look-back \emph{windows} attached at \emph{end points} spanning fixed time \emph{intervals}, 
      \vskip1ex
      For example, we may wish to perform aggregations at weekly \emph{end points}, over overlapping 40-week look-back \emph{windows}, 
      \vskip1ex
      The variable \texttt{look\_back} is equal to the number of end points in the look-back \emph{window}, while (\texttt{look\_back-1}) is equal to the number of intervals in that window, 
      \vskip1ex
      The \emph{startpoints} are the \emph{end points} lagged by the number of window intervals (number of intervals in the window), 
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
# library(HighFreq)  # load package HighFreq
# create vector of symbols for model
sym_bols <- c("VTI", "IEF", "DBC")

# calculate risk&ret stats for some symbols, over a range of dates
# perform lapply() loop over inter_vals
risk_stats <- lapply(inter_vals, 
  function(inter_val) {
    x_ts <- 
      rutils::env_etf$re_turns[inter_val, sym_bols]
    t(sapply(x_ts, 
      function(col_umn)
        c(return=mean(col_umn), risk=mad(col_umn))
      ))  # end sapply
    })  # end lapply
# rbind list into single xts or matrix
# risk_stats <- rutils::do_call_rbind(risk_stats)
# head(risk_stats)
# calculate non-overlapping returns in interval
re_turns <-sapply(2:len_gth, 
    function(in_dex) {
    sapply(rutils::env_etf$re_turns[
      (end_points[in_dex-1]+1):end_points[in_dex], 
      sym_bols], sum)
  })  # end sapply
re_turns <- t(re_turns)
      @
  \end{columns}
\end{block}

\end{frame}


\end{document}
