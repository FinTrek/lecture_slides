% FRE7241_Lecture_3

% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size='scriptsize', fig.width=4, fig.height=4)
options(width=60, dev='pdf')
options(digits=3)
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[10pt]{beamer}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
% \usepackage{mathtools}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text footnotesize
\renewcommand\UrlFont{\footnotesize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape,bg=red,fg=red}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}


% Title page setup
\title[FRE7241 Lecture\#3]{FRE7241 Algorithmic Portfolio Management}
\subtitle{Lecture\#3, Fall 2015}
% \subject{Getting Started With R}
\institute[NYU Polytechnic]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@nyu.edu}
\date{Sep 22, 2015}
% \date{\today}
% \pgfdeclareimage[height=0.5cm]{university-logo}{engineering_long_white}
% \logo{\pgfuseimage{engineering_long_white}}


%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle



%%%%%%%%%%%%%%%
\section{Package \texttt{quantmod} for Downloading and Plotting Data}


%%%%%%%%%%%%%%%
\subsection{ETF Dataset}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=(-(1:3))>>=
rm(list=ls())
setwd("C:/Develop/data")
library(xtable)
# ETF symbols for asset allocation
sym_bols <- c("VTI", "VEU", "IEF", "VNQ", 
  "DBC", "XLY", "XLP", "XLE", "XLF", "XLV", 
  "XLI", "XLB", "XLK", "XLU", "IWB", "IWD", 
  "IWF", "IWM", "IWN", "IWO", "IWP", "IWR", 
  "IWS", "IWV", "IUSV", "IUSG")
# read etf database into data frame
etf_list <- read.csv(file='etf_list.csv', 
                     stringsAsFactors=FALSE)
rownames(etf_list) <- etf_list$Symbol
# subset etf_list only those ETF's in sym_bols
etf_list <- etf_list[sym_bols, ]
# shorten names
etf_names <- sapply(etf_list$Name, 
                    function(name) {
  name_split <- strsplit(name, split=" ")[[1]]
  name_split <- 
    name_split[c(-1, -length(name_split))]
  name_match <- match("Select", name_split)
  if (!is.na(name_match))
    name_split <- name_split[-name_match]
  paste(name_split, collapse=" ")
})  # end sapply
etf_list$Name <- etf_names
etf_list["IEF", "Name"] <- "Treasury Bond Fund"
etf_list["XLY", "Name"] <- "Consumer Discr. Sector Fund"
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      <<eval=FALSE,echo=FALSE,size="tiny">>=
etf_list[c(1, 2)]
      @
      <<results='asis',echo=FALSE>>=
print(xtable(etf_list), comment=FALSE, size="tiny")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Package \texttt{quantmod} for Quantitative Financial Modelling}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The package \texttt{quantmod} contains functions:
      \begin{itemize}
        \item \texttt{getSymbols()} for downloading time series data,
        \item \texttt{getFinancials()} for downloading financial statements,
        \item for extracting and manipulating time series data, 
        \item for calculating periodic returns,
        \item \texttt{chartSeries} for plotting time series data, 
      \end{itemize}
      \texttt{quantmod} uses time series objects of class\texttt{"xts"},
    \column{0.6\textwidth}
      \vspace{-1em}
      <<eval=FALSE>>=
library(quantmod)  # load package "quantmod"
# get documentation for package "quantmod"
packageDescription("quantmod")  # get short description
help(package="quantmod")  # load help page
data(package="quantmod")  # list all datasets in "quantmod"
ls("package:quantmod")  # list all objects in "quantmod"
detach("package:quantmod")  # remove quantmod from search path
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Downloading Time Series Data Using Package \texttt{quantmod}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The function \texttt{getSymbols()} downloads time series data into the specified \emph{environment},
      \vskip1ex
      \texttt{getSymbols()} creates objects in the specified \emph{environment} from the input strings (names),
      \vskip1ex
      It then assigns the data to those objects, without returning them as a function value, as a \emph{side effect},
      \vskip1ex
      By default, \texttt{getSymbols()} downloads for each symbol the daily \emph{OHLC} prices and trading volume (Open, High, Low, Close, Adjusted, Volume),
      \vskip1ex
      The method \texttt{getSymbols.yahoo} accepts arguments \texttt{"from"} and \texttt{"to"} which specify the date range for the data,
      \vskip1ex
      If the argument \texttt{"auto.assign"} is set to \texttt{FALSE}, then \texttt{getSymbols()} returns the data, instead of assigning it silently,
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=(-(1)),eval=FALSE>>=
load(file="C:/Develop/data/etf_data.Rdata")
library(quantmod)  # load package "quantmod"
env_data <- new.env()  # new environment for data
# download data for sym_bols into env_data
getSymbols(sym_bols, env=env_data, adjust=TRUE,
    from="2007-01-03", to="2015-05-01")
      @
      \vspace{-2em}
      <<echo=(-(1:2)),eval=TRUE>>=
load(file="C:/Develop/data/etf_data.Rdata")
library(quantmod)  # load package "quantmod"
ls(env_data)  # list files in env_data
# get class of object in env_data
class(get(x=sym_bols[1], envir=env_data))
# another way
class(env_data$VTI)
colnames(env_data$VTI)
head(env_data$VTI, 3)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Adjusting Prices Using Package \texttt{quantmod}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Traded stock and bond prices experience jumps after splits and dividends, and must be adjusted to account for them,
      \vskip1ex
      The function \texttt{adjustOHLC()} adjusts \emph{OHLC} prices, 
      \vskip1ex
      The function \texttt{get()} retrieves objects that are referenced using character strings, instead of their names,
      \vskip1ex
      The \texttt{assign()} function assigns a value to an object in a specified \emph{environment}, by referencing it using a character string (name),
      \vskip1ex
      The functions \texttt{get()} and \texttt{assign()} allow retrieving and assigning values to objects that are referenced using character strings,
      \vskip1ex
      If the argument \texttt{"adjust"} in function \texttt{getSymbols()} is set to \texttt{TRUE}, then \texttt{getSymbols()} returns adjusted data,
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=(-(1:2)),eval=FALSE>>=
load(file="C:/Develop/data/etf_data.Rdata")
library(quantmod)  # load package "quantmod"
# adjust single OHLC object using its name
env_data$VTI <- adjustOHLC(env_data$VTI, 
                           use.Adjusted=TRUE)

# adjust OHLC object using string as name
assign(sym_bols[1], adjustOHLC(
    get(x=sym_bols[1], envir=env_data), 
    use.Adjusted=TRUE), 
  envir=env_data)

# adjust objects in environment using vector of strings
for (sym_bol in sym_bols) {
  assign(sym_bol, 
         adjustOHLC(get(sym_bol, envir=env_data), 
                    use.Adjusted=TRUE), 
         envir=env_data)
}
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Extracting Prices Using Package \texttt{quantmod}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Data can be extracted from an \emph{environment} by coercing it into a \texttt{list}, and then subsetting and merging it into an \texttt{xts} using the function \texttt{do.call()},
      \vskip1ex
      A list of \texttt{xts} can be flattened into a single \texttt{xts} using the function \texttt{do.call()},
      \vskip1ex
      The function \texttt{do.call()} executes a function call using a function name and a list of arguments,
      \vskip1ex
      \texttt{do.call()} passes the list elements individually, instead of passing the whole list as one argument,
      \vskip1ex
      The extractor (accessor) functions \texttt{Ad()}, \texttt{Vo()}, etc., extract columns from \emph{OHLC} data,
      \vskip1ex
      The function \texttt{eapply()} is similar \texttt{lapply()}, and applies a function to objects in an \emph{environment}, and returns a list,
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=(-(1:2)),eval=FALSE>>=
load(file="C:/Develop/data/etf_data.Rdata")
library(quantmod)  # load package "quantmod"
# extract and merge all data, subset by symbols
etf_series <- do.call(merge, 
                  as.list(env_data)[sym_bols])

# extract and merge adjusted prices, subset by symbols
etf_series_ad <- do.call(merge, 
                  lapply(as.list(env_data)[sym_bols], Ad))

# extract and merge adjusted prices, subset by symbols
etf_series_ad <- do.call(merge, 
                  eapply(env_data, Ad)[sym_bols])

# drop ".Adjusted" from colnames
colnames(etf_series_ad) <- 
  sapply(colnames(etf_series_ad), 
    function(col_name) 
      strsplit(col_name, split="[.]")[[1]])[1, ]
tail(etf_series_ad[, 1:2], 3)

# which objects in global environment are class xts?
unlist(eapply(globalenv(), is.xts))

# save xts to csv file
write.zoo(etf_series, 
     file='etf_series.csv', sep=",")
# save data to .Rdata file
save(env_data, etf_series, etf_series_ad, 
     file='etf_data.Rdata')
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Calculating Returns from Adjusted Prices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:2))>>=
library(quantmod)
load(file="C:/Develop/data/etf_data.Rdata")
# remove rows with NA values
etf_series_ad <- 
  etf_series_ad[complete.cases(etf_series_ad)]
colnames(etf_series_ad)

# calculate returns from adjusted prices
etf_rets <- lapply(etf_series_ad, 
                   function(x_ts) {
# dailyReturn returns single xts with bad colname
  daily_return <- dailyReturn(x_ts)
  colnames(daily_return) <- names(x_ts)
  daily_return
})  # end lapply

# "etf_rets" is a list of xts
class(etf_rets[[1]])

# flatten list of xts into a single xts
etf_rets <- do.call(merge, etf_rets)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE>>=
class(etf_rets)
dim(etf_rets)
head(etf_rets[, 1:3])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting Using \texttt{chartSeries()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A \emph{candlestick chart} is a type of plot designed to visualize \emph{OHLC} time series,
      \vskip1ex
      Each \emph{candlestick} displays one period of data, and consists of a vertical line representing the \emph{High} and \emph{Low} prices, and a box representing the \emph{Open} and \emph{Close} prices,
      \vskip1ex
      The color of the box signifies whether the \emph{Close} price was higher or lower than the \emph{Open},
      \vskip1ex
      The function \texttt{chartSeries()} from package \texttt{quantmod} can produce a variety of plots, including candlestick charts for \emph{OHLC} time series, including volume,
      <<chartSeries_basic,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(quantmod)
load(file="C:/Develop/data/etf_data.Rdata")
# is it an OHLC time series?
is.OHLC(env_data$VTI)
# plot OHLC candlechart with volume
chartSeries(env_data$VTI, 
            name="VTI", 
            theme=chartTheme("white"))
# redraw plot only for Nov-2014
reChart(type="candlesticks", subset="2014-11")
# plot OHLC bar chart with volume
chartSeries(env_data$VTI["2014-11"], 
            type="bars",
            name="VTI",
            theme=chartTheme("white"))
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/chartSeries_basic-1}\\
      The function \texttt{reChart()} redraws plots using additional parameters,
      \vskip1ex
      The argument \texttt{"type"} allows for plotting bar charts and line graphs,
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting Technical Indicators Using \texttt{chartSeries()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The argument \texttt{"TA"} allows adding technical indicators to the plot,
      \vskip1ex
      The technical indicators are functions provided by the package \texttt{TTR},
      \vskip1ex
      The function \texttt{newTA()} allows defining new technical indicators,
      <<chartSeries_addTA,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(quantmod)
load(file="C:/Develop/data/etf_data.Rdata")
# candlechart with Bollinger Bands
chartSeries(env_data$VTI["2014"],
            TA="addBBands();addBBands(draw='percent');addVo()",
            name="VTI with Bollinger Bands",
            theme=chartTheme("white"))
# candlechart with two Moving Averages
chartSeries(env_data$VTI["2014"],
            TA="addVo();addEMA(10);addEMA(30)",
            name="VTI with Moving Averages",
            theme=chartTheme("white"))
# candlechart with Commodity Channel Index
chartSeries(env_data$VTI["2014"], 
            TA="addVo();addBBands();addCCI()",
            name="VTI with Technical Indicators",
            theme=chartTheme("white"))
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/chartSeries_addTA-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Downloading \protect\emph{FRED} Time Series Data}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{FRED} is a database of economic time series maintained by the Federal Reserve Bank of St. Louis:\\
      \hskip1em\url{http://research.stlouisfed.org/fred2/}
      \vskip1ex
      \texttt{getSymbols()} can download \emph{FRED} data with the argument \texttt{"src"} set to \texttt{FRED},
      <<chartSeries_fred,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(quantmod)
load(file="C:/Develop/data/etf_data.Rdata")
# download U.S. unemployment rate data
unemp_rate <- getSymbols("UNRATE", 
                  auto.assign=FALSE, 
                  src="FRED")
# plot U.S. unemployment rate data
chartSeries(unemp_rate["1990/"], 
            name="U.S. unemployment rate",
            theme=chartTheme("white"))
# download 10-Year Treasury constant maturity rate
trs_10yr <- getSymbols("DGS10", 
                  auto.assign=FALSE, 
                  src="FRED")
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/chartSeries_fred-1}\\
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Package \texttt{PerformanceAnalytics} for Risk and Return Analysis}


%%%%%%%%%%%%%%%
\subsection{Package \texttt{PerformanceAnalytics}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The package \texttt{PerformanceAnalytics} contains functions and data sets for performance and risk analysis,
      \vskip1ex
      The function \texttt{data()} loads external data or lists data sets in a package,
      \vskip1ex
      \texttt{managers} is an \texttt{xts} time series containing monthly percentage returns of six asset managers (HAM1 through HAM6), the EDHEC Long-Short Equity hedge fund index, the \texttt{S\&P 500}, and US Treasury 10-year bond and 3-month bill total returns,
    \column{0.6\textwidth}
      \vspace{-1em}
      <<eval=FALSE>>=
library(PerformanceAnalytics)  # load package "PerformanceAnalytics"
# get documentation for package "PerformanceAnalytics"
packageDescription("PerformanceAnalytics")  # get short description
help(package="PerformanceAnalytics")  # load help page
data(package="PerformanceAnalytics")  # list all datasets in "PerformanceAnalytics"
ls("package:PerformanceAnalytics")  # list all objects in "PerformanceAnalytics"
detach("package:PerformanceAnalytics")  # remove PerformanceAnalytics from search path
      @
      \vspace{-1em}
      <<echo=(-1)>>=
library(PerformanceAnalytics)  # load package "PerformanceAnalytics"
perf_data <- 
  unclass(data(
    package="PerformanceAnalytics"))$results[, -(1:2)]
apply(perf_data, 1, paste, collapse=" - ")
data(managers)  # load "managers" data set
class(managers)
dim(managers)
head(managers, 3)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\texttt{CumReturns} Plots}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{chart.CumReturns()} plots the cumulative returns of a time series of returns,
      <<cum_returns,echo=TRUE,eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
# load package "PerformanceAnalytics"
library(PerformanceAnalytics)
data(managers)  # load "managers" data set
ham_1 <- managers[, c("HAM1", "EDHEC LS EQ", 
                      "SP500 TR")]

chart.CumReturns(ham_1, lwd=2, ylab="", 
        legend.loc="topleft", main="")
# add title
title(main="Managers cumulative returns", 
      line=-1)
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/cum_returns-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\texttt{PerformanceSummary} Plots}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{charts.PerformanceSummary()} plots three charts: cumulative returns, return bars, and drawdowns,
      <<performance_summary,echo=(-(1:2)),eval=FALSE,fig.height=6,fig.show='hide'>>=
library(PerformanceAnalytics)  # load package "PerformanceAnalytics"
data(managers)  # load "managers" data set
charts.PerformanceSummary(ham_1, 
  main="", lwd=2, ylog=TRUE)
      @
    \column{0.5\textwidth}
    \vspace{-3em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/performance_summary-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{ETF \texttt{CumReturns} Plots}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{chart.CumReturns()} plots the cumulative returns of a time series of returns,
      <<etf_cum_returns,echo=(-1),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(PerformanceAnalytics)  # load package "PerformanceAnalytics"
chart.CumReturns(
  etf_rets[, c("XLF", "XLP", "IEF")], lwd=2, 
  ylab="", legend.loc="topleft", main="")
# add title
title(main="ETF cumulative returns", line=-1)
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/etf_cum_returns-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Drawdown Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
    \vspace{-1em}
      <<drawdown_plot,eval=FALSE,echo=(-(1:2)),fig.width=7,fig.height=6,fig.show='hide'>>=
load(file="C:/Develop/data/etf_data.Rdata")
options(width=200)
library(PerformanceAnalytics)
chart.Drawdown(etf_rets[, "VTI"], ylab="", 
               main="VTI drawdowns")
      @
      \vskip27ex
      <<eval=TRUE,echo=(-(1:3))>>=
load(file="C:/Develop/data/etf_data.Rdata")
options(width=200)
library(PerformanceAnalytics)
table.Drawdowns(etf_rets[, "VTI"])
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/drawdown_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Return Distribution Histogram}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<returns_hist,echo=(-1),eval=FALSE,fig.width=5,fig.height=5,fig.show='hide'>>=
library(PerformanceAnalytics)
chart.Histogram(etf_rets[, 1], main="", 
  xlim=c(-0.06, 0.06), 
  methods = c("add.density", "add.normal"))
# add title
title(main=paste(colnames(etf_rets[, 1]), 
                 "density"), line=-1)
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/returns_hist-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Return Boxplots}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<returns_box,echo=(-1),eval=FALSE,fig.width=6,fig.height=6,fig.show='hide'>>=
library(PerformanceAnalytics)
chart.Boxplot(etf_rets[, 
  c(rownames(head(ret_stats, 3)), 
    rownames(tail(ret_stats, 3)))])
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \hspace*{-8em}\includegraphics[width=0.65\paperwidth,valign=t]{figure/returns_box-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Return Distribution Statistics}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-1)>>=
library(PerformanceAnalytics)
tail(table.Stats(etf_rets[, 
  c("VTI", "IEF", "DBC", "IUSG")]), 3)
ret_stats <- table.Stats(etf_rets)
class(ret_stats)
# Transpose the data frame
ret_stats <- as.data.frame(t(ret_stats))
      @
      \vspace{-1em}
      <<returns_scatter,echo=(-1),eval=FALSE,fig.width=5,fig.height=5,fig.show='hide'>>=
# plot scatterplot
plot(Kurtosis ~ Skewness, data=ret_stats,
     main="Kurtosis vs Skewness")
# add labels
text(x=ret_stats$Skewness, y=ret_stats$Kurtosis, 
          labels=colnames(etf_rets), 
          pos=1, cex=0.8)
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/returns_scatter-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Return Statistics Ranking}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.45\textwidth}
      \vspace{-1em}
      <<echo=(-(1))>>=
load(file="C:/Develop/data/etf_data.Rdata")
# add skew_kurt column
ret_stats$skew_kurt <- 
  ret_stats$Skewness/ret_stats$Kurtosis
# sort on skew_kurt
ret_stats <- ret_stats[
  order(ret_stats$skew_kurt, 
        decreasing=TRUE), ]
# add names column
ret_stats$Name <- 
  etf_list[rownames(ret_stats), ]$Name
      @
    \column{0.55\textwidth}
      \vspace{-1em}
      <<echo=TRUE>>=
ret_stats[, c("Name", "Skewness", "Kurtosis")]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Risk vs. Return Scatterplot}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<risk_return_scatter,echo=(-1),eval=FALSE,fig.width=5,fig.height=5,fig.show='hide'>>=
library(PerformanceAnalytics)
chart.RiskReturnScatter(etf_rets, Rf=0.01/12)
      @
    \column{0.5\textwidth}
    \vspace{-2em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/risk_return_scatter-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Risk-adjusted Returns Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The \emph{Sharpe} ratio measures the excess returns per unit of risk, and is equal to the excess returns (over a risk-free return) divided by the standard deviation of the returns:
      \begin{displaymath}
        S_{r}=\frac{E[R-R_{f}]}{\sigma}
      \end{displaymath}
      The \emph{Sortino} ratio is equal to the excess returns divided by the \emph{downside deviation} (standard deviation of returns below a target rate of return),
      \begin{displaymath}
        S_{r}=\frac{E[R-R_{t}]}{\sqrt{\sum_{i=1}^{k} ([R_{i}-R_{t}]_{-})^2}}
      \end{displaymath}
      The \emph{Calmar} ratio is equal to the excess returns divided by the maximum drawdown of the returns:
      \begin{displaymath}
        C_{r}=\frac{E[R-R_{f}]}{DD}
      \end{displaymath}
      \vskip1ex
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=(-1)>>=
library(PerformanceAnalytics)
vti_ief <- etf_rets[, c("VTI", "IEF")]
SharpeRatio(vti_ief)

SortinoRatio(vti_ief)

CalmarRatio(vti_ief)
tail(table.Stats(vti_ief), 4)
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Regression Analysis}


%%%%%%%%%%%%%%%
\subsection{Formula Objects}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Formulas in \texttt{R} are defined using the "\textasciitilde{}" operator followed by a series of terms separated by the \texttt{"+"} operator,
      \vskip1ex
      Formulas can be defined as separate objects, manipulated, and passed to functions,
      \vskip1ex
      The formula "\texttt{z} \textasciitilde{} \texttt{x}" means the response (independent) variable \texttt{z} is explained by the predictor \texttt{x},
      \vskip1ex
      The formula "\texttt{z \textasciitilde{} x + y}" represents a linear model: \texttt{z = ax  + by + c},
      \vskip1ex
      The formula "\texttt{y \textasciitilde{} x - 1}" or "\texttt{y \textasciitilde{} x + 0}" represents a linear model with zero intercept: $y = ax$,
      \vskip1ex
      The function \texttt{update()} modifies existing \texttt{formulas},
      \vskip1ex
      The \texttt{"."} symbol represents either all the remaining data, or the variable that was in this part of the formula,
    \column{0.6\textwidth}
      \vspace{-1em}
      <<>>=
# formula of linear model with zero intercept
lin_formula <- z ~ x + y - 1
lin_formula

# collapsing a character vector into a text string
paste0("x", 1:5)
paste(paste0("x", 1:5), collapse="+")

# creating formula from text string
lin_formula <- as.formula(  # coerce text strings to formula
              paste("y ~ ", 
                paste(paste0("x", 1:5), collapse="+")
                )  # end paste
            )  # end as.formula
class(lin_formula)
lin_formula
# modify the formula using "update"
update(lin_formula, log(.) ~ . + beta)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Linear Regression Using \texttt{lm()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      A linear model between a response variable \texttt{z} and explanatory variables \texttt{x} is defined by the formula:
      \begin{displaymath}
        z_{i} = {\alpha} + \sum_{j=1}^{k} {{\beta}_{j} x_{i,j}} + {\varepsilon}_{i}
      \end{displaymath}
      Where the ${\varepsilon}_{i}$ are the errors, assumed to be normally distributed, independent, and stationary,
      \vskip1ex
      The function \texttt{lm()} fits a linear model (regression) into the data (a set of observations),
      \vskip1ex
      \texttt{lm()} returns an object of class \texttt{lm()}, which is a list containing the results of fitting the model:
      \begin{itemize}
        \item call - the model formula,
        \item coefficients - the fitted model coefficients (${\alpha}$, ${\beta}_{j}$),
        \item residuals - the model residuals (response minus fitted values),
      \end{itemize}
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=(-1)>>=
set.seed(1121)  # initialize random number generator
explana_tory <- seq(from=0.1, to=3.0, by=0.1)  # explanatory variable
# dependent (response) variable equals linear form plus noise
res_ponse <- 3 + 2*explana_tory + rnorm(30)
# specify regression formula
reg_formula <- res_ponse ~ explana_tory
reg_model <- lm(reg_formula)  # perform regression
class(reg_model)  # regressions have class lm
attributes(reg_model)
eval(reg_model$call$formula)  # the regression formula
reg_model$coefficients  # the regression formula coefficients
coef(reg_model)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Regression Scatterplot}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The generic function \texttt{plot()} produces a scatterplot when it's called on the regression formula,
      \vskip1ex
      \texttt{abline()} plots a straight line corresponding to the regression coefficients, when it's called on the regression object,
      \vskip1ex
      The fitted (predicted) values are the values of the response variable obtained from applying the regression model to the explanatory variables,
        <<reg_scatter_plot,eval=FALSE,echo=(-1),fig.show='hide'>>=
par(oma=c(1, 2, 1, 0), mgp=c(2, 1, 0), mar=c(5, 1, 1, 1), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
plot(reg_formula)  # plot scatterplot using formula
title(main="Simple Regression", line=-1)
# add regression line
abline(reg_model, lwd=2, col="red")
# plot fitted (predicted) response values
points(x=explana_tory, y=reg_model$fitted.values, 
       pch=16, col="blue")
      @
    \column{0.5\textwidth}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/reg_scatter_plot-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Regression Summary}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The function \texttt{summary.lm()} produces a list of regression model summary statistics:
      \begin{itemize}
        \item coefficients: matrix with estimated coefficients, their \emph{t}-statistics, and \emph{p}-values,
        \item r.squared: fraction of response variance explained by the model (correlation between response and explanatory variables),
        \item adj.r.squared: r.squared adjusted for higher model complexity,
        \item fstatistic: \emph{F}-statistic - ratio of variance explained by model divided by unexplained variance,
      \end{itemize}
      The \emph{t}-statistic (\emph{t}-value) is the ratio of the estimated value divided by its standard error,
      \vskip1ex
      The \emph{p}-value is the probability of obtaining the observed value of the \emph{t}-statistic, or more extreme values,
    \column{0.6\textwidth}
      \vspace{-1em}
        <<>>=
reg_model_sum <- summary(reg_model)  # copy regression summary
reg_model_sum  # print the summary to console
attributes(reg_model_sum)$names  # get summary elements
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Interpreting the Regression Statistics}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The regression \texttt{summary} is a list, and its elements can be accessed individually,
      \vskip1ex
      The \emph{null} hypothesis is that the regression coefficients are \emph{zero},
      \vskip1ex
      A small \emph{p}-value is often interpreted as meaning that the coefficients are very unlikely to be zero (given the data),
      \vskip1ex
      The \emph{t}-statistic and the \emph{F}-statistic assume that the errors in the data are drawn from independent normal distributions,
      \vskip1ex
      But financial data is very far from normal, so the \emph{p}-values shouldn't be automatically interpreted as meaning that the coefficients are non-zero,
    \column{0.6\textwidth}
      \vspace{-1em}
        <<>>=
reg_model_sum$coefficients
reg_model_sum$r.squared
reg_model_sum$adj.r.squared
reg_model_sum$fstatistic
anova(reg_model)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Weak Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      If the relationship between the response and explanatory variables is weak compared to the noise, then the regression will have low statistical significance,
      \vskip1ex
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=(-1)>>=
set.seed(1121)  # initialize random number generator
# small coefficient between response and explanatory variables
res_ponse <- 3 + 0.2*explana_tory + rnorm(30)
reg_model <- lm(reg_formula)  # perform regression
# the estimate of the coefficient is not statistically significant
summary(reg_model)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Influence of Noise on Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
    \vspace{-2em}
      <<reg_noise,eval=FALSE,echo=(-(1:1)),fig.height=5.2,fig.show='hide'>>=
par(oma=c(1, 1, 1, 1), mgp=c(0, 0.5, 0), mar=c(1, 1, 1, 1), cex.lab=1.0, cex.axis=1.0, cex.main=1.0, cex.sub=1.0)
reg_stats <- function(std_dev) {  # noisy regression
  set.seed(1121)  # initialize number generator
# create explanatory and response variables
  explana_tory <- seq(from=0.1, to=3.0, by=0.1)
  res_ponse <- 3 + 0.2*explana_tory + 
    rnorm(30, sd=std_dev)
# specify regression formula
  reg_formula <- res_ponse ~ explana_tory
# perform regression and get summary
  reg_model_sum <- summary(lm(reg_formula))
# extract regression statistics
  c(pval=reg_model_sum$coefficients[2, 4],
    adj.r.squared=reg_model_sum$adj.r.squared,
    fstat=reg_model_sum$fstatistic[1])
}  # end reg_stats
# apply reg_stats() to vector of std dev values 
vec_sd <- seq(from=0.1, to=0.5, by=0.1)
names(vec_sd) <- paste0("sd=", vec_sd)
mat_reg_stats <- t(sapply(vec_sd, reg_stats))
# plot in loop
par(mfrow=c(ncol(mat_reg_stats), 1))
for (in_dex in 1:ncol(mat_reg_stats)) {
  plot(mat_reg_stats[, in_dex], type="l", 
       xaxt="n", xlab="", ylab="", main="")
  title(main=colnames(mat_reg_stats)[in_dex], 
        line=-1.0)
  axis(1, at=1:(nrow(mat_reg_stats)), 
       labels=rownames(mat_reg_stats))  
}  # end for
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/reg_noise-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Influence of Noise on Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
    \vspace{-2em}
      <<eval=FALSE,echo=TRUE>>=
reg_stats <- function(da_ta) {  # get regression
# perform regression and get summary
  col_names <- colnames(da_ta)
  reg_formula <- 
    paste(col_names[2], col_names[1], sep="~")
  reg_model_sum <- summary(lm(reg_formula, 
                              data=da_ta))
# extract regression statistics
  c(pval=reg_model_sum$coefficients[2, 4],
    adj.r.squared=reg_model_sum$adj.r.squared,
    fstat=reg_model_sum$fstatistic[1])
}  # end reg_stats
# apply reg_stats() to vector of std dev values 
vec_sd <- seq(from=0.1, to=0.5, by=0.1)
names(vec_sd) <- paste0("sd=", vec_sd)
mat_reg_stats <- 
  t(sapply(vec_sd, function (std_dev) {
    set.seed(1121)  # initialize number generator
# create explanatory and response variables
    explana_tory <- seq(from=0.1, to=3.0, by=0.1)
    res_ponse <- 3 + 0.2*explana_tory + 
      rnorm(30, sd=std_dev)
    reg_stats(data.frame(explana_tory, res_ponse))
    }))
# plot in loop
par(mfrow=c(ncol(mat_reg_stats), 1))
for (in_dex in 1:ncol(mat_reg_stats)) {
  plot(mat_reg_stats[, in_dex], type="l", 
       xaxt="n", xlab="", ylab="", main="")
  title(main=colnames(mat_reg_stats)[in_dex], 
        line=-1.0)
  axis(1, at=1:(nrow(mat_reg_stats)), 
       labels=rownames(mat_reg_stats))  
}  # end for
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/reg_noise-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Regression Diagnostic Plots}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{plot()} produces diagnostic scatterplots for the residuals, when called on the regression object,
      \vskip1ex
      {\scriptsize
      The diagnostic scatterplots allow for visual inspection to determine the quality of the regression fit,
      \vskip1ex
      "Residuals vs Fitted" is a scatterplot of the residuals vs. the predicted responses,
      \vskip1ex
      "Scale-Location" is a scatterplot of the square root of the standardized residuals vs. the predicted responses,
      \vskip1ex
      The residuals should be randomly distributed around the horizontal line representing zero residual error,
      \vskip1ex
      A pattern in the residuals indicates that the model was not able to capture the relationship between the variables, or that the variables don't follow the statistical assumptions of the regression model,
      \vskip1ex
      "Normal Q-Q" is the standard Q-Q plot, and the points should fall on the diagonal line, indicating that the residuals are normally distributed,
      \vskip1ex
      "Residuals vs Leverage" is a scatterplot of the residuals vs. their leverage,
      \vskip1ex
      Leverage measures the amount by which the predicted response would change if the observed response were shifted by a small amount,
      \vskip1ex
      Cook's distance measures the influence of a single observation on the predicted values, and is proportional to the sum of the squared differences between predictions made with all observations and predictions made without the observation,
      \vskip1ex
      Points with large leverage, or a Cook's distance greater than 1 suggest the presence of an outlier or a poor model,
      }
    \column{0.5\textwidth}
      \vspace{-1em}
      <<plot_reg,eval=FALSE,echo=(-(1:2)),fig.show='hide'>>=
# set plot paramaters - margins and font scale
par(oma=c(1,0,1,0), mgp=c(2,1,0), mar=c(2,1,2,1), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(2, 2))  # plot 2x2 panels
plot(reg_model)  # plot diagnostic scatterplots
plot(reg_model, which=2)  # plot just Q-Q
      @
      \vspace{-1em}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/plot_reg-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Durbin-Watson Test of Autocorrelation of Residuals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Durbin-Watson} test is designed to test the \emph{null hypothesis} that the autocorrelations of regression residuals are equal to zero,
      \vskip1ex
      The test statistic is:
      \begin{displaymath}
        DW = \frac {\sum_{i=2}^{n} (\varepsilon_{i} - \varepsilon_{i-1})^2} {\sum_{i=1}^{n} \varepsilon_{i}^2}
      \end{displaymath}
      Where $\varepsilon_{i}$ are the regression residuals,
      \vskip1ex
      The value of the \emph{Durbin-Watson} statistic \emph{DW} is close to zero for large positive autocorrelations, and close to four for large negative autocorrelations,
      \vskip1ex
      The \emph{DW} is close to two for autocorrelations close to zero,
      \vskip1ex
      The \emph{p}-value for the \texttt{my\_reg} regression is large, and we conclude that the \emph{null hypothesis} is \texttt{TRUE}, and the regression residuals are uncorrelated,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:3))>>=
res_ponse <- 3 + 2*explana_tory + rnorm(30)
reg_formula <- res_ponse ~ explana_tory
reg_model <- lm(reg_formula)  # perform regression
library(lmtest)  # load lmtest

# perform Durbin-Watson test
dwtest(reg_model)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Omitted Variable Bias}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Omitted Variable Bias} occurs in a regression model that omits important predictors,
      \vskip1ex
      The parameter estimates are biased, even though the \emph{t}-statistics, \emph{p}-values, and \emph{R}-squared all indicate a statistically significant regression,
      \vskip1ex
      But the Durbin-Watson test shows residuals are autocorrelated, invalidating other tests,
      \vspace{-1em}
        <<ovb_reg,echo=(-(1:3)),fig.height=8,fig.show='hide'>>=
par(oma=c(15, 1, 1, 1), mgp=c(0, 0.5, 0), mar=c(1, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(2,1))  # set plot panels
library(lmtest)  # load lmtest
design_matrix <- data.frame(  # design matrix
  explana_tory=1:30, omit_var=sin(0.2*1:30))
# response depends on both explanatory variables
res_ponse <- with(design_matrix, 
          0.2*explana_tory + omit_var + 0.2*rnorm(30))
# mis-specified regression only one explanatory
reg_model <- lm(res_ponse ~ explana_tory, 
                data=design_matrix)
reg_model_sum <- summary(reg_model)
reg_model_sum$coefficients
reg_model_sum$r.squared
# Durbin-Watson test shows residuals are autocorrelated
dwtest(reg_model)$p.value
plot(reg_formula, data=design_matrix)
abline(reg_model, lwd=2, col="red")
title(main="OVB Regression", line=-1)
plot(reg_model, which=2, ask=FALSE)  # plot just Q-Q
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/ovb_reg-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Spurious Time Series Regression}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Regression of non-stationary time series creates \emph{spurious} regressions,
      \vskip1ex
      The \emph{t}-statistics, \emph{p}-values, and \emph{R}-squared all indicate a statistically significant regression,
      \vskip1ex
      But the Durbin-Watson test shows residuals are autocorrelated, which invalidates the other tests,
      \vskip1ex
      The Q-Q plot also shows that residuals are \emph{not} normally distributed,
        <<spur_reg,echo=(-(1:5)),fig.height=8,fig.show='hide'>>=
par(oma=c(15, 1, 1, 1), mgp=c(0, 0.5, 0), mar=c(1, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(2,1))  # set plot panels
set.seed(1121)
library(lmtest)
# spurious regression in unit root time series
explana_tory <- cumsum(rnorm(100))  # unit root time series
res_ponse <- cumsum(rnorm(100))
reg_formula <- res_ponse ~ explana_tory
reg_model <- lm(reg_formula)  # perform regression
# summary indicates statistically significant regression
reg_model_sum <- summary(reg_model)
reg_model_sum$coefficients
reg_model_sum$r.squared
# Durbin-Watson test shows residuals are autocorrelated
dw_test <- dwtest(reg_model)
c(dw_test$statistic[[1]], dw_test$p.value)
plot(reg_formula, xlab="", ylab="")  # plot scatterplot using formula
title(main="Spurious Regression", line=-1)
# add regression line
abline(reg_model, lwd=2, col="red")
plot(reg_model, which=2, ask=FALSE)  # plot just Q-Q
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/spur_reg-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Predictions Using Regression Models}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{predict()} is a generic function for performing predictions based on a given model,
      \vskip1ex
      \texttt{predict.lm()} is the predict method for linear models (regressions),
      \vspace{-1em}
        <<predict_lm,echo=TRUE,fig.show='hide'>>=
explana_tory <- seq(from=0.1, to=3.0, by=0.1)  # explanatory variable
res_ponse <- 3 + 2*explana_tory + rnorm(30)
reg_formula <- res_ponse ~ explana_tory
reg_model <- lm(reg_formula)  # perform regression
new_data <- data.frame(explana_tory=0.1*31:40)
predict_lm <- predict(object=reg_model, 
                      newdata=new_data, level=0.95, 
                      interval="confidence")
predict_lm <- as.data.frame(predict_lm)
head(predict_lm, 2)
plot(reg_formula, xlim=c(1.0, 4.0), 
     ylim=range(res_ponse, predict_lm),
     main="Regression predictions")
abline(reg_model, col="red")
with(predict_lm, {
  points(x=new_data$explana_tory, y=fit, pch=16, col="blue")
  lines(x=new_data$explana_tory, y=lwr, lwd=2, col="red")
  lines(x=new_data$explana_tory, y=upr, lwd=2, col="red")
})  # end with
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth,valign=t]{figure/predict_lm-1}
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Homework Assignment}


%%%%%%%%%%%%%%%
\subsection{Homework Assignment}
\begin{frame}[t]{\secname}
\vspace{-1em}
\begin{block}{Required}
  A file with the homework will be uploaded to NYU Classes,
\end{block}

\begin{block}{Recommended}
  \begin{itemize}[]
    \item Read chapters 1-3: \fullcite{website:rintro}
    \item Read chapters 1, 2, 11: \citetitle{matloffbook}
    \item Read: \fullcite{website:googlestyler}
  \end{itemize}
\end{block}

\end{frame}


\end{document}
