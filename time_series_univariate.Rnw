% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, eval=FALSE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size='scriptsize', fig.width=4, fig.height=4)
options(width=60, dev='pdf')
options(digits=3)
thm <- knit_theme$get("acid")
knit_theme$set(thm)
      @


% Define document options
\documentclass[10pt]{beamer}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
\usepackage{mathtools}
% bbm package for unitary vector or matrix symbol
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}



% Title page setup
\title[Time Series Univariate]{Time Series Univariate}
\subtitle{FRE6871 \& FRE7241, Spring 2019}
\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@nyu.edu}
\date{\today}



%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle


%%%%%%%%%%%%%%%
\section{Package \protect\emph{tseries} for Time Series Analysis}


%%%%%%%%%%%%%%%
\subsection{Package \protect\emph{tseries} for Time Series Analysis}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \emph{tseries} contains functions for time series analysis and computational finance, such as:
      \begin{itemize}
        \item downloading historical data,
        \item plotting time series,
        \item calculating risk and performance measures,
        \item statistical \emph{hypothesis testing},
        \item calibrating models to time series,
        \item portfolio optimization,
      \end{itemize}
      Package \emph{tseries} accepts time series of class \texttt{"ts"} and \texttt{"zoo"}, and also has its own class \texttt{"irts"} for irregular spaced time-series objects.
      \vskip1ex
      The package \emph{zoo} is designed for managing \emph{time series} and ordered data objects.
      \vskip1ex
      The function \texttt{zoo::coredata()} extracts the underlying numeric data from a complex data object.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# get documentation for package tseries
packageDescription("tseries")  # get short description

help(package="tseries")  # load help page

library(tseries)  # load package tseries

data(package="tseries")  # list all datasets in "tseries"

ls("package:tseries")  # list all objects in "tseries"

detach("package:tseries")  # Remove tseries from search path
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting \protect\emph{OHLC} Time Series Using Package \protect\emph{tseries}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \emph{tseries} contains functions for plotting time series:
      \begin{itemize}
        \item \texttt{seqplot.ts()} for plotting two time series in same panel.
        \item \texttt{plotOHLC()} for plotting \emph{OHLC} time series.
      \end{itemize}
      The function \texttt{plotOHLC()} from package \emph{tseries} plots \emph{OHLC} time series.
      <<tseries_OHLC,echo=(-(1:1)),eval=FALSE,fig.show='hide'>>=
par(mar=c(7, 2, 1, 2), mgp=c(2, 1, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
load(file="C:/Develop/R/lecture_slides/data/zoo_data.RData")
# get start and end dates
in_dex <- time(ts_stx_adj)
e_nd <- in_dex[NROW(in_dex)]
st_art <- round((4*e_nd + in_dex[1])/5)
# Plot using plotOHLC
plotOHLC(window(ts_stx_adj,
                start=st_art,
                end=e_nd)[, 1:4],
         xlab="", ylab="")
title(main="MSFT OHLC Prices")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/tseries_OHLC-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting Two Time Series Using \protect\emph{tseries}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{seqplot.ts()} from package \emph{tseries} plots two time series in same panel.
      \vskip1ex
      A \emph{ts} time series can be created from a \emph{zoo} time series using the function \emph{ts()}, after extracting the data and date attributes from the \emph{zoo} time series.
      \vskip1ex
      The function \texttt{decimal\_date()} from package \emph{lubridate} converts \texttt{POSIXct} objects into \texttt{numeric} \emph{year-fraction} dates.
      \vspace{-1em}
      <<tseries_seqplot,echo=(-(1:1)),eval=FALSE,fig.show='hide'>>=
par(mar=c(7, 2, 1, 2), mgp=c(2, 1, 0), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
library(lubridate)  # load lubridate
# get start and end dates of zoo_series
start_date <- decimal_date(start(zoo_stx))
end_date <- decimal_date(end(zoo_stx))
# Calculate frequency of zoo_stx
fre_quency <- 
  NROW(zoo_stx)/(end_date-start_date)
# Extract data from zoo_stx
da_ta <- zoo::coredata(
  window(zoo_stx, start=as.Date("2015-01-01"),
         end=end(zoo_stx)))
# Create ts object using ts()
ts_stx <- ts(data=da_ta, 
  start=decimal_date(as.Date("2015-01-01")),
  frequency=fre_quency)
seqplot.ts(x=ts_stx[, 1], y=ts_stx[, 4], xlab="", ylab="")
title(main="MSFT Open and Close Prices", line=-1)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/tseries_seqplot-1}\\
      \vspace{-3em}
      The function \texttt{zoo::coredata()} extracts the underlying numeric data from a complex data object.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Risk and Performance Estimation Using \protect\emph{tseries}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \emph{tseries} contains functions for calculating risk and performance:
      \begin{itemize}
        \item \texttt{maxdrawdown()} for calculating the maximum drawdown,
        \item \texttt{sharpe()} for calculating the \emph{Sharpe} ratio (defined as the excess return divided by the standard deviation),
        \item \texttt{sterling()} for calculating the \emph{Sterling} ratio (defined as the return divided by the maximum drawdown),
      \end{itemize}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(tseries)  # load package tseries
# Calculate maximum drawdown
maxdrawdown(zoo_stx_adj[, "AdjClose"])
max_drawd <- maxdrawdown(zoo_stx_adj[, "AdjClose"])
index(zoo_stx_adj)[max_drawd$from]
index(zoo_stx_adj)[max_drawd$to]
# Calculate Sharpe ratio
sharpe(zoo_stx_adj[, "AdjClose"])
# Calculate Sterling ratio
sterling(as.numeric(zoo_stx_adj[, "AdjClose"]))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Hypothesis Testing Using \protect\emph{tseries}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \emph{tseries} contains functions for testing statistical hypothesis on time series:
      \begin{itemize}
        \item \texttt{jarque.bera.test()} \emph{Jarque-Bera} test for normality of distribution of returns,
        \item \texttt{adf.test()} \emph{Augmented Dickey-Fuller} test for existence of unit roots,
        \item \texttt{pp.test()} \emph{Phillips-Perron} test for existence of unit roots,
        \item \texttt{kpss.test()} \emph{KPSS} test for stationarity,
        \item \texttt{po.test()} \emph{Phillips-Ouliaris} test for cointegration,
        \item \texttt{bds.test()} \emph{BDS} test for randomness,
      \end{itemize}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
zoo_stx <- suppressWarnings(  # load MSFT data
  get.hist.quote(instrument="MSFT",
                 start=Sys.Date()-365,
                 end=Sys.Date(),
                 origin="1970-01-01")
)  # End suppressWarnings
class(zoo_stx)
dim(zoo_stx)
tail(zoo_stx, 4)

# Calculate Sharpe ratio
sharpe(zoo_stx[, "Close"], r=0.01)
# Add title
plot(zoo_stx[, "Close"], xlab="", ylab="")
title(main="MSFT Close Prices", line=-1)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Calibrating Time Series Models Using \protect\emph{tseries}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \emph{tseries} contains functions for calibrating models to time series:
      \begin{itemize}
        \item \texttt{garch()} for calibrating \texttt{GARCH} volatility models,
        \item \texttt{arma()} for calibrating \texttt{ARMA} models,
      \end{itemize}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(tseries)  # load package tseries
zoo_stx <- suppressWarnings(  # load MSFT data
  get.hist.quote(instrument="MSFT",
                 start=Sys.Date()-365,
                 end=Sys.Date(),
                 origin="1970-01-01")
)  # End suppressWarnings
class(zoo_stx)
dim(zoo_stx)
tail(zoo_stx, 4)

# Calculate Sharpe ratio
sharpe(zoo_stx[, "Close"], r=0.01)
# Add title
plot(zoo_stx[, "Close"], xlab="", ylab="")
title(main="MSFT Close Prices", line=-1)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Optimization Using \protect\emph{tseries}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \emph{tseries} contains functions for miscellaneous functions:
      \vskip1ex
      \texttt{portfolio.optim()} for calculating mean-variance efficient portfolios,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(tseries)  # load package tseries
zoo_stx <- suppressWarnings(  # load MSFT data
  get.hist.quote(instrument="MSFT",
                 start=Sys.Date()-365,
                 end=Sys.Date(),
                 origin="1970-01-01")
)  # End suppressWarnings
class(zoo_stx)
dim(zoo_stx)
tail(zoo_stx, 4)

# Calculate Sharpe ratio
sharpe(zoo_stx[, "Close"], r=0.01)
# Add title
plot(zoo_stx[, "Close"], xlab="", ylab="")
title(main="MSFT Close Prices", line=-1)
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Package \protect\emph{quantmod} for Quantitative Financial Modeling}


%%%%%%%%%%%%%%%
\subsection{Package \protect\emph{quantmod} for Quantitative Financial Modeling}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \emph{quantmod} is designed for downloading, manipulating, and visualizing \emph{OHLC} time series data,
      \vskip1ex
      \emph{quantmod} operates on time series of class \texttt{"xts"}, and provides many useful functions for building quantitative financial models:
      \begin{itemize}
        \item \texttt{getSymbols()} for downloading data from external sources (\emph{Yahoo}, \emph{FRED}, etc.),
        \item \texttt{getFinancials()} for downloading financial statements,
        \item \texttt{adjustOHLC()} for adjusting \emph{OHLC} data,
        \item \texttt{Op()}, \texttt{Ad()}, \texttt{Vo()}, etc. for extracting \emph{OHLC} data columns,
        \item \texttt{periodReturn()}, \texttt{dailyReturn()}, etc. for calculating periodic returns,
        \item \texttt{chartSeries()} for candlestick plots of \emph{OHLC} data,
        \item \texttt{addBBands()}, \texttt{addMA()}, \texttt{addVo()}, etc. for adding technical indicators (Moving Averages, Bollinger Bands) and volume data to a plot,
      \end{itemize}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# load package quantmod
library(quantmod)
# get documentation for package quantmod
# get short description
packageDescription("quantmod")
# load help page
help(package="quantmod")
# list all datasets in "quantmod"
data(package="quantmod")
# list all objects in "quantmod"
ls("package:quantmod")
# Remove quantmod from search path
detach("package:quantmod")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting \protect\emph{OHLC} Time Series Using \texttt{chartSeries()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{chartSeries()} from package \emph{quantmod} can produce a variety of plots for \emph{OHLC} time series, including candlestick plots, bar plots, and line plots,
      \vskip1ex
      The argument \texttt{"type"} determines the type of plot (candlesticks, bars, or lines),
      \vskip1ex
      The argument \texttt{"theme"} accepts a \texttt{"chart.theme"} object, containing parameters that determine the plot appearance (colors, size, fonts),
      \vskip1ex
      \texttt{chartSeries()} automatically plots the volume data in a separate panel,
      \vskip1ex
      \emph{Candlestick} plots are designed to visualize \emph{OHLC} time series,
      <<chartSeries_basic,echo=(-(1:1)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(quantmod)
# Plot OHLC candlechart with volume
chartSeries(etf_env$VTI["2014-11"],
            name="VTI",
            theme=chartTheme("white"))
# Plot OHLC bar chart with volume
chartSeries(etf_env$VTI["2014-11"],
            type="bars",
            name="VTI",
            theme=chartTheme("white"))
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/chartSeries_basic-1}\\
      Each \emph{candlestick} displays one period of data, and consists of a box representing the \emph{Open} and \emph{Close} prices, and a vertical line representing the \emph{High} and \emph{Low} prices,
      \vskip1ex
      The color of the box signifies whether the \emph{Close} price was higher or lower than the \emph{Open},
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Redrawing Plots Using \texttt{reChart()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{reChart()} redraws plots using the same data set, but using additional parameters that control the plot appearance,
      \vskip1ex
      The argument \texttt{"subset"} allows subsetting the data to a smaller range of dates,
      <<echo=(-(1:1)),eval=FALSE>>=
library(quantmod)
# Plot OHLC candlechart with volume
chartSeries(etf_env$VTI["2008-11/2009-04"],
            name="VTI")
# Redraw plot only for Feb-2009, with white theme
reChart(subset="2009-02",
        theme=chartTheme("white"))
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/chartSeries_black.png}\\
      \includegraphics[width=0.5\paperwidth]{figure/chartSeries_white.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting Technical Indicators Using \texttt{chartSeries()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The argument \texttt{"TA"} allows adding technical indicators to the plot,
      \vskip1ex
      The technical indicators are functions provided by the package \emph{TTR},
      \vskip1ex
      The function \texttt{newTA()} allows defining new technical indicators,
      <<chartSeries_TA,echo=(-(1:1)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(quantmod)
# Candlechart with Bollinger Bands
chartSeries(etf_env$VTI["2014"],
            TA="addBBands(): addBBands(draw='percent'): addVo()",
            name="VTI with Bollinger Bands",
            theme=chartTheme("white"))
# Candlechart with two Moving Averages
chartSeries(etf_env$VTI["2014"],
            TA="addVo(): addEMA(10): addEMA(30)",
            name="VTI with Moving Averages",
            theme=chartTheme("white"))
# Candlechart with Commodity Channel Index
chartSeries(etf_env$VTI["2014"],
            TA="addVo(): addBBands(): addCCI()",
            name="VTI with Technical Indicators",
            theme=chartTheme("white"))
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/chartSeries_TA-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Adding Indicators and Lines Using \texttt{addTA()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{addTA()} adds indicators and lines to plots, and allows plotting lines representing a single vector of data,
      \vskip1ex
      The \texttt{addTA()} function argument \texttt{"on"} determines on which plot panel (subplot) the indicator is drawn,
      \vskip1ex
      \texttt{"on=NA"} is the default, and draws in a new plot panel below the existing plot,
      \vskip1ex
      \texttt{"on=1"} draws in the foreground of the main plot panel, and \texttt{"on=-1"} draws in the background,
      <<chartSeries_addTA,echo=(-(1:2)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(quantmod)
library(TTR)
oh_lc <- rutils::etf_env$VTI["2009-02/2009-03"]
VTI_adj <- Ad(oh_lc); VTI_vol <- Vo(oh_lc)
# Calculate volume-weighted average price
VTI_vwap <- TTR::VWAP(price=VTI_adj,
      volume=VTI_vol, n=10)
# Plot OHLC candlechart with volume
chartSeries(oh_lc, name="VTI plus VWAP",
            theme=chartTheme("white"))
# Add VWAP to main plot
addTA(ta=VTI_vwap, on=1, col='red')
# Add price minus VWAP in extra panel
addTA(ta=(VTI_adj-VTI_vwap), col='red')
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/chartSeries_addTA-3}\\
      The function \texttt{VWAP()} from package \emph{TTR} calculates the Volume Weighted Average Price as the average of past prices multiplied by their trading volumes, divided by the total volume,
      \vskip1ex
      The argument \texttt{"n"} represents the number of look-back periods used for averaging,
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Shading Plots Using \texttt{addTA()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{addTA()} accepts Boolean vectors for shading of plots,
      \vskip1ex
      The function \texttt{addLines()} draws vertical or horizontal lines in plots,
      <<chartSeries_addTA_shade,echo=(-(1:9)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(quantmod)
library(TTR)
oh_lc <- rutils::etf_env$VTI
VTI_adj <- Ad(oh_lc)
VTI_vol <- Vo(oh_lc)
VTI_vwap <- TTR::VWAP(price=VTI_adj, volume=VTI_vol, n=10)
VTI_adj <- VTI_adj["2009-02/2009-03"]
oh_lc <- oh_lc["2009-02/2009-03"]
VTI_vwap <- VTI_vwap["2009-02/2009-03"]
# Plot OHLC candlechart with volume
chartSeries(oh_lc, name="VTI plus VWAP shaded",
            theme=chartTheme("white"))
# Add VWAP to main plot
addTA(ta=VTI_vwap, on=1, col='red')
# Add price minus VWAP in extra panel
addTA(ta=(VTI_adj-VTI_vwap), col='red')
# Add background shading of areas
addTA((VTI_adj-VTI_vwap) > 0, on=-1,
      col="lightgreen", border="lightgreen")
addTA((VTI_adj-VTI_vwap) < 0, on=-1,
      col="lightgrey", border="lightgrey")
# Add vertical and horizontal lines at VTI_vwap minimum
addLines(v=which.min(VTI_vwap), col='red')
addLines(h=min(VTI_vwap), col='red')
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/chartSeries_addTA_shade-7}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting Time Series Using \texttt{chart\_Series()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{chart\_Series()} from package \emph{quantmod} is an improved version of \texttt{chartSeries()}, with better aesthetics,
      \vskip1ex
      \texttt{chart\_Series()} plots are compatible with the base \texttt{graphics} package in \texttt{R}, so that standard plotting functions can be used in conjunction with \texttt{chart\_Series()},
      <<chart_Series_shaded,echo=(-(1:9)),eval=FALSE,fig.width=7,fig.height=6,fig.show='hide'>>=
library(quantmod)
library(TTR)
oh_lc <- rutils::etf_env$VTI
VTI_adj <- Ad(oh_lc)
VTI_vol <- Vo(oh_lc)
VTI_vwap <- TTR::VWAP(price=VTI_adj, volume=VTI_vol, n=10)
VTI_adj <- VTI_adj["2009-02/2009-03"]
oh_lc <- oh_lc["2009-02/2009-03"]
VTI_vwap <- VTI_vwap["2009-02/2009-03"]
# OHLC candlechart VWAP in main plot,
chart_Series(x=oh_lc, # volume in extra panel
             TA="add_Vo(); add_TA(VTI_vwap, on=1)",
             name="VTI plus VWAP shaded")
# Add price minus VWAP in extra panel
add_TA(VTI_adj-VTI_vwap, col='red')
# Add background shading of areas
add_TA((VTI_adj-VTI_vwap) > 0, on=-1,
      col="lightgreen", border="lightgreen")
add_TA((VTI_adj-VTI_vwap) < 0, on=-1,
      col="lightgrey", border="lightgrey")
# Add vertical and horizontal lines
abline(v=which.min(VTI_vwap), col='red')
abline(h=min(VTI_vwap), col='red')
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/chart_Series_shaded}\\
      \texttt{chart\_Series()} also has its own functions for adding indicators: \texttt{add\_TA()}, \texttt{add\_BBands()}, etc.
      \vskip1ex
      Note that functions associated with \texttt{chart\_Series()} contain an underscore in their name,
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plot and Theme Objects of \texttt{chart\_Series()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{chart\_Series()} creates a \emph{plot object} and returns it \emph{invisibly},
      \vskip1ex
      A \emph{plot object} is an environment of class \emph{replot}, containing parameters specifying a plot,
      \vskip1ex
      A plot can be rendered by calling, plotting, or printing the \emph{plot object},
      \vskip1ex
      A plot \emph{theme object} is a list containing parameters that determine the plot appearance (colors, size, fonts),
      \vskip1ex
      The function \texttt{chart\_theme()} returns the \emph{theme object},
      \vskip1ex
      \texttt{chart\_Series()} plots can be modified by modifying \emph{plot objects} or \emph{theme objects},
      \vskip1ex
      Plot and theme objects can be modified directly, or by using accessor and setter functions,
      \vskip1ex
      The parameter \texttt{"plot=FALSE"} suppresses plotting and allows modifying \emph{plot objects},
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:2)),eval=FALSE>>=
library(quantmod)
oh_lc <- rutils::etf_env$VTI["2009-02/2009-03"]
# Extract plot object
ch_ob <- chart_Series(x=oh_lc, plot=FALSE)
class(ch_ob)
ls(ch_ob)
class(ch_ob$get_ylim)
class(ch_ob$set_ylim)
# ls(ch_ob$Env)
class(ch_ob$Env$actions)
plot_theme <- chart_theme()
class(plot_theme)
ls(plot_theme)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Customizing \texttt{chart\_Series()} Plots}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{chart\_Series()} plots can be customized by modifying the plot and theme objects,
      \vskip1ex
      Plot and theme objects can be modified directly, or by using accessor and setter functions,
      \vskip1ex
      A plot is rendered by calling, plotting, or printing the plot object,
      \vskip1ex
      The parameter \texttt{"plot=FALSE"} suppresses plotting and allows modifying \emph{plot objects},
      <<chart_Series_custom_axis,echo=(-(1:1)),eval=FALSE,fig.width=5,fig.height=4,fig.show='hide'>>=
library(quantmod)
oh_lc <- rutils::etf_env$VTI["2010-04/2010-05"]
# Extract, modify theme, format tick marks "%b %d"
plot_theme <- chart_theme()
plot_theme$format.labels <- "%b %d"
# Create plot object
ch_ob <- chart_Series(x=oh_lc,
                      theme=plot_theme, plot=FALSE)
# Extract ylim using accessor function
y_lim <- ch_ob$get_ylim()
y_lim[[2]] <- structure(
  range(Ad(oh_lc)) + c(-1, 1),
  fixed=TRUE)
# modify plot object to reduce y-axis range
ch_ob$set_ylim(y_lim)  # use setter function
# Render the plot
plot(ch_ob)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/chart_Series_custom_axis-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting \texttt{chart\_Series()} in Multiple Panels}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{chart\_Series()} plots are compatible with the base \texttt{graphics} package, allowing easy plotting in multiple panels,
      \vskip1ex
      The parameter \texttt{"plot=FALSE"} suppresses plotting and allows adding extra plot elements,
      <<echo=(-(1:1)),eval=FALSE>>=
library(HighFreq)
# Calculate VTI and XLF volume-weighted average price
VTI_vwap <-
  TTR::VWAP(price=Ad(rutils::etf_env$VTI),
            volume=Vo(rutils::etf_env$VTI), n=10)
XLF_vwap <-
  TTR::VWAP(price=Ad(rutils::etf_env$XLF),
            volume=Vo(rutils::etf_env$XLF), n=10)
# open graphics device, and define
# Plot area with two horizontal panels
x11(); par(mfrow=c(2, 1))
ch_ob <- chart_Series(  # Plot in top panel
  x=etf_env$VTI["2009-02/2009-04"],
  name="VTI", plot=FALSE)
add_TA(VTI_vwap["2009-02/2009-04"],
       lwd=2, on=1, col='blue')
ch_ob <- chart_Series(  # Plot in bottom panel
  x=etf_env$XLF["2009-02/2009-04"],
  name="XLF", plot=FALSE)
add_TA(XLF_vwap["2009-02/2009-04"],
       lwd=2, on=1, col='blue')
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/chart_Series_panels.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting \protect\emph{OHLC} Time Series Using Package \protect\emph{dygraphs}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{dygraph()} from package \emph{dygraphs} creates interactive plots for \emph{xts} time series,
      \vskip1ex
      The function \texttt{dyCandlestick()} creates a \emph{candlestick} plot object for \emph{OHLC} data, and uses the first four columns to plot \emph{candlesticks}, and it plots any additional columns as lines,
      <<echo=TRUE,eval=FALSE>>=
library(dygraphs)
# Calculate volume-weighted average price
oh_lc <- rutils::etf_env$VTI
VTI_vwap <- TTR::VWAP(price=quantmod::Ad(oh_lc),
    volume=quantmod::Vo(oh_lc), n=20)
# Add VWAP to OHLC  data
oh_lc <- cbind(oh_lc[, c(1:3, 6)],
               VTI_vwap)["2009-02/2009-04"]
# Create dygraphs object
dy_graph <- dygraphs::dygraph(oh_lc)
# Convert dygraphs object to candlestick plot
dy_graph <- dygraphs::dyCandlestick(dy_graph)
# Render candlestick plot
dy_graph
# Candlestick plot using pipes syntax
dygraphs::dygraph(oh_lc) %>% dyCandlestick()
# Candlestick plot without using pipes syntax
dygraphs::dyCandlestick(dygraphs::dygraph(oh_lc))
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth, height=0.35\paperwidth]{figure/dygraphs_candlestick.png}\\
      Each \emph{candlestick} displays one period of data, and consists of a box representing the \emph{Open} and \emph{Close} prices, and a vertical line representing the \emph{High} and \emph{Low} prices,
      \vskip1ex
      The color of the box signifies whether the \emph{Close} price was higher or lower than the \emph{Open},
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{dygraphs} \protect\emph{OHLC} Plots With Background Shading}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{dyShading()} adds shading to a \emph{dygraphs} plot object,
      <<echo=TRUE,eval=FALSE>>=
# Create candlestick plot with background shading
in_dex <- index(oh_lc)
in_dic <-
  rutils::diff_it(oh_lc[, 4] > oh_lc[, "VWAP"])
in_dic <- rbind(cbind(which(in_dic==1), 1),
  cbind(which(in_dic==(-1)), -1))
in_dic <- in_dic[order(in_dic[, 1]), ]
in_dic <- rbind(c(1, -in_dic[1, 2]), in_dic,
  c(NROW(oh_lc), -in_dic[NROW(in_dic), 2]))
in_dic <-
  data.frame(in_dex[in_dic[, 1]], in_dic[, 2])
# Create dygraphs object
dy_graph <- dygraphs::dygraph(oh_lc) %>%
  dyCandlestick()
# Add shading
for (i in 1:(NROW(in_dic)-1)) {
  if (in_dic[i, 2] == 1)
    dy_graph <- dy_graph %>% dyShading(from=in_dic[i, 1], to=in_dic[i+1, 1], color="lightgreen")
  else
    dy_graph <- dy_graph %>% dyShading(from=in_dic[i, 1], to=in_dic[i+1, 1], color="antiquewhite")
}  # End for
# Render plot
dy_graph
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth, height=0.35\paperwidth]{figure/dygraphs_candlestick_shaded.png}\\
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{dygraphs} Plots With Two \texttt{"y"} Axes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{dyAxis()} from package \emph{dygraphs} adds customized axes to a \emph{dygraphs} plot object,
      \vskip1ex
      The function \texttt{dySeries()} adds a time series to a \emph{dygraphs} plot object,
      <<echo=TRUE,eval=FALSE>>=
library(dygraphs)
# Prepare VTI and IEF prices
price_s <- cbind(Ad(rutils::etf_env$VTI),
                 Ad(rutils::etf_env$IEF))
price_s <- na.omit(price_s)
col_names <- rutils::get_name(colnames(price_s))
colnames(price_s) <- col_names
# dygraphs plot with two y-axes
library(dygraphs)
dygraphs::dygraph(price_s, main=paste(col_names, collapse=" and ")) %>%
  dyAxis(name="y", label="VTI", independentTicks=TRUE) %>%
  dyAxis(name="y2", label="IEF", independentTicks=TRUE) %>%
  dySeries(name="VTI", axis="y", col="red") %>%
  dySeries(name="IEF", axis="y2", col="blue")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth, height=0.35\paperwidth]{figure/dygraphs_2yaxis.png}
  \end{columns}
\end{block}

\end{frame}




%%%%%%%%%%%%%%%
\section{Package \protect\emph{qmao} for Quantitative Financial Modeling}


%%%%%%%%%%%%%%%
\subsection{draft: Package \protect\emph{qmao} for Quantitative Financial Modeling}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \emph{qmao} is designed for downloading, manipulating, and visualizing \emph{OHLC} time series data,
package \emph{quantmod} 
      \vskip1ex
      \emph{qmao} uses time series of class \texttt{"xts"}, and provides many useful functions for building quantitative financial models:
      \begin{itemize}
        \item \texttt{getSymbols()} for downloading data from external sources (\emph{Yahoo}, \emph{FRED}, etc.),
        \item \texttt{getFinancials()} for downloading financial statements,
        \item \texttt{adjustOHLC()} for adjusting \emph{OHLC} data,
        \item \texttt{Op()}, \texttt{Ad()}, \texttt{Vo()}, etc. for extracting \emph{OHLC} data columns,
        \item \texttt{periodReturn()}, \texttt{dailyReturn()}, etc. for calculating periodic returns,
        \item \texttt{chartSeries()} for candlestick plots of \emph{OHLC} data,
        \item \texttt{addBBands()}, \texttt{addMA()}, \texttt{addVo()}, etc. for adding technical indicators (Moving Averages, Bollinger Bands) and volume data to a plot,
      \end{itemize}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# load package qmao
library(qmao)
# get documentation for package qmao
# get short description
packageDescription("qmao")
# load help page
help(package="qmao")
# list all datasets in "qmao"
data(package="qmao")
# list all objects in "qmao"
ls("package:qmao")
# Remove qmao from search path
detach("package:qmao")
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Time Series of Asset Prices}


%%%%%%%%%%%%%%%
\subsection{Geometric Brownian Motion}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If the percentage asset returns $r_t \mathrm{d} t = \mathrm{d} \log{P_t}$ follow \emph{Brownian motion}:
      \begin{displaymath}
        r_t \mathrm{d} t = \mathrm{d} \log{P_t} = ( \mu - \frac{\sigma^2}{2} ) \mathrm{d}t + \sigma \mathrm{d} W_t
      \end{displaymath}
      Then asset prices $P_t$ follow \emph{Geometric Brownian motion} (GBM):
      \begin{displaymath}
        \mathrm{d} P_t = \mu P_t \mathrm{d}t + \sigma P_t \mathrm{d} W_t
      \end{displaymath}
      Where $\sigma$ is the volatility of asset returns, and $W_t$ is a \emph{Brownian motion}, with $\mathrm{d} W_t$ following the standard normal distribution $N(0, \sqrt{\mathrm{d}t})$,
      \vskip1ex
      The solution of \emph{Geometric Brownian motion} is equal to:
      \begin{displaymath}
        P_t = P_0 \exp[( \mu - \frac{\sigma^2}{2} ) t + \sigma W_t]
      \end{displaymath}
      The convexity correction: $-\frac{\sigma^2}{2}$ ensures that the growth rate of prices is equal to $\mu$, (in accordance with Ito's lemma),
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/brown_geom.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# define daily volatility and growth rate
vol_at <- 0.01; dri_ft <- 0.0; len_gth <- 1000
# Simulate geometric Brownian motion
re_turns <- vol_at*rnorm(len_gth) +
  dri_ft - vol_at^2/2
price_s <- exp(cumsum(re_turns))
plot(price_s, type="l",
     xlab="periods", ylab="prices",
     main="geometric Brownian motion")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating Random \protect\emph{OHLC} Prices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Random \emph{OHLC} prices are useful for testing financial models,
      <<echo=TRUE,eval=FALSE>>=
# Simulate geometric Brownian motion
vol_at <- 0.01/sqrt(48)
dri_ft <- 0.0
len_gth <- 1e4
in_dex <- seq(from=as.POSIXct(paste(Sys.Date()-250, "09:30:00")),
  length.out=len_gth, by="30 min")
price_s <- xts(exp(cumsum(vol_at*rnorm(len_gth) + dri_ft - vol_at^2/2)),
  order.by=in_dex)
price_s <- cbind(price_s,
  volume=sample(x=10*(2:18), size=len_gth, replace=TRUE))
# Aggregate to daily OHLC data
oh_lc <- xts::to.daily(price_s)
quantmod::chart_Series(oh_lc, name="random prices")
# dygraphs candlestick plot using pipes syntax
library(dygraphs)
dygraphs::dygraph(oh_lc[, 1:4]) %>% 
  dyCandlestick()
# dygraphs candlestick plot without using pipes syntax
dygraphs::dyCandlestick(dygraphs::dygraph(oh_lc[, 1:4]))
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/random_ohlc.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Paths of Geometric Brownian Motion}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If asset prices follow \emph{Geometric Brownian motion}, then at any point in time, they are distributed according to the \emph{Log-normal} distribution,
      \vskip1ex
      The volatility increases with time as the square root of time: $\sigma \propto \sqrt{t}$
      \vskip1ex
      The skewness of the price distribution increases exponentially with the volatility and time: $\mathbb{E}[(x - \mathbb{E}[x])^3] \propto e^{1.5 \sigma^2} \propto e^{1.5 t}$
      <<echo=TRUE,eval=FALSE>>=
# define daily volatility and growth rate
vol_at <- 0.01; dri_ft <- 0.0; len_gth <- 5000
path_s <- 10
# Simulate multiple paths of geometric Brownian motion
price_s <- matrix(vol_at*rnorm(path_s*len_gth) +
    dri_ft - vol_at^2/2, nc=path_s)
price_s <- exp(matrixStats::colCumsums(price_s))
# Create xts time series
price_s <- xts(price_s, order.by=seq.Date(Sys.Date()-NROW(price_s)+1, Sys.Date(), by=1))
# Plot xts time series
col_ors <- colorRampPalette(c("red", "blue"))(NCOL(price_s))
col_ors <- col_ors[order(order(price_s[NROW(price_s), ]))]
par(mar=c(3, 3, 2, 2), oma=c(0, 0, 0, 0))
plot.zoo(price_s, main="Multiple paths of geometric Brownian motion",
         xlab=NA, ylab=NA, plot.type="single", col=col_ors)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/brown_geom_paths.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Distribution of Paths of Geometric Brownian Motion}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Prices following \emph{Geometric Brownian motion} have a large positive skewness, so that the expected value of prices is skewed by a few paths with very high prices, while the prices of the majority of paths are below their expected value,
      \vskip1ex
      The skewness of the price distribution increases exponentially with the volatility and time: $\mathbb{E}[(x - \mathbb{E}[x])^3] \propto e^{1.5 \sigma^2} \propto e^{1.5 t}$
      <<echo=TRUE,eval=FALSE>>=
# define daily volatility and growth rate
vol_at <- 0.01; dri_ft <- 0.0; len_gth <- 10000
path_s <- 100
# Simulate multiple paths of geometric Brownian motion
price_s <- matrix(vol_at*rnorm(path_s*len_gth) +
    dri_ft - vol_at^2/2, nc=path_s)
price_s <- exp(matrixStats::colCumsums(price_s))
# Calculate percentage of paths below the expected value
per_centage <- rowSums(price_s < 1.0) / path_s
# Create xts time series of percentage of paths below the expected value
per_centage <- xts(per_centage, order.by=seq.Date(Sys.Date()-NROW(per_centage)+1, Sys.Date(), by=1))
# Plot xts time series of percentage of paths below the expected value
par(mar=c(3, 3, 2, 2), oma=c(0, 0, 0, 0))
plot.zoo(per_centage, main="Percentage of GBM paths below mean",
         xlab=NA, ylab=NA, col="blue")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/brown_geom_percent.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\protect\emph{Log-normal} Probability Distribution}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Let \texttt{x} be a random variable which follows the \emph{Normal} distribution $N(x, \mu, \sigma)$,
      \vskip1ex
      Then the exponential of \texttt{x}: $y = e^x$ follows the \emph{Log-normal} distribution:,
      \begin{displaymath}
        logN(y, \mu, \sigma) = \frac{\exp(-(\log{y} - \mu)^2/2 \sigma^2)}{y \sigma \sqrt{2 \pi}}
      \end{displaymath}
      The mean of the \emph{Log-normal} distribution is equal to: $\mathbb{E}[x] = \exp(\mu + \sigma^2/2)$
      \vskip1ex
      The \emph{Log-normal} distribution has a positive skewness (third moment) equal to: $\mathbb{E}[(x - \mathbb{E}[x])^3] = (e^{\sigma^2} + 2) \sqrt{e^{\sigma^2} - 1}$
      \vskip1ex
      If asset returns follow the \emph{Normal} probability distribution, then asset prices follow the \emph{Log-normal} distribution,
      <<echo=TRUE,eval=FALSE>>=
# Sigma values
sig_mas <- c(0.5, 1, 1.5)
# Create plot colors
col_ors <- c("black", "red", "blue")
# Create legend labels
lab_els <- paste("sigma", sig_mas, sep="=")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/log_norm_dist.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Plot all curves
for (in_dex in 1:NROW(sig_mas)) {
  curve(expr=dlnorm(x, sdlog=sig_mas[in_dex]),
        type="l", xlim=c(0, 3),
        xlab="", ylab="", lwd=2,
        col=col_ors[in_dex],
        add=as.logical(in_dex-1))
}  # End for
# Add title
title(main="Log-normal Distributions", line=0.5)
# Add legend
legend("topright", inset=0.05, title="Sigmas",
       lab_els, cex=0.8, lwd=2,
       lty=rep(1, NROW(sig_mas)),
       col=col_ors)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Time Evolution of Stock Prices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Stock prices evolve in time similarly to \emph{Geometric Brownian motion}, and they also exhibit a very skewed distribution of prices,
      <<echo=TRUE,eval=FALSE>>=
# load S&P500 stock prices
load("C:/Develop/R/lecture_slides/data/sp500.RData")
ls(env_sp500)
# Extract closing prices
price_s <- eapply(env_sp500, quantmod::Cl)
# Flatten price_s into a single xts series
price_s <- rutils::do_call(cbind, price_s)
# Carry forward and backward non-NA prices
price_s <- xts:::na.locf.xts(price_s)
price_s <- xts:::na.locf.xts(price_s, fromLast=TRUE)
sum(is.na(price_s))
# Rename and normalize columns
colnames(price_s) <- sapply(colnames(price_s),
  function(col_name) strsplit(col_name, split="[.]")[[1]][1])
price_s <- xts(t(t(price_s) / as.numeric(price_s[1, ])),
               order.by=index(price_s))
# Calculate permution index for sorting the lowest to highest final price_s
or_der <- order(price_s[NROW(price_s), ])
# Select a few symbols
sym_bols <- colnames(price_s)[or_der]
sym_bols <- sym_bols[seq.int(from=1, to=(NROW(sym_bols)-1), length.out=20)]
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/stock_index_paths.png}
    \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Plot xts time series of price_s
col_ors <- colorRampPalette(c("red", "blue"))(NROW(sym_bols))
col_ors <- col_ors[order(order(price_s[NROW(price_s), sym_bols]))]
par(mar=c(3, 3, 2, 2), oma=c(0, 0, 0, 0))
plot.zoo(price_s[, sym_bols], main="20 S&P500 stock prices (normalized)",
         xlab=NA, ylab=NA, plot.type="single", col=col_ors)
legend(x="topleft", inset=0.05, cex=0.8,
       legend=rev(sym_bols), col=rev(col_ors), lwd=6, lty=1)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Distribution of Stock Prices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      In most stock indices, a small number of stocks reach very high prices, while the prices of the majority of the other stocks remain below the average index price,
      \vskip1ex
      For example, for a recent cohort of S\&P500 stocks (but with prices starting from 1990), the current prices of almost 80\% of the stocks are now below the average price of the cohort,
      <<echo=TRUE,eval=FALSE>>=
# Calculate average of valid stock prices
val_id <- (price_s != 1)  # valid stocks
n_stocks <- rowSums(val_id)
n_stocks[1] <- NCOL(price_s)
in_dex <- rowSums(price_s * val_id) / n_stocks
# Calculate percentage of stock prices below the average price
per_centage <- rowSums((price_s < in_dex) & val_id) / n_stocks
# Create xts time series of average stock prices
in_dex <- xts(in_dex, order.by=index(price_s))
# Plot xts time series of average stock prices
x11(width=6, height=4)
par(mar=c(3, 3, 2, 2), oma=c(0, 0, 0, 0))
plot.zoo(in_dex, main="Average S&P500 stock prices (normalized from 1990)",
         xlab=NA, ylab=NA, col="blue")
# Create xts time series of percentage of stock prices below the average price
per_centage <- xts(per_centage, order.by=index(price_s))
# Plot percentage of stock prices below the average price
plot.zoo(per_centage[-(1:2),],
         main="Percentage of S&P500 stock prices below the average price",
         xlab=NA, ylab=NA, col="blue")
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/stock_index_prices.png}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/stock_index_prices_percent.png}
      <<echo=TRUE,eval=FALSE>>=
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Time Series Modeling}


%%%%%%%%%%%%%%%
\subsection{Autocorrelation Function}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Autocorrelation Function} (ACF) are the correlation coefficients of a time series with its lagged values:
      \begin{displaymath}
        \rho_k = \frac{1}{(n-k)\sigma^2} {\sum_{i=k+1}^n (x_i-\bar{x})(x_{i-k}-\bar{x})}
      \end{displaymath}
      \vskip1ex
      The function \texttt{acf()} calculates and plots the autocorrelation function of a time series.
      \vskip1ex
      \texttt{acf()} returns the \texttt{acf} data invisibly, i.e. the return value can be assigned to a variable, but otherwise it isn't automatically printed to the console.
      \vspace{-1em}
        <<echo=(-(1:2)),eval=FALSE>>=
x11(width=6, height=4)
par(mar=c(4, 3, 1, 1), oma=c(0, 0, 0, 0))
library(zoo)
re_turns <- 
  diff(log(as.numeric(EuStockMarkets[, 1])))
# acf() autocorrelation from package stats
acf(re_turns, lag=10, main="")
title(main="acf of DAX returns", line=-1)
      @
      \vspace{-1em}
      The package \emph{zoo} is designed for managing \emph{time series} and ordered data objects.
      \vskip1ex
      The function \texttt{as.numeric()} coerces complex data objects into \texttt{numeric} vectors, and removes all their \emph{attributes}.
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/acf_dax.png}\\
      The horizontal dashed lines are confidence intervals of the autocorrelation estimator (at 95\% significance level).
      \vskip1ex
      The DAX time series of returns does not appear to have statistically significant autocorrelations.
      \vskip1ex
      The function \texttt{acf()} has the drawback that it plots the lag-zero autocorrelation (which is simply \texttt{1}).
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Ljung-Box Test of Autocorrelation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Ljung-Box} test \emph{null hypothesis} is that autocorrelations are equal to zero,
      \vskip1ex
      The test statistic is:
      \begin{displaymath}
        Q = n(n+2) \sum_{k=1}^{maxlag} \frac{{\hat\rho}_k^2}{n-k}
      \end{displaymath}
      Where \texttt{n} is the sample size, and the ${\hat\rho}_k$ are sample autocorrelations,
      \vskip1ex
      The \emph{Ljung-Box} statistic follows the \emph{chi-squared} distribution with \emph{maxlag} degrees of freedom,
      \vskip1ex
      The \emph{Ljung-Box} statistic is small for time series that are \emph{not} autocorrelated,
      \vskip1ex
      The \emph{p}-value for DAX returns is large, and we conclude that the \emph{null hypothesis} is \texttt{TRUE}, and that DAX returns are \emph{not} autocorrelated,
      \vskip1ex
      The \emph{p}-value for changes in econometric data is extremely small, and we conclude that the \emph{null hypothesis} is \texttt{FALSE}, and that econometric data \emph{are} autocorrelated,
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(Ecdat)  # load Ecdat
macro_zoo <- as.zoo(Macrodat[, c("lhur", "fygm3")])
colnames(macro_zoo) <- c("unemprate", "3mTbill")
macro_diff <- na.omit(diff(macro_zoo))
# Ljung-Box test for DAX returns
# 'lag' is the number of autocorrelation coefficients
Box.test(re_turns, lag=10, type="Ljung")

# Changes in 3 month T-bill rate are autocorrelated
Box.test(macro_diff[, "3mTbill"],
         lag=10, type="Ljung")

# Changes in unemployment rate are autocorrelated
Box.test(macro_diff[, "unemprate"],
         lag=10, type="Ljung")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Improved Autocorrelation Function}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Inspection of the data returned by \texttt{acf()} shows how to omit the lag-zero autocorrelation,
      <<echo=(-(1:1)),eval=FALSE>>=
library(zoo)  # load package zoo
dax_acf <- acf(re_turns, plot=FALSE)
summary(dax_acf)  # get the structure of the "acf" object
# Print(dax_acf)  # Print acf data
dim(dax_acf$acf)
dim(dax_acf$lag)
head(dax_acf$acf)
      @
    \column{0.5\textwidth}
      The below wrapper function for \texttt{acf()} omits the lag-zero autocorrelation,
      <<echo=TRUE,eval=FALSE>>=
acf_plus <- function(ts_data, plo_t=TRUE,
                      xlab="Lag", ylab="",
                      main="", ...) {
  acf_data <- acf(x=ts_data, plot=FALSE, ...)
# Remove first element of acf data
  acf_data$acf <-  array(data=acf_data$acf[-1],
          dim=c((dim(acf_data$acf)[1]-1), 1, 1))
  acf_data$lag <-  array(data=acf_data$lag[-1],
          dim=c((dim(acf_data$lag)[1]-1), 1, 1))
  if (plo_t) {
    ci <- qnorm((1+0.95)/2)*sqrt(1/NROW(ts_data))
    ylim <- c(min(-ci, range(acf_data$acf[-1])),
              max(ci, range(acf_data$acf[-1])))
    plot(acf_data, xlab=xlab, ylab=ylab,
         ylim=ylim, main="", ci=0)
    title(main=main, line=0.5)
    abline(h=c(-ci, ci), col="blue", lty=2)
  }
  invisible(acf_data)  # Return invisibly
}  # End acf_plus
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Autocorrelation of DAX Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The DAX time series of returns does not appear to have statistically significant autocorrelations,
      \vskip1ex
      But the \texttt{acf} plot alone is not enough to test whether autocorrelations are statistically significant or not,
        <<dax_acf,echo=(-(1:2)),eval=FALSE,fig.width=4,fig.height=3.5,fig.show='hide'>>=
par(mar=c(5,0,1,2), oma=c(1,2,1,0), mgp=c(2,1,0), cex.lab=0.8, cex.axis=1.0, cex.main=0.8, cex.sub=0.5)
library(zoo)  # load package zoo
# improved autocorrelation function
acf_plus(re_turns, lag=10, main="")
title(main="acf of DAX returns", line=-1)
# Ljung-Box test for DAX returns
Box.test(re_turns, lag=10, type="Ljung")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/dax_acf-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Autocorrelation of Squared DAX Returns}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Squared DAX returns do have statistically significant autocorrelations,
      \vskip1ex
      But squared random returns are not autocorrelated,
      <<dax_squared_acf,echo=(-(1:2)),eval=FALSE,fig.height=8,fig.show='hide'>>=
par(oma=c(15, 1, 1, 1), mgp=c(0, 0.5, 0), mar=c(1, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(2,1))  # Set plot panels
# Autocorrelation of squared DAX returns
acf_plus(re_turns^2, lag=10, main="")
title(main="acf of squared DAX returns",
      line=-1)
# Autocorrelation of squared random returns
acf_plus(rnorm(NROW(re_turns))^2,
         lag=10, main="")
title(main="acf of squared random returns",
      line=-1)
# Ljung-Box test for squared DAX returns
Box.test(re_turns^2, lag=10, type="Ljung")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/dax_squared_acf-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{U.S. Macroeconomic Data}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The package \emph{Ecdat} contains the \texttt{Macrodat} U.S. macroeconomic data,
      \vskip1ex
      \texttt{"lhur"} is the unemployment rate (average of months in quarter),
      \vskip1ex
      \texttt{"fygm3"} 3 month treasury bill interest rate (last month in quarter)
      <<macro_data,echo=(-(1:1)),eval=FALSE,fig.show='hide'>>=
library(zoo)  # load package zoo
library(Ecdat)  # load Ecdat
colnames(Macrodat)  # United States Macroeconomic Time Series
macro_zoo <- as.zoo(  # Coerce to "zoo"
          Macrodat[, c("lhur", "fygm3")])
colnames(macro_zoo) <- c("unemprate", "3mTbill")
# ggplot2 in multiple panes
autoplot(  # generic ggplot2 for "zoo"
  object=macro_zoo, main="US Macro",
  facets=Series ~ .) + # End autoplot
  xlab("") +
theme(  # modify plot theme
  legend.position=c(0.1, 0.5),
  plot.title=element_text(vjust=-2.0),
  plot.margin=unit(c(-0.5, 0.0, -0.5, 0.0), "cm"),
  plot.background=element_blank(),
  axis.text.y=element_blank()
)  # End theme
      @
    \column{0.5\textwidth}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/macro_data-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Autocorrelation of Econometric Data}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Most econometric data displays a high degree of autocorrelation,
      \vskip1ex
      But time series of tradeable prices display very low autocorrelation,
      <<macro_corr,echo=(-(1:2)),eval=FALSE,fig.height=8,fig.show='hide'>>=
par(oma=c(15, 1, 1, 1), mgp=c(0, 0.5, 0), mar=c(1, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(2,1))  # Set plot panels
macro_diff <- na.omit(diff(macro_zoo))
acf_plus(coredata(macro_diff[, "unemprate"]), 
  lag=10, main="quarterly unemployment rate")
acf_plus(coredata(macro_diff[, "3mTbill"]), 
  lag=10, main="3 month T-bill EOQ")
      @
      The function \texttt{zoo::coredata()} extracts the underlying numeric data from a complex data object.
    \column{0.5\textwidth}
      \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/macro_corr-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Filtering Time Series Using Function \texttt{filter()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{filter()} applies a linear filter to time series, vectors, and matrices, and returns a time series of class \texttt{"ts"}.
      \vskip1ex
      The function \texttt{filter()} with the argument \texttt{method="convolution"} calculates the \emph{convolution} of the vector $r_i$ with the filter $\varphi_i$:
      \begin{displaymath}
        f_i = \varphi_1 r_{i-1} + \varphi_2 r_{i-2} + \ldots + \varphi_p r_{i-p}
      \end{displaymath}
      Where $f_i$ is the filtered output vector, and $\varphi_i$ are the filter coefficients.
      \vskip1ex
      \texttt{filter()} with \texttt{method="recursive"} calculates a \emph{recursive} filter over the vector of random \emph{innovations} $\varepsilon_i$ as follows:
      \begin{displaymath}
        r_i = \varphi_1 r_{i-1} + \varphi_2 r_{i-2} + \ldots + \varphi_p r_{i-p} + \varepsilon_i
      \end{displaymath}
      Where $r_i$ is the filtered output vector, and $\varphi_i$ are the filter coefficients.
      \vskip1ex
      The \emph{recursive} filter describes an \emph{AR(p)} process, which is a special case of an \emph{ARIMA} process.
      \vskip1ex
      \texttt{filter()} is very fast because it calculates the filter by calling compiled \texttt{C++} functions.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Extract DAX time series
se_ries <- EuStockMarkets[, 1]
# Filter only over past values (sides=1)
co_eff <- rep(1/5,5)
filter_ed <- filter(se_ries, filter=co_eff, 
                   method="convolution", sides=1)
# filter() returns a time series of class "ts"
class(filter_ed)
# Filter using compiled C++ function directly
getAnywhere(C_cfilter)
str(stats:::C_cfilter)
filter_fast <- .Call(stats:::C_cfilter, se_ries, filter=co_eff, sides=1, circular=FALSE)
all.equal(as.numeric(filter_ed), filter_fast, check.attributes=FALSE)
# microbenchmark speed of the two methods
library(microbenchmark)
summary(microbenchmark(
  filter=filter(se_ries, filter=co_eff, method="convolution", sides=1),
  filter_fast=.Call(stats:::C_cfilter, se_ries, filter=co_eff, sides=1, circular=FALSE)
  ), times=10)[, c(1, 4, 5)]
# Simulate ARIMA using filter()
in_nov <- rnorm(NROW(EuStockMarkets))
arima_filter <- filter(x=in_nov, 
  filter=co_eff, method="recursive")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Plotting Filtered Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \vspace{-1em}
      <<dax_filter,eval=FALSE,fig.width=6,fig.height=5,fig.show='hide'>>=
library(zoo)  # load zoo
library(ggplot2)  # load ggplot2
library(gridExtra)  # load gridExtra
# Coerce to zoo and merge the time series
filter_ed <- cbind(as.zoo(se_ries),
                  as.zoo(filter_ed))
colnames(filter_ed) <- c("DAX", "DAX filtered")
filter_ed <- window(filter_ed,
                   start=1997, end=1998)
autoplot(  # Plot ggplot2
    filter_ed, main="Filtered DAX",
    facets=NULL) +  # End autoplot
xlab("") + ylab("") +
theme(  # modify plot theme
    legend.position=c(0.1, 0.5),
    plot.title=element_text(vjust=-2.0),
    plot.margin=unit(c(-0.5, 0.0, -0.5, 0.0), "cm"),
    plot.background=element_blank(),
    axis.text.y=element_blank()
    )  # End theme
# End ggplot2
      @
    \column{0.5\textwidth}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/dax_filter-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Autocorrelation Function of Filtered Time Series}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Filtering a time series creates autocorrelations,
      <<dax_filter_acf,echo=(-(1:1)),eval=FALSE,fig.height=8,fig.show='hide'>>=
par(oma=c(15, 1, 1, 1), mgp=c(0, 0.5, 0), mar=c(1, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
re_turns <- na.omit(diff(log(filter_ed)))
par(mfrow=c(2,1))  # Set plot panels

acf_plus(coredata(re_turns[, 1]), lag=10,
         xlab="")
title(main="DAX", line=-1)

acf_plus(coredata(re_turns[, 2]), lag=10,
         xlab="")
title(main="DAX filtered", line=-1)
      @
    \column{0.5\textwidth}
      \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/dax_filter_acf-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Autoregressive \protect\emph{ARIMA} Processes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      An \emph{autoregressive} process \emph{AR(p)} of order \emph{p} for a time series $r_i$ is defined as:
      \begin{displaymath}
        r_i = \varphi_1 r_{i-1} + \varphi_2 r_{i-2} + \ldots + \varphi_p r_{i-p} + \varepsilon_i
      \end{displaymath}
      Where $\varphi_i$ are the \emph{AR} coefficients, and $\varepsilon_i$ are random \emph{innovations} with zero mean and unit variance.
      \vskip1ex
      The \emph{AR(p)} process is a special case of an \emph{ARIMA} process, and is simply called an \emph{ARIMA} process.
      \vskip1ex
      If the \emph{AR(p)} process is stationary then the time series $r_i$ is mean-reverting to zero.
      \vskip1ex
      The function \texttt{arima.sim()} simulates \emph{ARIMA} processes, with the \texttt{"model"} argument accepting a \texttt{list} of \emph{AR} coefficients $\varphi_i$.
    <<echo=(-(1:2)),eval=FALSE>>=
# ARIMA processes
set.seed(1121)  # Reset random numbers
in_dex <- Sys.Date() + 0:728  # two year daily series
ari_ma <- xts(  # AR time series of returns
  x=arima.sim(n=NROW(in_dex), model=list(ar=0.2)),
  order.by=in_dex)
ari_ma <- cbind(ari_ma, cumsum(ari_ma))
colnames(ari_ma) <- c("AR returns", "AR prices")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      % \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/ar_process.png}
      \vspace{-3em}
    <<echo=(-(1:2)),eval=FALSE>>=
library(ggplot2)  # load ggplot2
library(gridExtra)  # load gridExtra
autoplot(object=ari_ma, # ggplot AR process
     facets="Series ~ .",
     main="Autoregressive process (phi=0.2)") +
  facet_grid("Series ~ .", scales="free_y") +
  xlab("") + ylab("") +
theme(legend.position=c(0.1, 0.5),
  plot.background=element_blank(),
  axis.text.y=element_blank())
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Examples of Autoregressive Processes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The speed of mean-reversion of an \emph{AR(1)} process depends on the \emph{AR} coefficient $\varphi_1$, with a negative coefficient producing faster mean-reversion, and a positive coefficient producing stronger diversion.
      \vskip1ex
      A positive coefficient $\varphi_1$ produces a diversion away from the mean, so that the time series $r_i$ wanders away from the mean for longer periods of time.
      <<echo=TRUE,eval=FALSE>>=
ar_coeff <- c(-0.9, 0.01, 0.9)  # AR coefficients
# Create three AR time series
ari_ma <- sapply(ar_coeff, function(phi) {
  set.seed(1121)  # Reset random numbers
  arima.sim(n=NROW(in_dex), model=list(ar=phi))
})  # End sapply
colnames(ari_ma) <- paste("autocorr", ar_coeff)
plot.zoo(ari_ma, main="AR(1) prices", xlab=NA)
# Or plot using ggplot
ari_ma <- xts(x=ari_ma, order.by=in_dex)
library(ggplot)
autoplot(ari_ma, main="AR(1) prices",
         facets=Series ~ .) +
    facet_grid(Series ~ ., scales="free_y") +
xlab("") +
theme(
  legend.position=c(0.1, 0.5),
  plot.title=element_text(vjust=-2.0),
  plot.margin=unit(c(-0.5, 0.0, -0.5, 0.0), "cm"),
  plot.background=element_blank(),
  axis.text.y=element_blank())
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/ar_processes.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Stationary Processes and Their Characteristic Equations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A process is \emph{stationary} if its probability distribution does not change with time, which means that it has constant mean and variance.
      \vskip1ex
      The \emph{autoregressive} process \emph{AR(p)}:
      $r_i = \varphi_1 r_{i-1} + \varphi_2 r_{i-2} + \ldots + \varphi_p r_{i-p} + \varepsilon_i$
      \vskip1ex
      Has the following characteristic equation:
      $1 - \varphi_1 z - \varphi_2 z^2 - \ldots - \varphi_p z^p = 0$
      \vskip1ex
      An autoregressive process is stationary only if the absolute values of all the roots of its characteristic equation are greater than \texttt{1}.
      \vskip1ex
      If the sum of the autoregressive coefficients is equal to \texttt{1}: $\sum_{i=1}^p \varphi_i = 1$, then the process has a root equal to \texttt{1} (it has a \emph{unit root}), so it's not stationary.
      \vskip1ex
      Non-stationary processes with unit roots are called \emph{unit-root} processes.
      \vskip1ex
      A simple example of a \emph{unit-root} process is the process: 
      $r_i = r_{i-1} + \varepsilon_i$,
      which is called a \emph{Wiener} process (Brownian motion, random walk).
    \column{0.5\textwidth}
      \vspace{-1em}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/stat_unit_root-1}
      \vspace{-4em}
      <<echo=(-(1:3)),eval=FALSE>>=
library(zoo)  # load zoo
library(ggplot2)  # load ggplot2
set.seed(1121)  # initialize random number generator
rand_walk <- cumsum(zoo(matrix(rnorm(3*100), ncol=3),
                  order.by=(Sys.Date()+0:99)))
colnames(rand_walk) <-
  paste("rand_walk", 1:3, sep="_")
plot.zoo(rand_walk, main="Random walks",
     xlab="", ylab="", plot.type="single",
     col=c("black", "red", "blue"))
# Add legend
legend(x="topleft",
       legend=colnames(rand_walk),
       col=c("black", "red", "blue"), lty=1)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating Autoregressive Processes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{arima.sim()} simulates \emph{ARIMA} processes by calling the function \texttt{filter()}.
      \vskip1ex
      \emph{ARIMA} processes can also be simulated by using the function \texttt{filter()} directly, with the argument \texttt{method="recursive"}.
      \vskip1ex
      Simulating stationary \emph{autoregressive} processes requires a \emph{warmup period}, to allow the process to reach its stationary state.
      \vskip1ex
      The required length of the \emph{warmup period} depends on the smallest root of the characteristic equation, with a longer \emph{warmup period} needed for smaller roots, that are closer to \texttt{1}.
      \vskip1ex
      The \emph{rule of thumb} (heuristic rule, guideline) is for the \emph{warmup period} to be equal to \texttt{6} divided  by the logarithm of the smallest characteristic root plus the number of \emph{AR} coefficients: $\frac{6}{\log(minroot)} + numcoeff$
    \column{0.5\textwidth}
      \vspace{-1em}
    <<echo=TRUE,eval=FALSE>>=
# define AR(2) coefficients
co_eff <- c(0.9, 0.09)
# Calculate modulus of roots of characteristic equation
root_s <- Mod(polyroot(c(1, -co_eff)))
# Calculate warmup period
warm_up <- NROW(co_eff) + ceiling(6/log(min(root_s)))
set.seed(1121)
len_gth <- 1e4
in_nov <- rnorm(len_gth + warm_up)
# Simulate ARIMA using arima.sim()
ari_ma <- arima.sim(n=len_gth, 
  model=list(ar=co_eff), 
  start.innov=in_nov[1:warm_up], 
  innov=in_nov[(warm_up+1):NROW(in_nov)])
# Simulate ARIMA using filter()
arima_filter <- filter(x=in_nov, 
  filter=co_eff, method="recursive")
all.equal(arima_filter[-(1:warm_up)], 
  as.numeric(ari_ma))
# Simulate ARIMA using for() loop
arima_loop <- numeric(NROW(in_nov))
arima_loop[1] <- in_nov[1]
arima_loop[2] <- co_eff[1]*arima_loop[1] + in_nov[2]
for (it in 3:NROW(arima_loop)) {
  arima_loop[it] <- arima_loop[(it-1):(it-2)] %*% co_eff + in_nov[it]
}  # End for
all.equal(arima_loop, 
  as.numeric(arima_filter))
# microbenchmark the speed of the three methods of simulating ARIMA
library(microbenchmark)
summary(microbenchmark(
  arima_filter=filter(x=in_nov, filter=co_eff, method="recursive"),
  arima_sim=arima.sim(n=len_gth, 
                      model=list(ar=co_eff), 
                      start.innov=in_nov[1:warm_up], 
                      innov=in_nov[(warm_up+1):NROW(in_nov)]),
  arima_loop=for (it in 3:NROW(arima_loop)) {
    arima_loop[it] <- arima_loop[(it-1):(it-2)] %*% co_eff + in_nov[it]}
  ), times=10)[, c(1, 4, 5)]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Variance of Unit-root Processes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      An \emph{AR(1)} process:
      $r_i = \varphi r_{i-1} + \varepsilon_i$
      has the following characteristic equation:
      $1 - \varphi z = 0$,
      with a root equal to:
      $z = 1 / \varphi$
      \vskip1ex
      If $\varphi = 1$, then the characteristic equation has a \emph{unit root} (and therefore it isn't stationary), and the process follows:
      $r_i = r_{i-1} + \varepsilon_i$
      \vskip1ex
      The above is called a \emph{Wiener} process (Brownian motion, random walk), and it's an example of a \emph{unit-root} process.
      \vskip1ex
      The variance of the \emph{AR(1)} process $r_i = \varphi r_{i-1} + \varepsilon$ is equal to:
      \begin{displaymath}
        \sigma^2 = \mathbb{E}[r_i^2] = \frac{\sigma_{\varepsilon}^2}{(1 - \varphi^2)}
      \end{displaymath}
      If $\varphi = 1$, then its \emph{variance} grows over time and becomes infinite over time, so the process isn't stationary.
      \vskip1ex
      The variance of the \emph{Wiener} process $r_i = r_{i-1} + \varepsilon$ is proportional to time: $\sigma_i^2 = \mathbb{E}[r_i^2] = i \sigma_{\varepsilon}^2$
    \column{0.5\textwidth}
      \vspace{-1em}
      \hspace*{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/brownian_var.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Simulate random walks using apply() loops
set.seed(1121)  # initialize random number generator
rand_walks <- matrix(rnorm(1000*100), ncol=1000)
rand_walks <- apply(rand_walks, 2, cumsum)
vari_ance <- apply(rand_walks, 1, var)
# Simulate random walks using vectorized functions
set.seed(1121)  # initialize random number generator
rand_walks <- matrixStats::colCumsums(matrix(rnorm(1000*100), ncol=1000))
vari_ance <- matrixStats::rowVars(rand_walks)
par(mar=c(5, 3, 2, 2), oma=c(0, 0, 0, 0))
plot(vari_ance, xlab="time steps", ylab="", 
     t="l", col="blue", lwd=2, 
     main="Variance of Random Walk")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Dickey-Fuller Test for Unit Roots}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Dickey-Fuller} and \emph{Augmented Dickey-Fuller} tests are designed to test the \emph{null hypothesis} that a time series process has a \emph{unit root}.
      \vskip1ex
      The \emph{Augmented Dickey-Fuller} (\emph{ADF}) test fits the following regression model, designed to determine if the time series $p_i$ exhibits mean reversion:
      \begin{displaymath}
        r_i = \gamma p_{i-1} + \varphi_1 r_{i-1} + \ldots + \varphi_p r_{i-p} + \varepsilon_i
      \end{displaymath}
      where $p_i = p_{i-1} + r_i$, so that:
      \begin{displaymath}
        p_i = (1 + \gamma) p_{i-1} + \varphi_1 r_{i-1} + \ldots + \varphi_p r_{i-p} + \varepsilon_i
      \end{displaymath}
      If the mean reversion parameter $\gamma$ is negative: $\gamma < 0$, then the time series $p_i$ has no \emph{unit root}.
      \vskip1ex
      The \emph{null hypothesis} is that the price process has a unit root ($\gamma = 0$, no mean reversion), while the alternative hypothesis is that the price process is stationary ($\gamma < 0$, mean reversion).
      \vskip1ex
      The \emph{ADF} test statistic is equal to the \emph{t}-value of the $\gamma$ parameter: $t_{\gamma} = \hat\gamma / SE_{\gamma}$ (which follows its own distribution, different from the \texttt{t}-distribution).
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
len_gth <- 1e4
# Simulate arima with small AR coefficient
set.seed(1121)
ari_ma <- arima.sim(n=len_gth, model=list(ar=0.01))
tseries::adf.test(ari_ma)
# Simulate arima with large AR coefficient
set.seed(1121)
ari_ma <- arima.sim(n=len_gth, model=list(ar=0.99))
tseries::adf.test(ari_ma)
# Simulate arima with different AR coefficients
coeff_s <- seq(0.99, 1.0, 0.001) - 0.001
set.seed(1121)
in_nov <- rnorm(len_gth)
adf_test <- sapply(coeff_s, function(co_eff) {
  ari_ma <- filter(x=in_nov, filter=co_eff, method="recursive")
  ad_f <- suppressWarnings(tseries::adf.test(ari_ma))
  c(adf_stat=unname(ad_f$statistic), pval=ad_f$p.value)
})  # End sapply
plot(x=coeff_s, y=adf_test["pval", ], main="ADF Pval versus AR coefficient", 
     xlab="AR coefficient", ylab="ADF pval", t="l", col="blue", lwd=2)
plot(x=coeff_s, y=adf_test["adf_stat", ], main="ADF Stat versus AR coefficient", 
     xlab="AR coefficient", ylab="ADF stat", t="l", col="blue", lwd=2)
      @
      \vspace{-1em}
      The \emph{ADF} test is weak in the sense that it requires a lot of data to identify a \emph{unit root} process.
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Integrated and Unit-root Processes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Asset prices follow an \emph{integrated} process with respect to asset returns:
      \begin{displaymath}
        p_n = {\sum_{i=1}^n r_i}
      \end{displaymath}
      If returns follow an \emph{AR(1)} process:
      \begin{displaymath}
        r_i = \varphi r_{i-1} + \varepsilon_i
      \end{displaymath}
      Then asset prices follow the process:
      \begin{displaymath}
        p_i = (1 + \varphi) p_{i-1} - \varphi p_{i-2} + \varepsilon_i
      \end{displaymath}
      The above process has a \emph{unit root} for all values of $\varphi$, because the sum of its autoregressive coefficients is equal to \texttt{1}.
      \vskip1ex
      The above process is a \emph{Wiener} process (random walk) for all values of $\varphi$.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Simulate arima with large AR coefficient
set.seed(1121)
ari_ma <- arima.sim(n=len_gth, model=list(ar=0.99))
tseries::adf.test(ari_ma)
# integrated series has unit root
tseries::adf.test(cumsum(ari_ma))
# Simulate arima with negative AR coefficient
set.seed(1121)
ari_ma <- arima.sim(n=len_gth, model=list(ar=-0.99))
tseries::adf.test(ari_ma)
# integrated series has unit root
tseries::adf.test(cumsum(ari_ma))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Autocorrelation of Autoregressive \protect\emph{ARIMA} Processes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The autocorrelation $\rho_i$ of an \emph{AR(1)} process (defined as $r_i = \varphi r_{i-1} + \varepsilon_i$), satisfies the recursive equation: $\rho_i = \varphi \rho_{i-1}$, with $\rho_1 = \varphi$.
      \vskip1ex
      Therefore \emph{AR(1)} processes have exponentially decaying autocorrelations: $\rho_i = \varphi^i$.
      \vskip1ex
      The \emph{AR(1)} process can be solved recursively:
      \begin{align*}
        r_1 &= \varepsilon_1\\
        r_2 &= \varphi r_1 + \varepsilon_2 = \varepsilon_2 + \varphi \varepsilon_1\\
        r_3 &= \varepsilon_3 + \varphi \varepsilon_2 + \varphi^2 \varepsilon_1\\
        r_4 &= \varepsilon_4 + \varphi \varepsilon_3 + \varphi^2 \varepsilon_2 + \varphi^3 \varepsilon_1
      \end{align*}
      Therefore the \emph{AR(1)} process can be expressed as a \emph{moving average} (\emph{MA}) of the \emph{innovations} $\varepsilon_i$: $r_i = \sum_{i=1}^n {\varphi^{i-1} \varepsilon_i}$.
      \vskip1ex
      If $\varphi < 1.0$ then the influence of the innovation $\varepsilon_i$ decays exponentially.
      \vskip1ex
      If $\varphi = 1.0$ then the influence of the random innovations $\varepsilon_i$ persists indefinitely, so that the variance of $r_i$ increases linearly with time.
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ar_acf.png}
      \vspace{-2em}
      <<echo=(-(1:2)),eval=FALSE>>=
x11(width=5, height=3.5)
par(mar=c(3, 3, 2, 1), oma=c(0, 0, 0, 0))
# Simulate AR(1) process
ari_ma <- arima.sim(n=729, model=list(ar=0.8))
# ACF of AR(1) process
ac_f <- acf_plus(ari_ma, lag=10, 
  xlab="", ylab="",
  main="Autocorrelations of AR(1) process")
ac_f$acf[1:5]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Partial Autocorrelations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If two random variables are both correlated to a third variable, then they are indirectly correlated with each other.
      \vskip1ex
      The indirect correlation can be removed by defining new variables with no correlation to the third variable.
      \vskip1ex
      The \emph{partial correlation} is the correlation after the correlations to the common variables are removed.
      \vskip1ex
      The \emph{partial autocorrelations} $\varrho_i$ of an \emph{AR(1)} process can be computed recursively from the autocorrelations $\rho_i$ using the Durbin-Levinson algorithm:
      \begin{align*}
        \varrho_1 &= \rho_1\\
        \varrho_2 &= \rho_2 - \varrho_1 \rho_1\\
        \varrho_3 &= \rho_3 - \varrho_1 \rho_2 - \varrho_2 \rho_1
      \end{align*}
      The function \texttt{pacf()} calculates and plots the \emph{partial autocorrelations}, but it performs regressions instead of using the Durbin-Levinson algorithm.
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ar_pacf.png}
      % \vspace{-2em}
      The \emph{AR(1)} process has an exponentially decaying ACF and a non-zero PACF at lag one.
      <<echo=TRUE,eval=FALSE>>=
# PACF of AR(1) process
pac_f <- pacf(ari_ma, lag=10, 
  xlab="", ylab="", main="")
title("Partial autocorrelations of AR(1) process", 
  line=1)
pac_f <- drop(pac_f$acf)
pac_f[1:5]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Partial Autocorrelations of \protect\emph{AR(1)} Processes}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      An autocorrelation of lag \texttt{1} induces higher order autocorrelations of lag \texttt{2, 3, ...}, which may obscure the true higher order autocorrelations.
      \vskip1ex
      A linear combination of the time series and its own lag can be created, such that its lag \texttt{1} autocorrelation is zero.
      \vskip1ex
      The lag \texttt{2} autocorrelation of this new series is called the \emph{partial autocorrelation} of lag \texttt{2}, and represents the true second order autocorrelation.
      \vskip1ex
      The \emph{partial autocorrelation} of lag \texttt{k} is the autocorrelation of lag \texttt{k}, after all the autocorrelations of lag \texttt{1, ..., k-1} have been removed.
      \vskip1ex
      The \emph{partial autocorrelations} $\varrho_i$ of an \emph{AR(1)} process can be computed recursively from the autocorrelations $\rho_i$ using the Durbin-Levinson algorithm:
      \begin{displaymath}
        \varrho_k = \rho_k - \sum_{i=1}^{k-1} {\varrho_i \rho_{k-i}}
      \end{displaymath}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Compute pacf recursively from acf
ac_f <- acf_plus(ari_ma, lag=10, plo_t=FALSE)
ac_f <- drop(ac_f$acf)
pac_f <- numeric(3)
pac_f[1] <- ac_f[1]
pac_f[2] <- ac_f[2] - ac_f[1]^2
pac_f[3] <- ac_f[3] - 
  pac_f[2]*ac_f[1] - ac_f[2]*pac_f[1]
# Compute pacf recursively in a loop
pac_f <- numeric(NROW(ac_f))
pac_f[1] <- ac_f[1]
for (it in 2:NROW(pac_f)) {
  pac_f[it] <- ac_f[it] - 
    pac_f[1:(it-1)] %*% ac_f[(it-1):1]
}  # End for
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Higher Order Autocorrelations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      An \emph{AR}(3) process of order \emph{three} is defined by the formula:
      \begin{displaymath}
        r_i = \varphi_1 r_{i-1} + \varphi_2 r_{i-2} + \varphi_3 r_{i-3} + \varepsilon_i
      \end{displaymath}
      Autoregressive processes \emph{AR(p)} of order \emph{p} have an exponentially decaying ACF and a non-zero PACF up to lag \emph{p}.
      <<ar_pacf,echo=(-(1:2)),eval=FALSE,fig.height=8,fig.show='hide'>>=
par(oma=c(15, 1, 1, 1), mgp=c(0, 0.5, 0), mar=c(1, 1, 1, 1), cex.lab=0.8, cex.axis=0.8, cex.main=0.8, cex.sub=0.5)
par(mfrow=c(2,1))  # Set plot panels
# Simulate AR(3) time series of returns
ari_ma <- arima.sim(n=729, 
  model=list(ar=c(0.1, 0.5, 0.1)))
# ACF of AR(3) process
acf_plus(ari_ma, lag=10, xlab="", ylab="", 
         main="ACF of AR(3) process")
# PACF of AR(3) process
pacf(ari_ma, lag=10, xlab="", ylab="", 
     main="PACF of AR(3) process")
      @
    \column{0.5\textwidth}
      \vspace{-2em}
      \includegraphics[width=0.5\paperwidth]{figure/ar_pacf-1}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Calibrating Autoregressive Models}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{arima()} from the base package \emph{stats} fits an ARIMA model to a univariate time series.
      \vskip1ex
      The function \texttt{auto.arima()} from the package \emph{forecast} automatically fits an ARIMA model to a univariate time series.
      \vskip1ex
      An \emph{autoregressive} process \emph{AR(p)} defined as:
      \begin{multline*}
        r_i = \varphi_1 r_{i-1} + \varphi_2 r_{i-2} + \ldots + \varphi_p r_{i-p} + \varepsilon_i = \\
        \sum_{j=1}^{p} {\varphi_j r_{i-j}} + \varepsilon_i
      \end{multline*}
      Can be solved as a \emph{multivariate} linear regression model, with the \emph{response} equal to $r_i$, and the \emph{design matrix} columns equal to the lags of $r_i$.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calibrate ARIMA model using arima()
arima_fit <- arima(ari_ma, 
  order=c(3,0,0), include.mean=FALSE)
arima_fit$coef
# Calibrate ARIMA model using auto.arima()
# library(forecast)  # load forecast
forecast::auto.arima(ari_ma, max.p=3, max.q=0)
# Calibrate ARIMA model using regression
ari_ma <- as.numeric(ari_ma)
# define design matrix
de_sign <- sapply(1:3, function(lagg) {
  rutils::lag_it(ari_ma, lagg=lagg)
})  # End sapply
# generalized inverse of design matrix
design_inv <- MASS::ginv(de_sign)
# Regression coefficients with response equal to ari_ma
co_eff <- drop(design_inv %*% ari_ma)
all.equal(arima_fit$coef, co_eff, check.attributes=FALSE)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Yule-Walker Equations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      To lighten the notation we can assume that the time series $r_i$ has zero mean $\mathbb{E}[r_i] = 0$ and unit variance $\mathbb{E}[r_i^2] = 1$.  ($\mathbb{E}$ is the expectation operator.)
      \vskip1ex
      Then the \emph{autocorrelations} of $r_i$ are equal to: $\rho_k = \mathbb{E}[r_i r_{i-k}]$.
      \vskip1ex
      If we multiply the \emph{autoregressive} process \emph{AR(p)}: $r_i = \sum_{j=1}^{p} {\varphi_j r_{i-j}} + \varepsilon_i$, by $r_{i-k}$ and take the expectations, then we obtain the Yule-Walker equations:
      \begin{displaymath}
        \begin{pmatrix}
          \rho_1 \\
          \rho_2 \\
          \rho_3 \\
          \vdots \\
          \rho_p
        \end{pmatrix} = 
        \begin{pmatrix}
          1 & \rho_1 & \dots & \rho_{p-1} \\
          \rho_1 & 1 & \dots & \rho_{p-2} \\
          \rho_2 & \rho_1 & \dots & \rho_{p-3} \\
          \vdots & \vdots & \ddots & \vdots \\
          \rho_{p-1} & \rho_{p-2} & \dots & 1
        \end{pmatrix}
        \begin{pmatrix}
          \varphi_1 \\
          \varphi_2 \\
          \varphi_3 \\
          \vdots \\
          \varphi_p
        \end{pmatrix}
      \end{displaymath}
      The Yule-Walker equations relate the \emph{autocorrelation coefficients} $\rho_i$ with the coefficients of the \emph{AR(p)} process $\varphi_i$.
      \vskip1ex
      The Yule-Walker equations can be solved for the \emph{AR(p)} coefficients $\varphi_i$ using matrix inversion.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Compute autocorrelation coefficients
ac_f <- acf_plus(ari_ma, lag=10, plo_t=FALSE)
ac_f <- drop(ac_f$acf)
# define Yule-Walker matrix
acf_1 <- c(1, ac_f[-10])
yule_walker <- sapply(1:9, function(lagg) {
  col_umn <- rutils::lag_it(acf_1, lagg=lagg)
  col_umn[1:lagg] <- acf_1[(lagg+1):2]
  col_umn
})  # End sapply
yule_walker <- cbind(acf_1, yule_walker)
# generalized inverse of Yule-Walker matrix
yule_walker_inv <- MASS::ginv(yule_walker)
# Solve Yule-Walker equations
co_eff <- drop(yule_walker_inv %*% ac_f)
      @
  \end{columns}
\end{block}

\end{frame}


% wipp
%%%%%%%%%%%%%%%
\subsection{Forecasting From Autoregressive Models}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The one step ahead \emph{forecast} $f_i$ of the time series $r_i$ using the process \emph{AR(p)} is defined as:
      \begin{displaymath}
        f_i = \varphi_1 r_{i-1} + \varphi_2 r_{i-2} + \ldots + \varphi_p r_{i-p}
      \end{displaymath}
      The function \texttt{filter()} with the argument \texttt{method="convolution"} calculates the convolution of a vector with a filter.
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
len_gth <- 1e2
# Simulate AR(3) time series using filter()
co_eff <- c(0.1, 0.39, 0.5)
set.seed(1121); in_nov <- rnorm(len_gth)
se_ries <- filter(x=in_nov, 
  filter=co_eff, method="recursive")
# Forecast using AR(3) ARIMA
fore_casts <- numeric(NROW(se_ries))
fore_casts[2] <- co_eff[1]*se_ries[1]
fore_casts[3] <- co_eff[1]*se_ries[2] + 
  co_eff[2]*se_ries[1]
for (it in 4:NROW(fore_casts)) {
  fore_casts[it] <- 
    se_ries[(it-1):(it-3)] %*% co_eff
}  # End for
# Forecast using filter()
forecasts_filter <- filter(x=se_ries, sides=1,
  filter=co_eff, method="convolution")
class(forecasts_filter)
all.equal(fore_casts[-(1:4)], 
  forecasts_filter[-c(1:3, NROW(forecasts_filter))], 
  check.attributes=FALSE)
# Compare residuals with innovations
residual_s <- (se_ries - fore_casts)
tail(cbind(in_nov, residual_s))
plot(residual_s, t="l", lwd=3, main="ARIMA Forecast Errors")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ar_forecast.png}
      Accurate forecasting requires knowing the order \texttt{p} of the \emph{AR(p)} process and its coefficients.
      <<echo=TRUE,eval=FALSE>>=
# Plot with legend
plot.default(se_ries, 
  main="Forecasting Using AR(3) Model",
  xlab="", ylab="", type="l")
lines(fore_casts, col="orange", lwd=3)
legend(x="topright", legend=c("series","forecasts"),
       col=c("black", "orange"), lty=1, lwd=6, 
       cex=0.9, bg="white", bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: Forecasting From Autoregressive Models Using \texttt{predict.Arima()}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The one step ahead \emph{forecast} $f_i$ of the time series $r_i$ using the process \emph{AR(p)} is defined as:
      \begin{displaymath}
        f_i = \varphi_1 r_{i-1} + \varphi_2 r_{i-2} + \ldots + \varphi_p r_{i-p}
      \end{displaymath}
      The function \texttt{filter()} with the argument \texttt{method="convolution"} calculates the convolution of a vector with a filter.
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Forecast using predict.Arima()
?stats:::predict.Arima
# se_ries <- as.numeric(lh)
# len_gth <- NROW(se_ries)
# Compare one-step-ahead forecasts
# arima_fit <- arima(se_ries, order=c(3,0,0), method="ML", include.mean=FALSE)
arima_fit <- arima(se_ries, order=c(3,0,0), method="ML")
pre_dict <- predict(arima_fit, n.ahead=1)
fore_cast <- drop(c(se_ries[(len_gth-2):len_gth], 1) %*% arima_fit$coef)
# fore_cast <- drop(se_ries[(len_gth-2):len_gth] %*% arima_fit$coef)
as.numeric(pre_dict$pred)

# Compare many one-step-ahead forecasts
foo <- sapply(1:1e2, function(x) {
  se_ries <- filter(x=rnorm(len_gth+1), filter=co_eff, method="recursive")
  arima_fit <- arima(se_ries[1:len_gth], order=c(3,0,0), method="ML")
  pre_dict <- predict(arima_fit, n.ahead=1)
  fore_cast <- drop(c(se_ries[(len_gth-2):len_gth], 1) %*% arima_fit$coef)
  c(actual=se_ries[len_gth+1], forecast=fore_cast, predict=as.numeric(pre_dict$pred))
})  # end sapply
foo <- t(foo)
# hist(foo[, 1], breaks=30, 
#   main="", ylim=c(0, 60), xlim=c(-0.04, 0.04), 
#   xlab="", ylab="", freq=FALSE)

hist(foo[, 1], ylim=c(0, 0.15), freq=FALSE)
lines(density(foo[, 1]), col='blue', lwd=3)
lines(density(foo[, 2]), col='green', lwd=3)
lines(density(foo[, 3]), col='red', lwd=3)


# Forecast using AR(3) ARIMA
fore_casts <- numeric(NROW(se_ries))
fore_casts[2] <- co_eff[1]*se_ries[1]
fore_casts[3] <- co_eff[1]*se_ries[2] + 
  co_eff[2]*se_ries[1]
for (it in 4:NROW(fore_casts)) {
  fore_casts[it] <- 
    se_ries[(it-1):(it-3)] %*% co_eff
}  # End for
# Forecast using filter()
forecasts_filter <- filter(x=se_ries, sides=1,
  filter=co_eff, method="convolution")
class(forecasts_filter)
all.equal(fore_casts[-(1:4)], 
  forecasts_filter[-c(1:3, NROW(forecasts_filter))], 
  check.attributes=FALSE)
# Compare residuals with innovations
residual_s <- (se_ries-fore_casts)
tail(cbind(in_nov, residual_s))
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ar_forecast.png}
      Accurate forecasting requires knowing the order \texttt{p} of the \emph{AR(p)} process and its coefficients.
      <<echo=TRUE,eval=FALSE>>=
# Plot with legend
plot.default(se_ries, 
  main="Forecasting Using AR(3) Model",
  xlab="", ylab="", type="l")
lines(fore_casts, col="orange", lwd=3)
legend(x="topright", legend=c("series","forecasts"),
       col=c("black", "orange"), lty=1, lwd=6, 
       cex=0.9, bg="white", bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: The Standard Errors of Forecasts from Autoregressive Models}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The one step ahead \emph{forecast} $f_i$ of the time series $r_i$ using the process \emph{AR(p)} is defined as:
      \begin{displaymath}
        f_i = \varphi_1 r_{i-1} + \varphi_2 r_{i-2} + \ldots + \varphi_p r_{i-p}
      \end{displaymath}
      The function \texttt{filter()} with the argument \texttt{method="convolution"} calculates the convolution of a vector with a filter.
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
len_gth <- 1e2
# Simulate AR(3) time series using filter()
co_eff <- c(0.1, 0.39, 0.5)
set.seed(1121)
se_ries <- filter(x=rnorm(len_gth), 
  filter=co_eff, method="recursive")
# Forecast using AR(3) ARIMA
fore_casts <- numeric(NROW(se_ries))
fore_casts[2] <- co_eff[1]*se_ries[1]
fore_casts[3] <- co_eff[1]*se_ries[2] + 
  co_eff[2]*se_ries[1]
for (it in 4:NROW(fore_casts)) {
  fore_casts[it] <- 
    se_ries[(it-1):(it-3)] %*% co_eff
}  # End for
# Forecast using filter()
forecasts_filter <- filter(x=se_ries, sides=1,
  filter=co_eff, method="convolution")
class(forecasts_filter)
all.equal(fore_casts[-(1:4)], 
  forecasts_filter[-c(1:3, NROW(forecasts_filter))], 
  check.attributes=FALSE)
# Compare residuals with innovations
residual_s <- (se_ries-fore_casts)
tail(cbind(in_nov, residual_s))
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ar_forecast.png}
      Accurate forecasting requires knowing the order \texttt{p} of the \emph{AR(p)} process and its coefficients.
      <<echo=TRUE,eval=FALSE>>=
# Plot with legend
plot.default(se_ries, 
  main="Forecasting Using AR(3) Model",
  xlab="", ylab="", type="l")
lines(fore_casts, col="orange", lwd=3)
legend(x="topright", legend=c("series","forecasts"),
       col=c("black", "orange"), lty=1, lwd=6, 
       cex=0.9, bg="white", bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Backtesting the Autoregressive Forecasting Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Backtesting} is the testing of the accuracy of a forecasting model using simulation on historical data.
      \vskip1ex
      The Autoregressive forecasting model can be \emph{backtested} by calculating forecasts over a rolling look-back interval.
      \vskip1ex
      The coefficients of the \emph{AR(p)} process can be calculated over a rolling look-back interval, and then used for calculating out-of-sample forecasts.
      \vskip1ex
      The accuracy of the \emph{AR(p)} forecasting model depends on the two \emph{meta-parameters}: \texttt{look\_back} (the length of look-back interval) and \texttt{p} (the order of the \emph{AR(p)} process).
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Simulate AR(3) time series using filter()
len_gth <- 1e3
co_eff <- c(0.1, 0.39, 0.5)
set.seed(1121)
se_ries <- filter(x=rnorm(len_gth), 
  filter=co_eff, method="recursive")
# Define design matrix and end_points
de_sign <- sapply(1:3, function(lagg) {
  rutils::lag_it(se_ries, lagg=lagg)
})  # End sapply
de_sign <- cbind(se_ries, de_sign)
look_back <- 100  # length of look-back interval
end_points <- seq_along(se_ries)
n_rows <- NROW(end_points)
start_points <- c(rep_len(1, look_back-1), 
    end_points[1:(n_rows-look_back+1)])
# Perform rolling forecasting
fore_casts <- sapply(seq_along(end_points)[-(1:2)], 
  function(it) {
    de_sign <- de_sign[start_points[it]:end_points[it], ]
    # Calculate AR(3) coefficients
    design_inv <- MASS::ginv(de_sign[, -1])
    co_eff <- drop(design_inv %*% de_sign[, 1])
    de_sign[(NROW(de_sign)-2):NROW(de_sign), 1] %*% co_eff
  })  # End sapply
fore_casts <- c(rep(fore_casts[1], 2), fore_casts)
# Lag the forecasts to push them out-of-sample
fore_casts <- rutils::lag_it(fore_casts)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Mean Squared Error of Forecasting Models}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The mean squared error (\emph{MSE}) of a forecasting model is the average of the squared differences between the forecasts minus the actual values.
      \vskip1ex
      The accuracy of the \emph{AR(p)} forecasting model depends on the two \emph{meta-parameters}: \texttt{look\_back} (the length of look-back interval) and \texttt{p} (the order of the \emph{AR(p)} process).
      \vskip1ex
      The two \emph{meta-parameters} can be chosen by minimizing the \emph{MSE} of the model forecasts in a \emph{backtest} simulation.
      <<echo=TRUE,eval=FALSE>>=
# Mean squared error
ms_e <- mean((fore_casts-se_ries)^2)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ar_forecast_rolling.png}\\
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Plot with legend
plot.default(se_ries, 
  main="Rolling Forecasting Using AR(3) Model",
  xlab="", ylab="", type="l")
lines(fore_casts, col="orange", lwd=1)
legend(x="topright", legend=c("series","forecasts"),
       col=c("black", "orange"), lty=1, lwd=6, 
       cex=0.9, bg="white", bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Ornstein-Uhlenbeck Process}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      In the \emph{Ornstein-Uhlenbeck} process, the returns $r_i$ are proportional to the difference between the equilibrium price $\mu$ minus the current price $p_i$:
      \begin{displaymath}
        r_i = p_i - p_{i-1} = \theta (\mu - p_{i-1}) + \sigma \varepsilon_i
      \end{displaymath}
      Where the parameter $\theta$ is the strength of mean reversion, and $\sigma$ is the volatility.
      \vskip1ex
      The \emph{Ornstein-Uhlenbeck} process can be written as an \emph{AR(1)} process plus a drift:
      \begin{displaymath}
        p_i = \theta \mu + (1 - \theta ) p_{i-1} + \sigma \varepsilon_i
      \end{displaymath}
      The \emph{Ornstein-Uhlenbeck} process cannot be simulated using the function \texttt{filter()} because of the drift term in its equation, and must be simulated using loops.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# define Ornstein-Uhlenbeck parameters
eq_price <- 1.0; vol_at <- 0.02
the_ta <- 0.01; len_gth <- 1000
drif_t <- the_ta*eq_price
theta_1 <- 1-the_ta
# Simulate Ornstein-Uhlenbeck process
in_nov <- vol_at*rnorm(len_gth)
price_s <- numeric(len_gth)
price_s[1] <- in_nov[1]
for (i in 2:len_gth) {
  price_s[i] <- theta_1*price_s[i-1] + 
    in_nov[i] + drif_t
}  # End for
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Ornstein-Uhlenbeck Process Warmup and Mean Reversion}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Stationary \emph{AR(p)} time series are mean-reverting to zero, while the \emph{Ornstein-Uhlenbeck} process is mean-reverting to a non-zero equilibrium price $\mu$.
      \vskip1ex
      The \emph{Ornstein-Uhlenbeck} process needs a \emph{warmup period} before it reaches equilibrium.
      <<echo=TRUE,eval=FALSE>>=
plot(price_s, type="l",
     xlab="periods", ylab="prices",
     main="Ornstein-Uhlenbeck process")
legend("topright",
       title=paste(c(paste0("vol_at = ", vol_at),
                     paste0("eq_price = ", eq_price),
                     paste0("the_ta = ", the_ta)),
                   collapse="\n"),
       legend="", cex=0.8,
       inset=0.1, bg="white", bty="n")
abline(h=eq_price, col='red', lwd=2)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/ou_proc.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Ornstein-Uhlenbeck Process Returns Correlation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Under the \emph{Ornstein-Uhlenbeck} process, the returns are negatively correlated to the lagged prices.
      <<echo=TRUE,eval=FALSE>>=
re_turns <- rutils::diff_it(price_s)
lag_price <- rutils::lag_it(price_s)
for_mula <- re_turns ~ lag_price
l_m <- lm(for_mula)
summary(l_m)
# Plot regression
plot(for_mula, main="OU Returns Versus Lagged Prices")
abline(l_m, lwd=2, col="red")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/ou_scatter.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Estimating the Ornstein-Uhlenbeck Parameters}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The volatility parameter of the Ornstein-Uhlenbeck process can be estimated directly from the returns.
      \vskip1ex
      The $\theta$ and $\mu$ parameters can be estimated from the linear regression of the returns versus the lagged prices.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# volatility parameter
c(vol_at, sd(re_turns))
# Extract OU parameters from regression
co_eff <- summary(l_m)$coefficients
# theta strength of mean reversion
round(co_eff[2, ], 3)
# Equilibrium price
co_eff[1, 1]/co_eff[2, 1]
# Parameter and t-values
co_eff <- cbind(c(the_ta*eq_price, the_ta), 
  co_eff[, 1:2])
rownames(co_eff) <- c("drift", "theta")
round(co_eff, 3)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Schwartz Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Ornstein-Uhlenbeck} time series can have negative values, while prices cannot be negative.
      \vskip1ex
      The emph{Schwartz} model is similar to the \emph{Ornstein-Uhlenbeck} process, but it avoids negative prices by using the percentage returns $\mathrm{d} \log{P}$ instead of the simple returns $\mathrm{d} P$:
      \begin{displaymath}
        r_i = \log{p_i} - \log{p_{i-1}} = \theta (\mu - p_{i-1}) + \sigma \varepsilon_i
      \end{displaymath}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Simulate Ornstein-Uhlenbeck process
re_turns <- numeric(len_gth)
price_s <- numeric(len_gth)
price_s[1] <- eq_price
set.seed(1121)  # Reset random numbers
for (i in 2:len_gth) {
  re_turns[i] <- the_ta*(eq_price - price_s[i-1]) +
    vol_at*rnorm(1)
  price_s[i] <- price_s[i-1] * exp(re_turns[i])
}  # End for
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/ou_lognormal.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
plot(price_s, type="l",
     xlab="periods", ylab="prices",
     main="Log-normal Ornstein-Uhlenbeck process")
legend("topright",
       title=paste(c(paste0("vol_at = ", vol_at),
                     paste0("eq_price = ", eq_price),
                     paste0("the_ta = ", the_ta)),
                   collapse="\n"),
       legend="", cex=0.8,
       inset=0.12, bg="white", bty="n")
abline(h=eq_price, col='red', lwd=2)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{draft: The Solution of the Ornstein-Uhlenbeck Equation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
    % wipp
      Thierfelder Ornstein-Uhlenbeck Process.pdf
      \vskip1ex
      The Standard \emph{Ornstein-Uhlenbeck} process has a solution in the form of an integral over \emph{Brownian motion}:
      \begin{flalign*}
        & \mathrm{d} \log{P_t} = \theta ( \mu - P_t ) \mathrm{d} t + \sigma \mathrm{d} W_t \\
        & \mathrm{d} \log{P_t} = \theta ( \mu - P_t ) \mathrm{d} t + \sigma \mathrm{d} W_t \\
        & \mathrm{d} \log{P_t} = \theta ( \mu - P_t ) \mathrm{d} t + \sigma \mathrm{d} W_t \\
      \end{flalign*}
      % \begin{displaymath}
      % \end{displaymath}
      Where $\theta$ is the strength of mean reversion, and $\sigma$ is the volatility,
      \vskip1ex
      The \emph{Ornstein-Uhlenbeck} process must be simulated using a \texttt{for()} loop, since it is path-dependent,
      <<echo=TRUE,eval=FALSE>>=
# define Ornstein-Uhlenbeck parameters
eq_price <- 5.0; vol_at <- 0.01
the_ta <- 0.01; len_gth <- 1000
# Simulate Ornstein-Uhlenbeck process
re_turns <- numeric(len_gth)
price_s <- numeric(len_gth)
price_s[1] <- 5.0
set.seed(1121)  # Reset random numbers
for (i in 2:len_gth) {
  re_turns[i] <- the_ta*(eq_price - price_s[i-1]) +
    vol_at*rnorm(1)
  price_s[i] <- price_s[i-1] * exp(re_turns[i])
}  # End for
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/ou_lognormal.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
plot(price_s, type="l",
     xlab="periods", ylab="prices",
     main="Ornstein-Uhlenbeck process")
legend("topright",
       title=paste(c(paste0("vol_at = ", vol_at),
                     paste0("eq_price = ", eq_price),
                     paste0("the_ta = ", the_ta)),
                   collapse="\n"),
       legend="", cex=0.8,
       inset=0.1, bg="white", bty="n")
      @
  \end{columns}
\end{block}

\end{frame}


\end{document}
